---
layout: tutorial_hands_on

title: Multi-sample batch correction with Harmony and SnapATAC2
subtopic: scmultiomics
priority: 3
level: Intermediate
zenodo_link: https://zenodo.org/records/12683310
questions:
- Why is batch correction important during the analysis of data from multiple samples?
- How is batch correction performed on single cell ATAC-seq data?
objectives:
- Perform batch correction on a dataset collection of multiple single cell ATAC-seq samples.
- Learn how Harmony and other batch correction algorithms remove batch effects. 
time_estimation: 4H
key_points:
- Batch correction is important for the integration of data from multiple experiments
- Batch correction algorithms identify similar cells and move them closer together through appropriate correction vectors. 
requirements:
  -
    type: "internal"
    topic_name: single-cell
    tutorials:
      - scatac-preprocessing-tenx
      - scatac-standard-processing-snapatac2
tags:
- 10x
- epigenetics
abbreviations:
    scATAC-seq: Single-cell Assay for Transposase-Accessible Chromatin using sequencing
    QC: quality control
    TSSe: transcription start site enrichment
    TSS: transcription start sites
    UMAP: Uniform Manifold Approximation and Projection
contributors:
- timonschlegel
gitter: Galaxy-Training-Network/galaxy-single-cell


---


# Introduction

<!-- This is a comment. -->
Performing experiments in replicates is a cornerstone of modern biological science. However, when integrating data from multiple single-cell sequencing experiments, technical confounders might impact the results. 
To reduce technical confounders, such as different experimenters, experimental protocols, sequencing lanes or sequencing technologies, batch correction is often beneficial. 

In this tutorial, we will perform batch correction on five datasets of {scATAC-seq} data with the three algorithms *Harmony* ({% cite Korsunsky2019 %}), *Scanorama* ({% cite Hie2019 %}) and the *mutual nearest neighbor-based* ({% cite Haghverdi2018%}) algorithm *MNC-correct* ({% cite Zhang2024 %}). The {scATAC-seq} analysis will be performed with the tool suite [**SnapATAC2**](https://kzhang.org/SnapATAC2/version/2.5/index.html) ({% cite Zhang2024 %}). 

{% snippet topics/single-cell/faqs/single_cell_omics.md %}

{% snippet faqs/galaxy/tutorial_mode.md %}

> <comment-title></comment-title>
>
> This tutorial is significantly based on the ["Multi-sample Pipeline" tutorial](https://kzhang.org/SnapATAC2/version/2.5/tutorials/integration.html) from **SnapATAC2**. 
> 
> The data analysis is performed with the same tools shown in the tutorial [Single-cell ATAC-seq standard processing with SnapATAC2]( {% link topics/single-cell/tutorials/scatac-standard-processing-snapatac2/tutorial.md %} ). 
> That tutorial also explains the steps of the ATAC-seq analysis with SnapATAC2 in more detail. 
> We recommend completing that tutorial before continuing with this one. 
>
{: .comment}

> <agenda-title></agenda-title>
>
> In this tutorial, we will cover:
>
> 1. TOC
> {:toc}
>
{: .agenda}

# Data

In this tutorial we will analyze colon samples from multiple donors, provided by the [SnapATAC2 documentation](https://kzhang.org/SnapATAC2/version/2.5/tutorials/integration.html). The `chrom_sizes` file and the `gene_annotation` file are identical to the previous tutorial [Single-cell ATAC-seq standard processing with SnapATAC2]( {% link topics/single-cell/tutorials/scatac-standard-processing-snapatac2/tutorial.md %} ).
The five `colon_multisample` files have been generated by the **Cell Ranger ATAC 2.0.0** pipeline from 10X to generate a [*Fragments File*](https://support.10xgenomics.com/single-cell-atac/software/pipelines/latest/output/fragments).


> <details-title>Chromosome sizes </details-title>
>
> - A chromosome sizes file can be generated using the tool {% tool [Compute sequence length](toolshed.g2.bx.psu.edu/repos/devteam/fasta_compute_length/fasta_compute_length/1.0.3) %}.
> - The reference genome can either be selected from cached genomes or uploaded to the galaxy history.
>
{: .details}

First we will import the datasets into Galaxy. Then we will build a dataset collection, containing all `colon_multisample` datasets. This will make the following analysis steps much simpler. 

{% snippet faqs/galaxy/histories_datasets_vs_collections.md %}


## Get data

> <hands-on-title> Data Upload </hands-on-title>
>
> 1. Create a new history for this tutorial
> 2. Import the files from [Zenodo]({{ page.zenodo_link }}) or from
>    the shared data library
>
>
>    ```
>    {{ page.zenodo_link }}/files/colon_multisample_01.gz
>    {{ page.zenodo_link }}/files/colon_multisample_02.gz
>    {{ page.zenodo_link }}/files/colon_multisample_03.gz
>    {{ page.zenodo_link }}/files/colon_multisample_04.gz
>    {{ page.zenodo_link }}/files/colon_multisample_05.gz
>    {{ page.zenodo_link }}/files/chrom_sizes.txt
>    {{ page.zenodo_link }}/files/gencode.v46.annotation.gtf.gz
>    ```
>
>    {% snippet faqs/galaxy/datasets_import_via_link.md %}
>
>    {% snippet faqs/galaxy/datasets_import_from_data_library.md %}
>
>    > <warning-title>Large file sizes!</warning-title>
>    > - The `colon_multisample` datasets are quite large. The entire tutorial requires approximately 50 GB of storage. 
>    > - To reduce storage you can change the {% icon galaxy-gear %} **Upload Configuration** to *Defer dataset resolution* for the upload of the `colon_multisample` datasets.
>      > - This will delete the datasets after the first analysis step and helps in reducing storage. 
>    > - You can also permanently delete datasets, which are no longer required. 
>    > 
>    >   {% snippet faqs/galaxy/datasets_deleting.md %}
>    > 
>    {: .warning}
>
> 3. Rename the datasets
>    - {% icon galaxy-pencil %} **Rename** the file `gencode.v46.annotation.gtf.gz` to `gene_annotation.gtf.gz`
>
>    {% snippet faqs/galaxy/datasets_rename.md %}
>
> 4. Check that the datatypes of the `colon_multisample` files are set to `bed`
>
>    {% snippet faqs/galaxy/datasets_change_datatype.md datatype="bed" %}
>
> 5. Create a dataset collection with all `colon_multisample` datasets and rename the collection to `Colon Multisample Fragments`.
> 
>    {% snippet faqs/galaxy/collections_build_list.md name="Colon Multisample Fragments" %}
>
{: .hands_on}

# SnapATAC2 preprocessing and filtering

With our data imported and the collection built, we can now begin the {scATAC-seq} data preprocessing with SnapATAC2.

The first step is importing the datasets into an AnnData object with the tool *pp.import_data*. Next, the {TSSe} will be calculated. The {TSS} serve as a {QC} measurement to selectively filter droplets containing high-quality cells. 

> <details-title>AnnData format </details-title>
>
> - The [**AnnData**](https://anndata.readthedocs.io/en/latest/) format was initially developed for the [**Scanpy**](https://scanpy.readthedocs.io/en/stable/index.html) package and is now a widely accepted data format to store annotated data matrices in a space-efficient manner.
> 
> ![Anndata format]({% link topics/single-cell/images/scatac-standard-snapatac2/anndata_schema.svg %} "<code>AnnData</code> format stores a count matrix <code>X</code> together with annotations of observations (i.e. cells) <code>obs</code>, variables (i.e. genes) <code>var</code> and unstructured annotations <code>uns</code>.")
>
{: .details}

> <hands-on-title> Preprocessing and QC </hands-on-title>
>
> 1. {% tool [SnapATAC2 Preprocessing](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_preprocessing/snapatac2_preprocessing/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for preprocessing"*: `Import data fragment files and compute basic QC metrics, using 'pp.import_data'`
>        - {% icon param-collection %} *"Fragment file, optionally compressed with gzip or zstd"*: `Colon Multisample Fragments` (Input dataset collection)
>        - {% icon param-file %} *"A tabular file containing chromosome names and sizes"*: `chrom_sizes.txt` (Input dataset)
>        - *"Number of unique fragments threshold used to filter cells"*: `1000`
> 2. {% tool [SnapATAC2 Preprocessing](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_preprocessing/snapatac2_preprocessing/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for preprocessing"*: `Compute the TSS enrichment score (TSSe) for each cell, using 'metrics.tsse'`
>        - {% icon param-collection %} *"Annotated data matrix"*: `Colon Multisample AnnDatas` (dataset collection output of **pp.import_data** {% icon tool %})
>        - {% icon param-file %} *"GTF/GFF file containing the gene annotation"*: `gene_annotation` (Input dataset)
>
> 2. Rename the generated collection to `Colon Multisample AnnDatas TSSe`. 
>
> 3. {% tool [SnapATAC2 Plotting](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_plotting/snapatac2_plotting/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for plotting"*: `Plot the TSS enrichment vs. number of fragments density figure, using 'pl.tsse'`
>        - {% icon param-collection %} *"Annotated data matrix"*: `Colon Multisample AnnDatas TSSe` (output of **metrics.tsse** {% icon tool %})
> 4. {% icon galaxy-eye %} Inspect a few exemplary `.png` outputs of the collection
> 
> ![TSSe plots against number of unique fragments]({% link topics/single-cell/images/scatac-batch-correction-snapatac2/tsse-colon01-colon02.png %}"Examplary plots of TSSe from <code>colon_multisample_01</code> and <code>colon_multisample_02</code>")
> 
High-quality cells can be identified in the plot of {TSSe} scores against a number of unique fragments for each cell. 
>
> > <question-title></question-title>
> >
> > 1. Where are high-quality cells located in a {TSSe} plot?
> > 2. Based on these plots, how should the filter be set?
> >
> > > <solution-title></solution-title>
> > >
> > > 1. The cells in the upper right are high-quality cells, enriched for {TSS}. Fragments in the lower left represent low-quality cells or empty droplets and should be filtered out. 
> > > 2. Setting the minimum {TSSe} to 7.0 will filter out the lowest quality droplets without loosing too much data. 
> > >
> > {: .solution}
> >
> {: .question}
>
{: .hands_on}

## Filtering the count matrices

The {TSSe} distributions show that the sample quality differs substantially between batches. In order to retain as much biological data as possible, we need to use a broad filter (f.ex. minimum TSSe = 7.0). 

> <hands-on-title> Filtering </hands-on-title>
>
> 1. {% tool [SnapATAC2 Preprocessing](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_preprocessing/snapatac2_preprocessing/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for preprocessing"*: `Filter cell outliers based on counts and numbers of genes expressed, using 'pp.filter_cells'`
>        - {% icon param-collection %} *"Annotated data matrix"*: `Colon Multisample AnnDatas TSSe` (output of **metrics.tsse** {% icon tool %})
>        - *"Minimum TSS enrichemnt score required for a cell to pass filtering"*: `7.0`
>
> 2. {% tool [SnapATAC2 Preprocessing](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_preprocessing/snapatac2_preprocessing/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for preprocessing"*: `Generate cell by bin count matrix, using 'pp.add_tile_matrix'`
>        - {% icon param-collection %} *"Annotated data matrix"*: `Colon Multisample AnnDatas filtered` (output of **pp.filter_cells** {% icon tool %})
>        - *"The size of consecutive genomic regions used to record the counts"*: `5000`
>
> 3. {% tool [SnapATAC2 Preprocessing](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_preprocessing/snapatac2_preprocessing/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for preprocessing"*: `Perform feature selection, using 'pp.select_features'`
>        - {% icon param-collection %} *"Annotated data matrix"*: `Colon Multisample AnnDatas tile_matrix` (output of **pp.add_tile_matrix** {% icon tool %})
>        - *"Number of features to keep"*: `50000`
>
>    > <details-title> Bin size and features </details-title>
>    >
>    > - *pp.add_tile_matrix* divides the genome into a specified number of bins, depending on the bin size (f.ex. 5000bp). For each bin, the ATAC-seq reads of individual cells are checked to determine if a read is located in the bin. This is counted as a feature and stored under `n_vars` in the AnnData object.   
>    >    - Increasing the bin size greatly reduces compute time at the cost of some biological data. 
>    >    - For this reason, the bin size 5000bp has been selected for the colon datasets. In the [previous tutorial]( {% link topics/single-cell/tutorials/scatac-standard-processing-snapatac2/tutorial.md %}#feature-selection), the lower bin size of 500bp was chosen, since fewer cells were analyzed. 
>    > - *pp.select_features* uses the previously identified features to select the most accessible features for further analysis. 
>    >    - The parameter *"Number of features to keep"* determines the upper limit of features which can be selected. 
>    >    - Similarly to the *bin_size*, the *Number of Features to keep* can also impact downstream clustering. This was demonstrated in the [previous tutorial]( {% link topics/single-cell/tutorials/scatac-standard-processing-snapatac2/tutorial.md %}#feature-selection ).
>    {: .details}
>
> 4. {% tool [SnapATAC2 Preprocessing](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_preprocessing/snapatac2_preprocessing/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for preprocessing"*: `Compute probability of being a doublet using the scrublet algorithm, using 'pp.scrublet'`
>        - {% icon param-collection %} *"Annotated data matrix"*: `Colon Multisample AnnDatas features` (output of **pp.select_features** {% icon tool %})
>
> 5. {% tool [SnapATAC2 Preprocessing](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_preprocessing/snapatac2_preprocessing/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for preprocessing"*: `Remove doublets according to the doublet probability or doublet score, using 'pp.filter_doublets'`
>        - {% icon param-file %} *"Annotated data matrix"*: `Colon Multisample AnnDatas scrublet` (output of **pp.scrublet** {% icon tool %})
>
{: .hands_on}

# Concatenate the Collection
Before we can continue with the analysis and batch correction, we need to extract the datasets out of the collection and merge them into a single AnnData object. 

## Extracting datasets from a collection
This is achieved in two steps:
1. The first dataset is extracted from the collection using *Extract dataset*
2. Afterwards, the first dataset will be removed from the collection. This is done by extracting element identifiers and filtering the collection with the name of the first dataset. 

> <comment-title>  </comment-title>
> - It is also possible to manually remove a dataset from a collection. 
> - However, manually removing datasets can not be implemented in Galaxy workflows. In contrast the automatic method, shown here, can be represented in a workflow and is therefore much better scalable. 
{: .comment}

> <hands-on-title> Extract datasets </hands-on-title>
>
> 1. {% tool [Extract element from collection](__EXTRACT_DATASET__) %} with the following parameters:
>    - {% icon param-collection %} *"Input List"*: `Colon Multisample AnnDatas filtered_doublets` (output of **pp.filter_doublets** {% icon tool %})
>    - *"How should a dataset be selected?"*: `The first dataset`
> 2. {% tool [Extract element identifiers](toolshed.g2.bx.psu.edu/repos/iuc/collection_element_identifiers/collection_element_identifiers/0.0.2) %} with the following parameters:
>    - {% icon param-collection %} *"Dataset collection"*: `Colon Multisample AnnDatas filtered_doublets` (output of **pp.filter_doublets** {% icon tool %})
>
> 3. {% tool [Select first](Show beginning1) %} with the following parameters:
>    - *"Select first"*: `1`
>    - {% icon param-file %} *"from"*: `Element identifiers` (output of **Extract element identifiers** {% icon tool %})
> 4. {% tool [Filter collection](__FILTER_FROM_FILE__) %} with the following parameters:
>    - {% icon param-collection %} *"Input Collection"*: `Colon Multisample AnnDatas filtered_doublets` (output of **pp.filter_doublets** {% icon tool %})
>    - *"How should the elements to remove be determined?"*: `Remove if identifiers are PRESENT in file`
>        - {% icon param-file %} *"Filter out identifiers present in"*: `select_first` (output of **Select first** {% icon tool %})
> 5. {% icon galaxy-pencil %} Rename the filtered collection to `Colon Multisample 02-05`
>
{: .hands_on}

## Concatenate AnnDatas

> <hands-on-title> Concatenate </hands-on-title>
>
> 1. {% tool [Manipulate AnnData](toolshed.g2.bx.psu.edu/repos/iuc/anndata_manipulate/anndata_manipulate/0.10.3+galaxy0) %} with the following parameters:
>    - {% icon param-file %} *"Annotated data matrix"*: `colon_multisample_01` (output of **Extract dataset** {% icon tool %})
>    - *"Function to manipulate the object"*: `Concatenate along the observations axis`
>        - {% icon param-collection %} *"Annotated data matrix to add"*: `Colon Multisample 02-05` (output of **Filter collection** {% icon tool %})
>        - *"Join method"*: `Intersection of variables`
>        - *"Key to add the batch annotation to obs"*: `batch`
>
>    > <details-title>Issues with the concatenation</details-title>
>    > - Depending on the size of the datasets, this operation can take a lot of time. With the `colon_multisample` datasets, the concatenation can run for 1h. 
>    > - For even larger datasets, the allocated memory of the tool might not be enough and the operation fails. In that case, you will receive the following error message: 
>    >
>    >   ```
>    >                Fatal error: Exit code 137 ()
>    >   ```
>    > - In such a case, please report the issue. The administrators can then increase the memory limit and the job will succeed. 
>    >   
>    >   {% snippet faqs/galaxy/analysis_troubleshooting_reporting.md %}
>    >   
>    {: .details}
>
> 2. {% icon galaxy-pencil %} Rename the AnnData output to `Multisample AnnData`
> 3. {% icon galaxy-eye %} Inspect the general information of `Multisample AnnData`
>
>    > <tip-title>Inspecting AnnData objects</tip-title>
>    > * Many toolsets producing outputs in *AnnData* formats in Galaxy, provide the general information by default:
>    >    * Click on the name of the dataset in the history to expand it. The general Anndata information will be given in the expanded box.
>    >    * Alternatively, expand the dataset and click on {% icon details %}*Dataset Details*. Scroll to Job Information and inspect the Tool Standard Output. 
>    > * If a tool does not provide the general AnnData information, or a more specific query is required, the tool {% tool [Inspect AnnData](toolshed.g2.bx.psu.edu/repos/iuc/anndata_inspect/anndata_inspect/0.10.3+galaxy0) %} can also be selected.
>    {: .tip}
>
>    > ```
>    > AnnData object with n_obs × n_vars = 34372 × 606219
>    >  obs: 'n_fragment', 'frac_dup', 'frac_mito', 'tsse', 'doublet_probability', 'doublet_score', 'batch'
>    >  var: 'count-0', 'selected-0', 'count-1', 'selected-1', 'count-2', 'selected-2', 'count-3', 'selected-3', 'count-4', 'selected-4'
>    >  obsm: 'fragment_paired'
>    > ```
>    >
> 
> > <question-title></question-title>
> >
> > 1. How many colon cells are stored in this AnnData object?
> > 2. What does the 'batch' annotation represent?
> > 3. What do the different annotations for 'count-' and 'selected-' stand for?
> >
> > > <solution-title></solution-title>
> > >
> > > 1. There are 34372 cells. 
> > > 2. The cells are marked with the 'batch' annotation according to their sample number (0-4). This annotation will be used later by the batch correction algorithms to produce clusters from multiple samples. 
> > > 3. 'count' and 'selected' are variable annotations indicating the detected and selected features. The sample number (0-4) specifies the dataset which produced these annotations.
> > >
> > {: .solution}
>  {: .question}
>
{: .hands_on}

# Dimension Reduction
Now that all samples have been concatenated into a single AnnData object, the most accessible features of the combined count matrix must be selected. The previously selected features were dependent on the individual samples and can not be utilized for dimensionality reduction. Therefore the most accessible features will be selected once again and then the dimensionality of the data will be reduced through *matrix-free spectral embedding*. 

> <hands-on-title> Spectral embedding </hands-on-title>
>
> 1. {% tool [SnapATAC2 Preprocessing](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_preprocessing/snapatac2_preprocessing/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for preprocessing"*: `Perform feature selection, using 'pp.select_features'`
>        - {% icon param-file %} *"Annotated data matrix"*: `Multisample AnnData` (output of **Manipulate AnnData** {% icon tool %})
>        - *"Number of features to keep"*: `50000`
> 
> 2. {% tool [SnapATAC2 Clustering](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_clustering/snapatac2_clustering/2.6.4+galaxy1) %} with the following parameters:
>    - *"Dimension reduction and Clustering"*: `Perform dimension reduction using Laplacian Eigenmap, using 'tl.spectral'`
>        - {% icon param-file %} *"Annotated data matrix"*: `Multisample AnnData features` (output of **pp.select_features** {% icon tool %})
>        - *"distance metric"*: `cosine`
>
> 3. {% icon galaxy-pencil %} Rename the AnnData output to `Multisample AnnData spectral`
>
{: .hands_on}

## Control without batch correction
Batch effects can be visualized in an {UMAP} projection of the data. For this, the different samples are colored according to their batch annotation (obs: 'batch'). 

> <hands-on-title> UMAP projection without batch correction </hands-on-title>
>
> 1. {% tool [SnapATAC2 Clustering](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_clustering/snapatac2_clustering/2.6.4+galaxy1) %} with the following parameters:
>    - *"Dimension reduction and Clustering"*: `Compute Umap, using 'tl.umap'`
>        - {% icon param-file %} *"Annotated data matrix"*: `Multisample AnnData spectral` (output of **tl.spectral** {% icon tool %})
>
> 2. {% icon galaxy-pencil %} Rename the AnnData output to `Multisample AnnData UMAP`
> 3. {% tool [SnapATAC2 Plotting](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_plotting/snapatac2_plotting/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for plotting"*: `Plot the UMAP embedding, using 'pl.umap'`
>        - {% icon param-file %} *"Annotated data matrix"*: `Multisample AnnData UMAP` (output of **tl.umap** {% icon tool %})
>        - *"Color"*: `batch`
>        - *"Height of the plot"*: `500`
>
> 4. {% icon galaxy-pencil %} Rename the generated image to `spectral-UMAP-No Batch correction`
>
> 5. {% icon galaxy-eye %} Inspect the `.png` output
>
>  ![UMAP plot before batch correction]({% link topics/single-cell/images/scatac-batch-correction-snapatac2/batch-umap-no_harmony-spectral.png %})
> 
> > <question-title></question-title>
> >
> > 1. How are batch effects visible in this plot?
> > 2. How would a plot without batch effects look like?
> >
> > > <solution-title></solution-title>
> > >
> > > 1. Batch effects are visible as parts of the projection where the different samples are not distributed evenly. For example the large mass in the upper right corner of the plot consists of seperate groups for each batch. It is very likely, that the differences between these groups are technical artefacts, due to batch effects and do not represent "real" biological differences between the cells of different samples. 
> > > 2. A plot without batch effects does not exhibit groups of cells from a single sample. Instead, most parts of the projection would consist of evenly distributed cells from all samples.  
> > >
> > {: .solution}
>  {: .question}
>
>
{: .hands_on}

# Batch correction
After confirming that batch effects have affected our samples, we should remove them with correction algorithms. **SnapATAC2** offers three algorithms for batch correction: *Harmony*, *MNC-correct* and *Scanorama*. In order to determine the best-suited algorithm for your specific dataset, the batch correction outputs of different algorithms should be compared. 

> <details-title> Batch correction algorithms </details-title>
> - Batch correction algorithms aim to correct the cell-by-feature count matrix against batch-specific differences between samples. 
> - Batch effects can arise from many different technical sources: variation in sequencing lanes, plates, protocol, handling. Additionally, biological factors can also be regarded as batch effects, for example tissue types, species and inter-individual variation {% cite Luecken2021 %}. 
> - Many different correction algorithms have been developed, although most methods for scATAC-seq have been adapted from scRNA-seq batch removal algorithms. 
> - *Harmony* {% cite Korsunsky2019 %} is a principle component analysis (PCA)-based method which utilizes the previously generated lower-dimensional data, to assign cells into new clusters. The grouping of cells into clusters favors multi-sample clusters, in order to integrate the datasets. Linear correction factors are calculated for each batch and cluster, and the cells are moved to the corrected positions. The preceding steps are iterated, until optimal batch correction is achieved. 
>
>   ![Graphical abstract of Harmony batch correction]({% link topics/single-cell/images/harmony-graphical-abstract.png %})
>
> - *Scanorama* {% cite Hie2019 %} performs panorama stiching, to find and merge overlapping cell types. 
>
>   ![Graphical abstract of Scanorama batch correction]({% link topics/single-cell/images/scanorama-graphical-abstract.png %})
>
> - *MNC-correct* {% cite Zhang2024 %} is a modified version of a *mutual nearest neighbor* algorithm {% cite Haghverdi2018 %}. The algorithm calculates centroids for batch-specific clusters and identifies pairs of mutual nearest centroids (MNC) across batches. Correction vectors align the batches in the same plane. Additionally, *MNC-correct* can also be run iteratively, to find the most ideal corrections. 
>
>   ![Graphical abstract of MNC-correct batch correction]({% link topics/single-cell/images/mnn-graphical-abstract.png %})
>
{: .details}

We will use *Harmony* to correct for batch effects first. The other methods will be tested afterwards. 
> <hands-on-title> Batch correction and visualization</hands-on-title>
>
> 1. {% tool [SnapATAC2 Preprocessing](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_preprocessing/snapatac2_preprocessing/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for preprocessing"*: `Use harmonypy to integrate different experiments,using 'pp.harmony'`
>        - {% icon param-file %} *"Annotated data matrix"*: `Multisample AnnData UMAP` (output of **tl.umap** {% icon tool %})
>
> 2. {% tool [SnapATAC2 Clustering](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_clustering/snapatac2_clustering/2.6.4+galaxy1) %} with the following parameters:
>    - *"Dimension reduction and Clustering"*: `Compute Umap, using 'tl.umap'`
>        - {% icon param-file %} *"Annotated data matrix"*: `Multisample AnnData harmony` (output of **pp.harmony** {% icon tool %})
>        - *"Use the indicated representation in `.obsm`"*: `X_spectral_harmony`
>        - *"`adata.obs` key under which t add cluster labels"*: `umap_harmony`
>
> 2. {% icon galaxy-pencil %} Rename the AnnData output to `Multisample AnnData harmony UMAP`
>
>    > <comment-title> Key for cluster labels </comment-title>
>    > - If you add the new *UMAP-embeddings* under the key `umap_harmony`, the non-batch corrected embeddings are still stored in the AnnData object. 
>    >    - Alternatively, by leaving this parameter empty, the old embeddings will be written over. 
>    {: .comment}
> 
> 4. {% tool [SnapATAC2 Plotting](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_plotting/snapatac2_plotting/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for plotting"*: `Plot the UMAP embedding, using 'pl.umap'`
>        - {% icon param-file %} *"Annotated data matrix"*: `Multisample AnnData harmony UMAP` (output of **tl.umap** {% icon tool %})
>        - *"Color"*: `batch`
>        - *"Use the indicated representation in .obsm"*: `X_umap_harmony`
>        - *"Height of the plot"*: `500`
>
> 5. {% icon galaxy-pencil %} Rename the generated image to `spectral-UMAP-harmony`
> 
> 6. {% icon galaxy-eye %} Inspect the `.png` output
>
>  ![UMAP plot of Batch correction with Harmony]({% link topics/single-cell/images/scatac-batch-correction-snapatac2/batch-umap-harmony-spectral.png %})
> 
> > <question-title></question-title>
> >
> > 1. How has *Harmony* changed the appearance of this plot?
> > 2. Are there still parts of the plot where batch effects weren't removed?
> >
> > > <solution-title></solution-title>
> > >
> > > 1. Most of the batch effects have been successfully removed by *Harmony*. Especially the center-left groups have now been merged into a single larger group, consisting of all batches. 
> > > 2. Yes, for example in the upper-right corner batch-specific colors are not overlapping completely. However, it is possible that some samples simply contain fewer cells and are underrepresented in clusters of rare cell types. Therefore it can not be said for certain, if *Harmony* has removed all batch effects or not. 
> > >
> > {: .solution}
>  {: .question}
>
>
{: .hands_on}

> <details-title>Batch correction with Scanorama and MNC-correct </details-title>
> - Other batch correction methods can also be selected with the tool {% tool [SnapATAC2 Preprocessing](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_preprocessing/snapatac2_preprocessing/2.6.4+galaxy1) %}: *pp.mnc_correct* and *pp.scanorama_integrate* 
>   - For *MNC-correct* the *Number of iterations* can also be selected. 
> - In order to identify the optimal algorithm, it is recommended to test the different algorithms and settings.  
> - Examplary outputs of the methods *Scanorama* and *MNC-correct* are shown here:
>  ![Batch correction UMAP plots of MNC-correct with different settings and Scanorama]({% link topics/single-cell/images/scatac-batch-correction-snapatac2/mnc-correct-scanorama-umap-spectral.png %} "UMAP plots of batch correction with different methods. (a) Batch correction with MNC-correct and default settings. (b) Batch correction with Scanorama  (c) Batch correction with MNC-correct and 30 iterations.")
> 
> > <question-title></question-title>
> >
> > - Compare these plots with the output of *Harmony*. Which algorithm is best-suited for the colon datasets?
> >
> > > <solution-title></solution-title>
> > >
> > > - *Harmony* has performed the best batch integration. In that plot, the fewest single-batch groups are visible. *Scanorama* and *MNC-correct* (with the default settings) did not integrate the batches as well as *Harmony*. *MNC-correct* with 30 iterations, on the other hand, did remove a lot of batch effects and could also be used to continue the analysis. 
> > >
> > {: .solution}
>  {: .question}
>
{: .details}


# Clustering of the batch corrected samples
With the analysis can now continue with the same methods, shown in the [standard pathway]( {% link topics/single-cell/tutorials/scatac-standard-processing-snapatac2/tutorial.md %} ). The batch-corrected embeddings are now clustered and visualized with the *leiden* algorithm. 

> <hands-on-title> Leiden clustering and visualization </hands-on-title>
>
> 1. {% tool [SnapATAC2 Clustering](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_clustering/snapatac2_clustering/2.6.4+galaxy1) %} with the following parameters:
>    - *"Dimension reduction and Clustering"*: `Compute a neighborhood graph of observations, using 'pp.knn'`
>        - {% icon param-file %} *"Annotated data matrix"*: `Multisample AnnData harmony UMAP` (output of **tl.umap** {% icon tool %})
>        - *"The key for the matrix"*: `X_spectral_harmony`
>
>    > <tip-title>Key for the matrix</tip-title>
>    >
>    > - The batch correction algorithms have individual keys for the matrix. 
>    >   - *Harmony* has the key `X_spectral_harmony`
>    >   - *MNC-correct* has the key `X_spectral_mnn`
>    >   - *Scanorama* has the key `X_spectral_scanorama`
>    > - The keys are stored in the AnnData object under 'obsm' 
>    > 
>    {: .tip}
>
> 2. {% tool [SnapATAC2 Clustering](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_clustering/snapatac2_clustering/2.6.4+galaxy1) %} with the following parameters:
>    - *"Dimension reduction and Clustering"*: `Cluster cells into subgroups, using 'tl.leiden'`
>        - {% icon param-file %} *"Annotated data matrix"*: `Multisample AnnData harmony knn` (output of **pp.knn** {% icon tool %})
>        - *"Whether to use the Constant Potts Model (CPM) or modularity"*: `modularity` 
>
> 3. {% icon galaxy-pencil %} Rename the AnnData output to `Multisample AnnData harmony leiden`
> 
> 4. {% tool [SnapATAC2 Plotting](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_plotting/snapatac2_plotting/2.6.4+galaxy1) %} with the following parameters:
>    - *"Method used for plotting"*: `Plot the UMAP embedding, using 'pl.umap'`
>        - {% icon param-file %} *"Annotated data matrix"*: `anndata_out` (output of **tl.leiden** {% icon tool %})
>        - *"Color"*: `leiden`
>        - *"Use the indicated representation in .obsm"*: `X_umap_harmony`
>        - *"Height of the plot"*: `500`
>
> 5. {% icon galaxy-pencil %} Rename the generated image to `spectral-UMAP-harmony-leiden`
>
> 6. {% icon galaxy-eye %} Inspect the `.png` output
>
>  ![UMAP plot of Batch-corrected leiden clusters]({% link topics/single-cell/images/scatac-batch-correction-snapatac2/batch-umap-harmony-leiden.png %})
>
{: .hands_on}

After integrating the different datasets and clustering the cells, the scATAC-seq analysis can now continue with downstream analysis. As part of the downstream analysis, the clusters can be [annotated]( {% link topics/single-cell/tutorials/scatac-standard-processing-snapatac2/tutorial.md %}#cell-cluster-annotation ) and differential peak analysis can be performed. 
> <comment-title></comment-title>
>
> The **SnapATAC2** tools for differential peak analysis are already accessible on Galaxy. However, there are no GTN trainings available yet. Until such a tutorial is uploaded, you can visit the **SnapATAC2** documentation for a [tutorial on differential peak analysis](https://kzhang.org/SnapATAC2/version/2.6/tutorials/diff.html). 
>
> The tools are available in Galaxy under {% tool [SnapATAC2 Clustering](toolshed.g2.bx.psu.edu/repos/iuc/snapatac2_peaks_and_motif/snapatac2_peaks_and_motif/2.6.4+galaxy1) %}. 
> 
{: .comment}


# Conclusion
{% icon congratulations %} Well done, you’ve made it to the end! You might want to consult your results with this [control history](https://usegalaxy.eu/u/timonschlegel/h/multisample-batch-correction-with-harmony-and-snapatac2), or check out the [full workflow](https://usegalaxy.eu/u/timonschlegel/w/multisample-batch-correction-with-snapatac2-and-harmony) for this tutorial.

In this tutorial we have integrated five {scATAC-seq} colon samples. To achieve this, we have assembled a well-scalable Galaxy workflow and have compared different batch integration algorithms, to identify the best-suited method for our data. Finally, we have assigned the cells into clusters, to prepare the data for downstream analysis. 

![SnapATAC2 batch correction pipeline]({% link topics/single-cell/images/scatac-batch-correction-snapatac2/Batch-correction-pipeline-overview.png %})