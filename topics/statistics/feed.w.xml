<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xml" href="https://training.galaxyproject.org/training-material/feed-widget.xslt.xml"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <generator uri="https://jekyllrb.com/">Jekyll</generator>
  <link href="https://training.galaxyproject.org/training-material/topics/statistics/feed.xml" rel="self"/>
  <link rel="alternate" href="https://training.galaxyproject.org/training-material/topics/statistics/"/>
  <updated>2024-10-28T12:27:43+00:00</updated>
  <id>https://training.galaxyproject.org/training-material/topics/statistics/feed.xml</id>
  <title>Statistics and machine learning</title>
  <subtitle>Recently added tutorials, slides, FAQs, and events in the statistics topic</subtitle>
  <logo>https://training.galaxyproject.org/training-material/assets/images/GTN-60px.png</logo>
  <entry>
    <title>üõ†Ô∏è Ludwig - Image recognition model - MNIST</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/galaxy-ludwig/workflows/main_workflow.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/galaxy-ludwig/workflows/main_workflow.html</id>
    <updated>2024-10-28T12:27:43+00:00</updated>
    <category term="workflows"/>
    <category term="statistics"/>
    <category term="Ludwig"/>
    <category term="MNIST"/>
    <category term="imagerecognition"/>
    <summary>Deep Learning image classifier model</summary>
    <author>
      <name>Paulo Cilas Morais Lyra Junior</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/paulocilasjr/</uri>
    </author>
    <author>
      <name>Junhao Qiu</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/qchiujunhao/</uri>
    </author>
    <author>
      <name>Jeremy Goecks</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/jgoecks/</uri>
    </author>
  </entry>
  <entry>
    <title>üìö Train and Test a Deep learning image classifier with Galaxy-Ludwig</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/galaxy-ludwig/tutorial.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/galaxy-ludwig/tutorial.html</id>
    <updated>2024-10-28T12:27:43+00:00</updated>
    <category term="statistics"/>
    <category term="MNIST"/>
    <category term="Deep learning"/>
    <category term="Ludwig"/>
    <summary>

</summary>
    <author>
      <name>Paulo Cilas Morais Lyra Junior</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/paulocilasjr/</uri>
    </author>
    <author>
      <name>Junhao Qiu</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/qchiujunhao/</uri>
    </author>
    <author>
      <name>Jeremy Goecks</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/jgoecks/</uri>
    </author>
    <contributor>
      <name>Saskia Hiltemann</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/shiltemann/</uri>
    </contributor>
    <contributor>
      <name>Paulo Cilas Morais Lyra Junior</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/paulocilasjr/</uri>
    </contributor>
    <contributor>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </contributor>
  </entry>
  <entry>
    <title>üé• Recording of Deep Learning (Part 3) - Convolutional neural networks (CNN)</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/CNN/recordings/#tutorial-recording-5-october-2024"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/CNN/recordings/#tutorial-recording-5-october-2024</id>
    <updated>2024-10-05T00:00:00+00:00</updated>
    <category term="statistics"/>
    <summary>A 45M long recording is now available.
</summary>
    <author>
      <name>Michelle Terese Savage</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/hujambo-dunia/</uri>
    </author>
  </entry>
  <entry>
    <title>üé• Recording of Fine tune large protein model (ProtTrans) using HuggingFace</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/fine_tuning_protTrans/recordings/#tutorial-recording-29-august-2024"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/fine_tuning_protTrans/recordings/#tutorial-recording-29-august-2024</id>
    <updated>2024-08-29T00:00:00+00:00</updated>
    <category term="statistics"/>
    <category term="interactive-tools"/>
    <category term="machine-learning"/>
    <category term="deep-learning"/>
    <category term="jupyter-lab"/>
    <category term="fine-tuning"/>
    <category term="dephosphorylation-site-prediction"/>
    <summary>A 35M long recording is now available.
</summary>
    <author>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </author>
  </entry>
  <entry>
    <title>üé• Recording of Classification in Machine Learning</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/classification_machinelearning/recordings/#tutorial-recording-29-august-2024"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/classification_machinelearning/recordings/#tutorial-recording-29-august-2024</id>
    <updated>2024-08-29T00:00:00+00:00</updated>
    <category term="statistics"/>
    <summary>A 1H7M long recording is now available.
</summary>
    <author>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </author>
  </entry>
  <entry>
    <title>üìö Fine tune large protein model (ProtTrans) using HuggingFace</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/fine_tuning_protTrans/tutorial.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/fine_tuning_protTrans/tutorial.html</id>
    <updated>2024-06-17T12:35:27+00:00</updated>
    <category term="statistics"/>
    <category term="interactive-tools"/>
    <category term="machine-learning"/>
    <category term="deep-learning"/>
    <category term="jupyter-lab"/>
    <category term="fine-tuning"/>
    <category term="dephosphorylation-site-prediction"/>
    <summary>The advent of large language models has transformed the field of natural language processing, enabling machines to comprehend and generate human-like language with unprecedented accuracy. Pre-trained language models, such as BERT, RoBERTa, and their variants, have achieved state-of-the-art results on various tasks, from sentiment analysis and question answering to language translation and text classification. Moreover, the emergence of transformer-based models, such as Generative Pre-trained Transformer (GPT) and its variants, has enabled the creation of highly advanced language models to generate coherent and context-specific text. The latest iteration of these models, ChatGPT, has taken the concept of conversational AI to new heights, allowing users to engage in natural-sounding conversations with machines. However, despite their impressive capabilities, these models are imperfect, and their performance can be significantly improved through fine-tuning. Fine-tuning involves adapting the pre-trained model to a specific task or domain by adjusting its parameters to optimise its performance on a target dataset. This process allows the model to learn task-specific features and relationships that may not be captured by the pre-trained model alone, resulting in highly accurate and specialised language models that can be applied to a wide range of applications. In this tutorial, we will discuss and fine-tune large language model trained on protein sequences ProtT5, exploring the benefits and challenges of this approach, as well as the various techniques and strategies such as low ranking adaptations (LoRA) that can be employed to fit large language models with billions of parameters on regular GPUs. Protein large language models (LLMs) represent a significant advancement in Bioinformatics, leveraging the power of deep learning to understand and predict the behaviour of proteins at an unprecedented scale. These models, exemplified by the ProtTrans suite, are inspired by natural language processing (NLP) techniques, applying similar methodologies to biological sequences. ProtTrans models, including BERT and T5 adaptations, are trained on vast datasets of protein sequences from databases such as UniProt and BFD, storing millions of protein sequences and enabling them to capture the complex patterns and functions encoded within amino acid sequences. By interpreting these sequences much like languages, protein LLMs offer transformative potential in drug discovery, disease understanding, and synthetic biology, bridging the gap between computational predictions and experimental biology. In this tutorial, we will fine-tune the ProtT5 pre-trained model for dephosphorylation site prediction, a binary classification task.
</summary>
    <author>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </author>
    <contributor>
      <name>Teresa M√ºller</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/teresa-m/</uri>
    </contributor>
    <contributor>
      <name>Saskia Hiltemann</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/shiltemann/</uri>
    </contributor>
    <contributor>
      <name>Helena Rasche</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/hexylena/</uri>
    </contributor>
    <contributor>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </contributor>
    <contributor>
      <name>Bj√∂rn Gr√ºning</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/bgruening/</uri>
    </contributor>
    <contributor>
      <name>Michelle Terese Savage</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/hujambo-dunia/</uri>
    </contributor>
  </entry>
  <entry>
    <title>üõ†Ô∏è ml_regression</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/regression_machinelearning/workflows/ml_regression.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/regression_machinelearning/workflows/ml_regression.html</id>
    <updated>2024-05-21T10:39:24+00:00</updated>
    <category term="workflows"/>
    <category term="statistics"/>
    <category term="regression"/>
    <category term="ml"/>
    <summary>Regression in Machine Learning</summary>
    <author>
      <name>Anup Kumar</name>
    </author>
  </entry>
  <entry>
    <title>üõ†Ô∏è Intro_To_CNN_v1.0.11.0</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/CNN/workflows/Intro_To_CNN_v1_0_11_0.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/CNN/workflows/Intro_To_CNN_v1_0_11_0.html</id>
    <updated>2023-12-11T10:30:45+00:00</updated>
    <category term="workflows"/>
    <category term="statistics"/>
    <summary/>
    <author>
      <name>Kaivan Kamali</name>
    </author>
  </entry>
  <entry>
    <title>üõ†Ô∏è Intro_To_RNN_v1_0_10_0</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/RNN/workflows/Intro_To_RNN_v1_0_10_0.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/RNN/workflows/Intro_To_RNN_v1_0_10_0.html</id>
    <updated>2023-10-17T08:58:40+00:00</updated>
    <category term="workflows"/>
    <category term="statistics"/>
    <summary/>
    <author>
      <name>Kaivan Kamali</name>
    </author>
  </entry>
  <entry>
    <title>üõ†Ô∏è Intro_To_FNN_v1_0_10_0</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/FNN/workflows/Intro_To_FNN_v1_0_10_0.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/FNN/workflows/Intro_To_FNN_v1_0_10_0.html</id>
    <updated>2023-10-17T08:58:40+00:00</updated>
    <category term="workflows"/>
    <category term="statistics"/>
    <category term="ml"/>
    <category term="fnn"/>
    <summary/>
    <author>
      <name>Kaivan Kamali</name>
    </author>
  </entry>
  <entry>
    <title>üìö Supervised Learning with Hyperdimensional Computing</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/hyperdimensional_computing/tutorial.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/hyperdimensional_computing/tutorial.html</id>
    <updated>2023-04-28T20:05:26+00:00</updated>
    <category term="statistics"/>
    <summary>chopin2 (Cumbo et al. 2020) implements a domain-agnostic supervised classification method based on the hyperdimensional (HD) computing paradigm. It is an open-source tool and its code is available on GitHub at https://github.com/cumbof/chopin2.
</summary>
    <author>
      <name>Fabio Cumbo</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/cumbof/</uri>
    </author>
    <contributor>
      <name>Bj√∂rn Gr√ºning</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/bgruening/</uri>
    </contributor>
    <contributor>
      <name>Helena Rasche</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/hexylena/</uri>
    </contributor>
    <contributor>
      <name>Fabio Cumbo</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/cumbof/</uri>
    </contributor>
    <contributor>
      <name>Daniel Blankenberg</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/blankenberg/</uri>
    </contributor>
  </entry>
  <entry>
    <title>üõ†Ô∏è gpu_jupytool</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/gpu_jupyter_lab/workflows/gpu_jupyterlab_as_jupytool.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/gpu_jupyter_lab/workflows/gpu_jupyterlab_as_jupytool.html</id>
    <updated>2023-01-18T08:59:15+00:00</updated>
    <category term="workflows"/>
    <category term="statistics"/>
    <summary/>
  </entry>
  <entry>
    <title>üìö A Docker-based interactive Jupyterlab powered by GPU for artificial intelligence in Galaxy</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/gpu_jupyter_lab/tutorial.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/gpu_jupyter_lab/tutorial.html</id>
    <updated>2022-04-06T17:18:13+00:00</updated>
    <category term="statistics"/>
    <category term="interactive-tools"/>
    <category term="machine-learning"/>
    <category term="deep-learning"/>
    <category term="jupyter-lab"/>
    <category term="image-segmentation"/>
    <category term="protein-3D-structure"/>
    <summary>Jupyterlab is a popular integrated development environment (IDE) for a variety of tasks in data science such as prototyping analyses, creating meaningful plots, data manipulation and preprocessing. Python is one of the most used languages in such an environment. Given the usefulness of Jupyterlab, more importantly in online platforms, a robust Jupyterlab notebook application has been developed that is powered by GPU acceleration and contains numerous packages such as Pandas, Numpy, Scipy, Scikit-learn, Tensorflow, ONNX to support modern data science projects. It has been developed as an interactive Galaxy tool that runs on an isolated docker container. The docker container has been built using nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu20.04 as the base container. Moreover, a Galaxy tool ( run_jupyter_job) can be executed using Bioblend which uses Galaxy‚Äôs remote job handling for long-running machine learning and deep learning training. The training happens remotely on a Galaxy cluster and the outcome datasets such as the trained models, tabular files and so on are saved in a Galaxy history for further use.
</summary>
    <author>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </author>
    <contributor>
      <name>Saskia Hiltemann</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/shiltemann/</uri>
    </contributor>
    <contributor>
      <name>Helena Rasche</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/hexylena/</uri>
    </contributor>
    <contributor>
      <name>Kaivan Kamali</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/kxk302/</uri>
    </contributor>
    <contributor>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </contributor>
    <contributor>
      <name>Bj√∂rn Gr√ºning</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/bgruening/</uri>
    </contributor>
  </entry>
  <entry>
    <title>üé• Recording of Image classification in Galaxy with fruit 360 dataset</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/fruit_360/recordings/#tutorial-recording-19-january-2022"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/fruit_360/recordings/#tutorial-recording-19-january-2022</id>
    <updated>2022-01-19T00:00:00+00:00</updated>
    <category term="statistics"/>
    <summary>A 1H long recording is now available.
</summary>
    <author>
      <name>Kaivan Kamali</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/kxk302/</uri>
    </author>
  </entry>
  <entry>
    <title>üõ†Ô∏è fruit_360</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/fruit_360/workflows/fruit_360.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/fruit_360/workflows/fruit_360.html</id>
    <updated>2021-12-01T15:54:59+00:00</updated>
    <category term="workflows"/>
    <category term="statistics"/>
    <summary>Image classification with fruit 360 dataset</summary>
    <author>
      <name>Kaivan Kamali</name>
    </author>
  </entry>
  <entry>
    <title>üñºÔ∏è Image classification in Galaxy with fruit 360 dataset</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/fruit_360/slides.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/fruit_360/slides.html</id>
    <updated>2021-12-01T15:54:59+00:00</updated>
    <category term="statistics"/>
    <summary>What is a convolutional neural network (CNN)?
</summary>
    <author>
      <name>Kaivan Kamali</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/kxk302/</uri>
    </author>
    <contributor>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </contributor>
    <contributor>
      <name>Kaivan Kamali</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/kxk302/</uri>
    </contributor>
    <contributor>
      <name>Helena Rasche</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/hexylena/</uri>
    </contributor>
  </entry>
  <entry>
    <title>üìö Image classification in Galaxy with fruit 360 dataset</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/fruit_360/tutorial.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/fruit_360/tutorial.html</id>
    <updated>2021-12-01T15:54:59+00:00</updated>
    <category term="statistics"/>
    <summary>The classification of fruits and vegetables offers many useful applications such as

</summary>
    <author>
      <name>Kaivan Kamali</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/kxk302/</uri>
    </author>
    <contributor>
      <name>Saskia Hiltemann</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/shiltemann/</uri>
    </contributor>
    <contributor>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </contributor>
    <contributor>
      <name>Kaivan Kamali</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/kxk302/</uri>
    </contributor>
    <contributor>
      <name>Helena Rasche</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/hexylena/</uri>
    </contributor>
  </entry>
  <entry>
    <title>üñºÔ∏è Feedforward neural networks (FNN) 
 Deep Learning - Part 1</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/FNN/slides.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/FNN/slides.html</id>
    <updated>2021-06-02T10:53:09+00:00</updated>
    <category term="statistics"/>
    <summary>What is an artificial neural network?
</summary>
    <author>
      <name>Kaivan Kamali</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/kxk302/</uri>
    </author>
    <contributor>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </contributor>
    <contributor>
      <name>Kaivan Kamali</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/kxk302/</uri>
    </contributor>
    <contributor>
      <name>Helena Rasche</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/hexylena/</uri>
    </contributor>
    <contributor>
      <name>Crist√≥bal Gallardo</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/gallardoalba/</uri>
    </contributor>
    <contributor>
      <name>Saskia Hiltemann</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/shiltemann/</uri>
    </contributor>
  </entry>
  <entry>
    <title>üñºÔ∏è Recurrent neural networks (RNN) 
 Deep Learning - Part 2</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/RNN/slides.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/RNN/slides.html</id>
    <updated>2021-05-31T15:17:18+00:00</updated>
    <category term="statistics"/>
    <summary>What is a recurrent neural network (RNN)?
</summary>
    <author>
      <name>Kaivan Kamali</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/kxk302/</uri>
    </author>
    <contributor>
      <name>Saskia Hiltemann</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/shiltemann/</uri>
    </contributor>
    <contributor>
      <name>Kaivan Kamali</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/kxk302/</uri>
    </contributor>
  </entry>
  <entry>
    <title>üìö Introduction to Machine Learning using R</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/intro-to-ml-with-r/tutorial.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/intro-to-ml-with-r/tutorial.html</id>
    <updated>2021-05-21T15:04:43+00:00</updated>
    <category term="statistics"/>
    <category term="interactive-tools"/>
    <summary>This is an Introduction to Machine Learning in R, in which you‚Äôll learn the basics of unsupervised learning for pattern recognition and supervised learning for prediction. At the end of this workshop, we hope that you will:
</summary>
    <author>
      <name>Fotis E. Psomopoulos</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/fpsom/</uri>
    </author>
    <contributor>
      <name>Helena Rasche</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/hexylena/</uri>
    </contributor>
    <contributor>
      <name>Anthony Bretaudeau</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/abretaud/</uri>
    </contributor>
    <contributor>
      <name>Saskia Hiltemann</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/shiltemann/</uri>
    </contributor>
    <contributor>
      <name>Bj√∂rn Gr√ºning</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/bgruening/</uri>
    </contributor>
    <contributor>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </contributor>
    <contributor>
      <name>Nate Coraor</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/natefoo/</uri>
    </contributor>
    <contributor>
      <name>Martin ƒåech</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/martenson/</uri>
    </contributor>
  </entry>
  <entry>
    <title>üñºÔ∏è Convolutional neural networks (CNN) 
 Deep Learning - Part 3</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/CNN/slides.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/CNN/slides.html</id>
    <updated>2021-05-19T07:55:00+00:00</updated>
    <category term="statistics"/>
    <summary>What is a convolutional neural network (CNN)?
</summary>
    <author>
      <name>Kaivan Kamali</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/kxk302/</uri>
    </author>
    <contributor>
      <name>Simon Bray</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/simonbray/</uri>
    </contributor>
    <contributor>
      <name>Bj√∂rn Gr√ºning</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/bgruening/</uri>
    </contributor>
    <contributor>
      <name>Martin ƒåech</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/martenson/</uri>
    </contributor>
    <contributor>
      <name>Helena Rasche</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/hexylena/</uri>
    </contributor>
    <contributor>
      <name>Crist√≥bal Gallardo</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/gallardoalba/</uri>
    </contributor>
    <contributor>
      <name>Saskia Hiltemann</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/shiltemann/</uri>
    </contributor>
  </entry>
  <entry>
    <title>üõ†Ô∏è papaa@0.1.9_PI3K_OG_model_tutorial</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/aberrant_pi3k_pathway_analysis/workflows/main_workflow.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/aberrant_pi3k_pathway_analysis/workflows/main_workflow.html</id>
    <updated>2021-05-06T10:06:35+00:00</updated>
    <category term="workflows"/>
    <category term="statistics"/>
    <category term="classification"/>
    <category term="ml"/>
    <category term="cancer"/>
    <summary>PanCancer Aberrant Pathway Activity Analysis: PI3K example</summary>
  </entry>
  <entry>
    <title>üìö PAPAA PI3K_OG: PanCancer Aberrant Pathway Activity Analysis</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/aberrant_pi3k_pathway_analysis/tutorial.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/aberrant_pi3k_pathway_analysis/tutorial.html</id>
    <updated>2021-05-06T10:06:35+00:00</updated>
    <category term="statistics"/>
    <category term="Machine learning"/>
    <category term="Pan-cancer"/>
    <category term="cancer biomarkers"/>
    <category term="oncogenes and tumor suppressor genes"/>
    <summary>Signaling pathways are among the most commonly altered across different tumor types. Many tumors possess at least one driver alteration and nearly half of such alterations are potentially targeted by currently available drugs. A recent study in TCGA tumors has identified patterns of somatic variations and mechanisms in 10 canonical pathways

</summary>
    <author>
      <name>Vijay</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/nvk747/</uri>
    </author>
    <author>
      <name>Daniel Blankenberg</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/blankenberg/</uri>
    </author>
    <contributor>
      <name>Saskia Hiltemann</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/shiltemann/</uri>
    </contributor>
    <contributor>
      <name>Vijay</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/nvk747/</uri>
    </contributor>
    <contributor>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </contributor>
    <contributor>
      <name>Helena Rasche</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/hexylena/</uri>
    </contributor>
    <contributor>
      <name>B√©r√©nice Batut</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/bebatut/</uri>
    </contributor>
  </entry>
  <entry>
    <title>üìö Deep Learning (Part 1) - Feedforward neural networks (FNN)</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/FNN/tutorial.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/FNN/tutorial.html</id>
    <updated>2021-04-28T06:47:19+00:00</updated>
    <category term="statistics"/>
    <summary>Artificial neural networks are a machine learning discipline roughly inspired by how neurons in a

</summary>
    <author>
      <name>Kaivan Kamali</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/kxk302/</uri>
    </author>
    <contributor>
      <name>Helena Rasche</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/hexylena/</uri>
    </contributor>
    <contributor>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </contributor>
    <contributor>
      <name>Saskia Hiltemann</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/shiltemann/</uri>
    </contributor>
    <contributor>
      <name>Kaivan Kamali</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/kxk302/</uri>
    </contributor>
    <contributor>
      <name>Nate Coraor</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/natefoo/</uri>
    </contributor>
  </entry>
  <entry>
    <title>üìö Deep Learning (Part 3) - Convolutional neural networks (CNN)</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/CNN/tutorial.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/CNN/tutorial.html</id>
    <updated>2021-04-19T17:54:38+00:00</updated>
    <category term="statistics"/>
    <summary>Artificial neural networks are a machine learning discipline that have been successfully applied to problems

</summary>
    <author>
      <name>Kaivan Kamali</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/kxk302/</uri>
    </author>
    <contributor>
      <name>Teresa M√ºller</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/teresa-m/</uri>
    </contributor>
    <contributor>
      <name>Helena Rasche</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/hexylena/</uri>
    </contributor>
    <contributor>
      <name>Saskia Hiltemann</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/shiltemann/</uri>
    </contributor>
    <contributor>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </contributor>
    <contributor>
      <name>Bj√∂rn Gr√ºning</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/bgruening/</uri>
    </contributor>
    <contributor>
      <name>Kaivan Kamali</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/kxk302/</uri>
    </contributor>
    <contributor>
      <name>qiagu</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/qiagu/</uri>
    </contributor>
    <contributor>
      <name>Martin ƒåech</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/martenson/</uri>
    </contributor>
  </entry>
  <entry>
    <title>üõ†Ô∏è Simtext training workflow</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/text-mining_simtext/workflows/main_workflow.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/text-mining_simtext/workflows/main_workflow.html</id>
    <updated>2021-04-05T18:58:54+00:00</updated>
    <category term="workflows"/>
    <category term="statistics"/>
    <category term="text-mining"/>
    <category term="visualisation"/>
    <category term="PubMed"/>
    <category term="PubTator"/>
    <summary>In this workflow the similarity among set of search queries (e.g. genes) is analyzed based on the associated vocabulary in PubMed. The last tool is an interactive tool that enables the inspection of the data.</summary>
    <author>
      <name/>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame//</uri>
    </author>
  </entry>
  <entry>
    <title>üìö Text-mining with the SimText toolset</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/text-mining_simtext/tutorial.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/text-mining_simtext/tutorial.html</id>
    <updated>2021-04-05T18:58:54+00:00</updated>
    <category term="statistics"/>
    <category term="interactive-tools"/>
    <summary>Literature exploration in PubMed on a large number of biomedical entities (e.g., genes, diseases, or experiments) can be time-consuming and challenging, especially when assessing associations between entities. Here, we use SimText, a toolset for literature research that allows you to collect text from PubMed for any given set of biomedical entities, extract associated terms, and analyze similarities among them and their key characteristics in an interactive tool.
</summary>
    <author>
      <name>Marie Gramm</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/mgramm1/</uri>
    </author>
    <author>
      <name>Dennis Lal group</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/dlalgroup/</uri>
    </author>
    <author>
      <name>Daniel Blankenberg</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/blankenberg/</uri>
    </author>
    <contributor>
      <name>Saskia Hiltemann</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/shiltemann/</uri>
    </contributor>
    <contributor>
      <name>Helena Rasche</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/hexylena/</uri>
    </contributor>
    <contributor>
      <name>dlal-group</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/dlal-group/</uri>
    </contributor>
    <contributor>
      <name>Bj√∂rn Gr√ºning</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/bgruening/</uri>
    </contributor>
    <contributor>
      <name>Martin ƒåech</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/martenson/</uri>
    </contributor>
  </entry>
  <entry>
    <title>üìö Deep Learning (Part 2) - Recurrent neural networks (RNN)</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/RNN/tutorial.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/RNN/tutorial.html</id>
    <updated>2021-02-23T08:46:07+00:00</updated>
    <category term="statistics"/>
    <summary>Artificial neural networks are a machine learning discipline roughly inspired by how neurons in a

</summary>
    <author>
      <name>Kaivan Kamali</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/kxk302/</uri>
    </author>
    <contributor>
      <name>Helena Rasche</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/hexylena/</uri>
    </contributor>
    <contributor>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </contributor>
    <contributor>
      <name>Saskia Hiltemann</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/shiltemann/</uri>
    </contributor>
    <contributor>
      <name>Enis Afgan</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/afgane/</uri>
    </contributor>
    <contributor>
      <name>Kaivan Kamali</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/kxk302/</uri>
    </contributor>
    <contributor>
      <name>qiagu</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/qiagu/</uri>
    </contributor>
  </entry>
  <entry>
    <title>üé• Recording of Introduction to Machine Learning using R</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/intro-to-ml-with-r/recordings/#tutorial-recording-15-february-2021"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/intro-to-ml-with-r/recordings/#tutorial-recording-15-february-2021</id>
    <updated>2021-02-15T00:00:00+00:00</updated>
    <category term="statistics"/>
    <category term="interactive-tools"/>
    <summary>A 1H30M long recording is now available.
</summary>
    <author>
      <name>Fotis E. Psomopoulos</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/fpsom/</uri>
    </author>
  </entry>
  <entry>
    <title>üé• Recording of Classification in Machine Learning</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/classification_machinelearning/recordings/#tutorial-recording-15-february-2021"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/classification_machinelearning/recordings/#tutorial-recording-15-february-2021</id>
    <updated>2021-02-15T00:00:00+00:00</updated>
    <category term="statistics"/>
    <summary>A 1H50M long recording is now available.
</summary>
    <author>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </author>
  </entry>
  <entry>
    <title>üé• Recording of Deep Learning (Part 2) - Recurrent neural networks (RNN)</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/RNN/recordings/#tutorial-recording-15-february-2021"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/RNN/recordings/#tutorial-recording-15-february-2021</id>
    <updated>2021-02-15T00:00:00+00:00</updated>
    <category term="statistics"/>
    <summary>A 50M long recording is now available.
</summary>
    <author>
      <name>Kaivan Kamali</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/kxk302/</uri>
    </author>
  </entry>
  <entry>
    <title>üé• Recording of Regression in Machine Learning</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/regression_machinelearning/recordings/#tutorial-recording-15-february-2021"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/regression_machinelearning/recordings/#tutorial-recording-15-february-2021</id>
    <updated>2021-02-15T00:00:00+00:00</updated>
    <category term="statistics"/>
    <summary>A 1H29M long recording is now available.
</summary>
    <author>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </author>
  </entry>
  <entry>
    <title>üé• Recording of Deep Learning (Part 1) - Feedforward neural networks (FNN)</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/FNN/recordings/#tutorial-recording-15-february-2021"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/FNN/recordings/#tutorial-recording-15-february-2021</id>
    <updated>2021-02-15T00:00:00+00:00</updated>
    <category term="statistics"/>
    <summary>A 1H10M long recording is now available.
</summary>
    <author>
      <name>Kaivan Kamali</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/kxk302/</uri>
    </author>
  </entry>
  <entry>
    <title>üé• Recording of Deep Learning (Part 3) - Convolutional neural networks (CNN)</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/CNN/recordings/#tutorial-recording-15-february-2021"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/CNN/recordings/#tutorial-recording-15-february-2021</id>
    <updated>2021-02-15T00:00:00+00:00</updated>
    <category term="statistics"/>
    <summary>A 1H long recording is now available.
</summary>
    <author>
      <name>Kaivan Kamali</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/kxk302/</uri>
    </author>
  </entry>
  <entry>
    <title>üõ†Ô∏è Intro_To_Deep_Learning</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/intro_deep_learning/workflows/Intro_To_Deep_Learning.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/intro_deep_learning/workflows/Intro_To_Deep_Learning.html</id>
    <updated>2021-01-26T14:40:29+00:00</updated>
    <category term="workflows"/>
    <category term="statistics"/>
    <category term="deeplearning"/>
    <category term="ml"/>
    <summary>Introduction to Deep Learning</summary>
  </entry>
  <entry>
    <title>üõ†Ô∏è Clustering in Machine Learning</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/clustering_machinelearning/workflows/clustering.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/clustering_machinelearning/workflows/clustering.html</id>
    <updated>2020-05-08T17:04:18+00:00</updated>
    <category term="workflows"/>
    <category term="statistics"/>
    <category term="clustering"/>
    <category term="ml"/>
    <summary>Clustering in Machine Learning</summary>
  </entry>
  <entry>
    <title>üìö Clustering in Machine Learning</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/clustering_machinelearning/tutorial.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/clustering_machinelearning/tutorial.html</id>
    <updated>2020-05-08T17:04:18+00:00</updated>
    <category term="statistics"/>
    <summary>The goal of unsupervised learning is to discover hidden patterns in any unlabeled data. One of the approaches to unsupervised learning is clustering. In this tutorial, we will discuss clustering, its types and a few algorithms to find clusters in data. Clustering groups data points based on their similarities. Each group is called a cluster and contains data points with high similarity and low similarity with data points in other clusters. In short, data points of a cluster are more similar to each other than they are to the data points of other clusters. The goal of clustering is to divide a set of data points in such a way that similar items fall into the same cluster, whereas dissimilar data points fall in different clusters. Further in this tutorial, we will discuss ideas on how to choose different metrics of similarity  between data points and use them in different clustering algorithms.
</summary>
    <author>
      <name>Alireza Khanteymoori</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/khanteymoori/</uri>
    </author>
    <author>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </author>
    <contributor>
      <name>Saskia Hiltemann</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/shiltemann/</uri>
    </contributor>
    <contributor>
      <name>Bj√∂rn Gr√ºning</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/bgruening/</uri>
    </contributor>
    <contributor>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </contributor>
    <contributor>
      <name>Alireza Khanteymoori</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/khanteymoori/</uri>
    </contributor>
    <contributor>
      <name>M√©lanie Petera</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/melpetera/</uri>
    </contributor>
  </entry>
  <entry>
    <title>üõ†Ô∏è ml_classification</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/classification_machinelearning/workflows/ml_classification.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/classification_machinelearning/workflows/ml_classification.html</id>
    <updated>2020-04-30T14:15:23+00:00</updated>
    <category term="workflows"/>
    <category term="statistics"/>
    <category term="classification"/>
    <category term="ml"/>
    <category term="cheminformatics"/>
    <summary>Classification in Machine Learning</summary>
    <author>
      <name>Anup Kumar</name>
    </author>
  </entry>
  <entry>
    <title>üìö Classification in Machine Learning</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/classification_machinelearning/tutorial.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/classification_machinelearning/tutorial.html</id>
    <updated>2020-04-30T14:15:23+00:00</updated>
    <category term="statistics"/>
    <summary>In this tutorial you will learn how to apply Galaxy tools to solve classification problems. First, we will introduce classification briefly, and then examine logistic regression, which is an example of a linear classifier. Next, we will discuss the nearest neighbor classifier, which is a simple but nonlinear classifier. Then advanced classifiers, such as support vector machines, random forest and ensemble classifiers will be introduced and applied. Furthermore, we will show how to visualize the results in each step.
</summary>
    <author>
      <name>Alireza Khanteymoori</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/khanteymoori/</uri>
    </author>
    <author>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </author>
    <author>
      <name>Simon Bray</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/simonbray/</uri>
    </author>
    <contributor>
      <name>Teresa M√ºller</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/teresa-m/</uri>
    </contributor>
    <contributor>
      <name>Saskia Hiltemann</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/shiltemann/</uri>
    </contributor>
    <contributor>
      <name>Bj√∂rn Gr√ºning</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/bgruening/</uri>
    </contributor>
    <contributor>
      <name>Helena Rasche</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/hexylena/</uri>
    </contributor>
    <contributor>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </contributor>
    <contributor>
      <name>Alireza Khanteymoori</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/khanteymoori/</uri>
    </contributor>
    <contributor>
      <name>Simon Bray</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/simonbray/</uri>
    </contributor>
  </entry>
  <entry>
    <title>üìö Introduction to deep learning</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/intro_deep_learning/tutorial.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/intro_deep_learning/tutorial.html</id>
    <updated>2020-03-26T12:17:27+00:00</updated>
    <category term="statistics"/>
    <summary>Introduction
</summary>
    <author>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </author>
    <author>
      <name>Alireza Khanteymoori</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/khanteymoori/</uri>
    </author>
    <contributor>
      <name>Saskia Hiltemann</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/shiltemann/</uri>
    </contributor>
    <contributor>
      <name>Fabio Cumbo</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/cumbof/</uri>
    </contributor>
    <contributor>
      <name>Bj√∂rn Gr√ºning</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/bgruening/</uri>
    </contributor>
  </entry>
  <entry>
    <title>üìö Regression in Machine Learning</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/regression_machinelearning/tutorial.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/regression_machinelearning/tutorial.html</id>
    <updated>2020-01-25T09:55:53+00:00</updated>
    <category term="statistics"/>
    <summary>In this tutorial you will learn how to use Galaxy tools to solve regression problems. First, we will introduce the concept of regression briefly, and then examine linear regression, which models the relationship between a target variable and some explanatory variables (also known as independent variables). Next, we will discuss gradient boosting regression, an more advanced regressor model which can model nonlinear relationships between variables. Then, we will show how to visualize the results in each step. Finally, we will discuss how to train our models by finding the values of their parameters that minimize a cost function. We will work through a real problem to learn how the models and learning algorithms work.
</summary>
    <author>
      <name>Alireza Khanteymoori</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/khanteymoori/</uri>
    </author>
    <author>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </author>
    <author>
      <name>Simon Bray</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/simonbray/</uri>
    </author>
    <contributor>
      <name>Helena Rasche</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/hexylena/</uri>
    </contributor>
    <contributor>
      <name>Saskia Hiltemann</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/shiltemann/</uri>
    </contributor>
    <contributor>
      <name>Bj√∂rn Gr√ºning</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/bgruening/</uri>
    </contributor>
    <contributor>
      <name>Alireza Khanteymoori</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/khanteymoori/</uri>
    </contributor>
  </entry>
  <entry>
    <title>üõ†Ô∏è Machine Learning</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/machinelearning/workflows/machine_learning.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/machinelearning/workflows/machine_learning.html</id>
    <updated>2019-11-21T07:14:20+00:00</updated>
    <category term="workflows"/>
    <category term="statistics"/>
    <category term="ml"/>
    <summary>Basics of machine learning</summary>
  </entry>
  <entry>
    <title>üõ†Ô∏è Regression GradientBoosting</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/classification_regression/workflows/regression_GradientBoosting.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/classification_regression/workflows/regression_GradientBoosting.html</id>
    <updated>2019-06-25T12:59:12+00:00</updated>
    <category term="workflows"/>
    <category term="statistics"/>
    <category term="ml"/>
    <summary>Machine learning: classification and regression</summary>
  </entry>
  <entry>
    <title>üõ†Ô∏è Classification LSVC</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/classification_regression/workflows/classification_LSVC.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/classification_regression/workflows/classification_LSVC.html</id>
    <updated>2019-06-25T12:59:12+00:00</updated>
    <category term="workflows"/>
    <category term="statistics"/>
    <category term="ml"/>
    <summary>Machine learning: classification and regression</summary>
  </entry>
  <entry>
    <title>üìö Machine learning: classification and regression</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/classification_regression/tutorial.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/classification_regression/tutorial.html</id>
    <updated>2019-03-07T13:04:32+00:00</updated>
    <category term="statistics"/>
    <summary>Machine learning is a subset of artificial intelligence (AI) that provides machines with the ability to automatically learn from data without being explicitly programmed. It is a combined field of computer science, mathematics and statistics to create a predictive model by learning patterns in a dataset. The dataset may have an output field which makes the learning process supervised. The supervised learning methods in machine learning have outputs (also called as targets or classes or categories) defined in the datasets in a column. These targets can either be  integers or real (continuous) numbers. When the targets are integers, the learning task is known as classification. Each row in the dataset is a sample and the classification is assigning a class label/target to each sample. The algorithm which is used for this learning task is called a classifier. When the targets are real numbers, the learning task is called regression and the algorithm which is used for this task is called a regressor. We will go through classification first and look at regression later in this tutorial.
</summary>
    <author>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </author>
    <author>
      <name>B√©r√©nice Batut</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/bebatut/</uri>
    </author>
    <contributor>
      <name>Saskia Hiltemann</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/shiltemann/</uri>
    </contributor>
    <contributor>
      <name>B√©r√©nice Batut</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/bebatut/</uri>
    </contributor>
    <contributor>
      <name>Bj√∂rn Gr√ºning</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/bgruening/</uri>
    </contributor>
    <contributor>
      <name>Alireza Khanteymoori</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/khanteymoori/</uri>
    </contributor>
    <contributor>
      <name>Helena Rasche</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/hexylena/</uri>
    </contributor>
  </entry>
  <entry>
    <title>üõ†Ô∏è Age Prediction RNA-Seq</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/age-prediction-with-ml/workflows/age-prediction-rna.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/age-prediction-with-ml/workflows/age-prediction-rna.html</id>
    <updated>2019-01-25T11:10:10+00:00</updated>
    <category term="workflows"/>
    <category term="statistics"/>
    <summary>Age prediction using machine learning</summary>
  </entry>
  <entry>
    <title>üõ†Ô∏è Age Prediction DNA Methylation</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/age-prediction-with-ml/workflows/age-prediction-dnam.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/age-prediction-with-ml/workflows/age-prediction-dnam.html</id>
    <updated>2019-01-25T11:10:10+00:00</updated>
    <category term="workflows"/>
    <category term="statistics"/>
    <summary>Age prediction using machine learning</summary>
  </entry>
  <entry>
    <title>üìö Age prediction using machine learning</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/age-prediction-with-ml/tutorial.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/age-prediction-with-ml/tutorial.html</id>
    <updated>2019-01-25T11:10:10+00:00</updated>
    <category term="statistics"/>
    <summary>Machine Learning is used to create predictive models by learning features from datasets. In the studies performed by Jason G. Fleischer et al. 2018 and Jana Naue et al. 2017, biomarkers are examined to predict the chronological age of humans by analysing the RNA-seq gene expression levels and DNA methylation pattern respectively. Different machine learning algorithms are used in these studies to select specific biomarkers to make age prediction. The RNA-seq gene expression (FPKM) dataset is generated using fibroblast cell lines of humans. The skin fibroblasts cells keep damage that happens with age. Epigenomic and phenotypic changes which are age-dependent are also contained in these cells. Within each individual, DNA methylation changes with age. This knowledge is used to select useful biomarkers from DNA methylation dataset. The CpGs sites with the highest correlation to age are selected as the biomarkers/features. In both these studies, specific biomarkers are analysed by machine learning algorithms to create an age prediction model.
</summary>
    <author>
      <name>Ekaterina Polkh</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/polkhe/</uri>
    </author>
    <author>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </author>
    <contributor>
      <name>Saskia Hiltemann</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/shiltemann/</uri>
    </contributor>
    <contributor>
      <name>B√©r√©nice Batut</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/bebatut/</uri>
    </contributor>
    <contributor>
      <name>Bj√∂rn Gr√ºning</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/bgruening/</uri>
    </contributor>
    <contributor>
      <name>Alireza Khanteymoori</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/khanteymoori/</uri>
    </contributor>
  </entry>
  <entry>
    <title>üìö Basics of machine learning</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/machinelearning/tutorial.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/machinelearning/tutorial.html</id>
    <updated>2018-11-05T18:03:45+00:00</updated>
    <category term="statistics"/>
    <summary>Machine learning uses techniques from statistics, mathematics and computer science to make computer programs learn from data. It is one of the most popular fields of computer science and finds applications in multiple streams of data analysis such as classification, regression, clustering, dimensionality reduction, density estimation and many more. Some real-life applications are spam filtering, medical diagnosis, autonomous driving, recommendation systems, facial recognition, stock prices prediction and many more. The following image shows a basic flow of any machine learning task. Data is provided by a user to a machine learning algorithm for analysis.
</summary>
    <author>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </author>
    <contributor>
      <name>Bj√∂rn Gr√ºning</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/bgruening/</uri>
    </contributor>
    <contributor>
      <name>Saskia Hiltemann</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/shiltemann/</uri>
    </contributor>
    <contributor>
      <name>B√©r√©nice Batut</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/bebatut/</uri>
    </contributor>
    <contributor>
      <name>Helena Rasche</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/hexylena/</uri>
    </contributor>
    <contributor>
      <name>Gildas Le Corguill√©</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/lecorguille/</uri>
    </contributor>
    <contributor>
      <name>Anup Kumar</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/anuprulez/</uri>
    </contributor>
  </entry>
  <entry>
    <title>üõ†Ô∏è Workflow Constructed From History 'IWTomics Workflow'</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/iwtomics/workflows/IWTomics_Workflow.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/iwtomics/workflows/IWTomics_Workflow.html</id>
    <updated>2018-06-14T09:51:52+00:00</updated>
    <category term="workflows"/>
    <category term="statistics"/>
    <category term="genomics"/>
    <category term="iwtomics"/>
    <summary>Interval-Wise Testing for omics data</summary>
  </entry>
  <entry>
    <title>üìö Interval-Wise Testing for omics data</title>
    <link href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/iwtomics/tutorial.html"/>
    <id>https://training.galaxyproject.org/training-material/topics/statistics/tutorials/iwtomics/tutorial.html</id>
    <updated>2018-06-14T09:51:52+00:00</updated>
    <category term="statistics"/>
    <summary>IWTomics (Cremona et al. 2018) implements the Interval-Wise Testing (IWT; Pini and Vantini 2017) for omics data. This

</summary>
    <author>
      <name>Marzia A Cremona</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/marziacremona/</uri>
    </author>
    <author>
      <name>Fabio Cumbo</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/cumbof/</uri>
    </author>
    <contributor>
      <name>B√©r√©nice Batut</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/bebatut/</uri>
    </contributor>
    <contributor>
      <name>Saskia Hiltemann</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/shiltemann/</uri>
    </contributor>
    <contributor>
      <name>Nicola Soranzo</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/nsoranzo/</uri>
    </contributor>
    <contributor>
      <name>Bj√∂rn Gr√ºning</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/bgruening/</uri>
    </contributor>
    <contributor>
      <name>Bert Droesbeke</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/bedroesb/</uri>
    </contributor>
    <contributor>
      <name>Daniel Sobral</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/dsobral/</uri>
    </contributor>
    <contributor>
      <name>Helena Rasche</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/hexylena/</uri>
    </contributor>
    <contributor>
      <name>Gildas Le Corguill√©</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/lecorguille/</uri>
    </contributor>
    <contributor>
      <name>Fabio Cumbo</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/cumbof/</uri>
    </contributor>
    <contributor>
      <name>Niall Beard</name>
      <uri>https://training.galaxyproject.org/training-material/hall-of-fame/njall/</uri>
    </contributor>
  </entry>
</feed>
