<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <title>Classification in Machine Learning</title>
        <link rel="stylesheet" href="/training-material/assets/css/bootstrap.min.css?v=3">
        <link rel="stylesheet" href="/training-material/assets/css/bootstrap-toc.min.css">
        <link rel="stylesheet" href="/training-material/assets/css/main.css?v=2">
        <script src="https://kit.fontawesome.com/67b3f98409.js" crossorigin="anonymous"></script>
        <link rel="stylesheet" href="/training-material/assets/css/academicons.css">
        <link rel="stylesheet" href="/training-material/assets/css/syntax_highlighting.css">
        <link rel="shortcut icon" href="/training-material/favicon.ico" type="image/x-icon" />

        
        
        
        
        
        <meta name="description" content="Statistical Analyses for omics data and machine learning ..." />
        <meta property="og:title" content="Galaxy Training: Classification in Machine Learning" />
        <meta property="og:description" content="Statistical Analyses for omics data and machine learning ..." />
        <meta property="og:image" content="/training-material/assets/images/GTNLogo1000.png" />
    </head>
    <body data-spy="scroll" data-target="#toc">
        











<!-- Gitter -->


<script>
  ((window.gitter = {}).chat = {}).options = {
  room: 'Galaxy-Training-Network/Lobby'
  };
</script>
<script src="https://sidecar.gitter.im/dist/sidecar.v1.js" async defer></script>

<header>
    <nav class="navbar navbar-expand-lg navbar-dark">
        <div class="container">
            <a class="navbar-brand" href="/training-material/">
                <img src="/training-material/assets/images/GTN-60px.png" height="30" alt="Galaxy Training Network logo">
                Galaxy Training!
            </a>

            <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#top-navbar" aria-controls="top-navbar" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="top-navbar">
                <ul class="navbar-nav">
                    <li class="nav-item">
                        <a class="nav-link" href="/training-material/topics/statistics" title="Go back to list of tutorials">
                            <i class="far fa-folder" aria-hidden="true"></i><span class="visually-hidden">topic</span> Statistics and machine learning
                        </a>
                    </li>

                    <li class="nav-item dropdown">
                        <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-expanded="false" title="Language Selector">
                            <i class="fas fa-language" aria-hidden="true"></i><span class="visually-hidden">language</span> Language
                        </a>
                        <div class="dropdown-menu">
                            
                            <a class="dropdown-item" href="https://translate.google.com/translate?hl=jp&sl=en&tl=fr&u=https%3A%2F%2Ftraining.galaxyproject.org%2Ftopics%2Fstatistics%2Ftutorials%2Fclassification_machinelearning%2Ftutorial.html&edit-text=&act=url" title="">
                                Fran√ßais
                            </a>
                            
                            <a class="dropdown-item" href="https://translate.google.com/translate?hl=jp&sl=en&tl=ja&u=https%3A%2F%2Ftraining.galaxyproject.org%2Ftopics%2Fstatistics%2Ftutorials%2Fclassification_machinelearning%2Ftutorial.html&edit-text=&act=url" title="">
                                Êó•Êú¨Ë™û
                            </a>
                            
                            <a class="dropdown-item" href="https://translate.google.com/translate?hl=jp&sl=en&tl=es&u=https%3A%2F%2Ftraining.galaxyproject.org%2Ftopics%2Fstatistics%2Ftutorials%2Fclassification_machinelearning%2Ftutorial.html&edit-text=&act=url" title="">
                                Espa√±ol
                            </a>
                            
                            <a class="dropdown-item" href="https://translate.google.com/translate?hl=jp&sl=en&tl=pt&u=https%3A%2F%2Ftraining.galaxyproject.org%2Ftopics%2Fstatistics%2Ftutorials%2Fclassification_machinelearning%2Ftutorial.html&edit-text=&act=url" title="">
                                Portugu√™s
                            </a>
                            
                            <a class="dropdown-item" href="https://translate.google.com/translate?hl=jp&sl=en&tl=ar&u=https%3A%2F%2Ftraining.galaxyproject.org%2Ftopics%2Fstatistics%2Ftutorials%2Fclassification_machinelearning%2Ftutorial.html&edit-text=&act=url" title="">
                                ÿßŸÑÿπÿ±ÿ®Ÿäÿ©
                            </a>
                            
                            <a class="dropdown-item" href="https://translate.google.com/translate?hl=jp&sl=en&tl=&u=https%3A%2F%2Ftraining.galaxyproject.org%2Ftopics%2Fstatistics%2Ftutorials%2Fclassification_machinelearning%2Ftutorial.html&edit-text=&act=url" title="">
                                And more!
                            </a>
                        </div>
                    </li>

                    <li class="nav-item dropdown">
    <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-expanded="false" title="Help">
        <i class="far fa-question-circle" aria-hidden="true"></i><span class="visually-hidden">help</span> Help
    </a>
    <div class="dropdown-menu dropdown-menu-right">
        <form method="get" action="https://tess.elixir-europe.org/materials">
            <input type="text" id="search" name="q" value="" style="margin-left: 0.5em;/*! border-radius: 0px; */">
            <input type="hidden" value="Galaxy Training" name="content_provider">
            <input type="submit" value="Search on TeSS" style="width: 92%;border-radius: 0px;margin: 0.5em;background: #f47d20;border: 0px;padding: 0.25em;" class="">
        </form>

        <div class="dropdown-divider"></div>
        <a class="dropdown-item" href="/training-material/faq" title="Check our FAQ">
            FAQ
        </a>
        <a class="dropdown-item" href="https://help.galaxyproject.org/" title="Discuss on Galaxy Help">
            Discuss on Galaxy Help
        </a>

        <div class="dropdown-item">
            <div>
                Theme
            </div>

            <div id="theme-selector" data-toggle="buttons">
                <label data-value="default" class="btn btn-secondary">
                    <input type="radio" name="options" id="default" autocomplete="off"> Default
                </label>
                <label data-value="night" class="btn btn-secondary">
                    <input type="radio" name="options" id="night" autocomplete="off"> Night
                </label>
                <label data-value="midnight" class="btn btn-secondary">
                    <input type="radio" name="options" id="midnight" autocomplete="off"> Midnight
                </label>
                <label data-value="rainbow" class="btn btn-secondary">
                    <input type="radio" name="options" id="rainbow" autocomplete="off"> Rainbow
                </label>
                <label data-value="halloween" class="btn btn-secondary">
                    <input type="radio" name="options" id="halloween" autocomplete="off"> üéÉ
                </label>
            </div>

        </div>
    </div>
</li>


                    <li class="nav-item">
                        <a class="nav-link" href="https://github.com/galaxyproject/training-material/edit/master/topics/statistics/tutorials/classification_machinelearning/tutorial.md">
                            <i class="fab fa-github" aria-hidden="true"></i><span class="visually-hidden">github</span> Edit
                        </a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>
</header>

<div class="container main-content">
    <script type="application/ld+json">
        


{
  "@context": "http://schema.org",
  "@type": "Course",
  "accessMode": [
    "textual",
    "visual"
  ],
  "accessModeSufficient": [
    "textual",
    "visual"
  ],
  "accessibilityControl": [
    "fullKeyboardControl",
    "fullMouseControl"
  ],
  "accessibilityFeature": [
    "alternativeText",
    "tableOfContents"
  ],
  "accessibilitySummary": "Short descriptions are present but long descriptions will be needed for non-visual users",
  "audience": {
    "@type": "EducationalAudience",
    "educationalRole": "students"
  },
  "citation": {
    "@type": "CreativeWork",
    "name": "Community-Driven Data Analysis Training for Biology",
    "url": "https://doi.org/10.1016/j.cels.2018.05.012"
  },
  "copyrightHolder": {
    "@type": "Organization",
    "email": "galaxytrainingnetwork@gmail.com",
    "name": "Galaxy Training Network",
    "url": "https://galaxyproject.org/teach/gtn/"
  },
  "discussionUrl": "https://gitter.im/Galaxy-Training-Network/Lobby",
  "headline": "Classification in Machine Learning",
  "inLanguage": {
    "@type": "Language",
    "name": "English",
    "alternateName": "en"
  },
  "interactivityType": "mixed",
  "isAccessibleForFree": true,
  "license": "https://github.com/galaxyproject/training-material/blob/master/LICENSE.md",
  "producer": {
    "@type": "Organization",
    "email": "galaxytrainingnetwork@gmail.com",
    "name": "Galaxy Training Network",
    "url": "https://galaxyproject.org/teach/gtn/"
  },
  "provider": {
    "@type": "Organization",
    "email": "galaxytrainingnetwork@gmail.com",
    "name": "Galaxy Training Network",
    "url": "https://galaxyproject.org/teach/gtn/"
  },
  "sourceOrganization": {
    "@type": "Organization",
    "email": "galaxytrainingnetwork@gmail.com",
    "name": "Galaxy Training Network",
    "url": "https://galaxyproject.org/teach/gtn/"
  },
  "isPartOf": {
    "@type": "CreativeWork",
    "name": "Statistics and machine learning",
    "description": "Statistical Analyses for omics data and machine learning using Galaxy tools",
    "url": "https://training.galaxyproject.org//training-material/topics/statistics/"
  },
  "courseCode": "statistics / classification_machinelearning / hands-on",
  "learningResourceType": "hands-on tutorial",
  "name": "Hands-on for 'Classification in Machine Learning' tutorial",
  "url": "https://training.galaxyproject.org//training-material/topics/statistics/tutorials/classification_machinelearning/tutorial.html",
  "timeRequired": "PT2H",
  "description": "The questions this  addresses are:\n - What is classification and how we can use classification techniques?\n\n\\nThe objectives are:\n - Learn classification background\n - Learn what a quantitative structure-analysis relationship (QSAR) model is and how it can be constructed in Galaxy\n - Learn to apply logistic regression, k-nearest neighbors, support verctor machines, random forests and bagging algorithms\n - Learn how visualizations can be used to analyze the classification results\n\n",
  "coursePrerequisites": [
    {
      "@type": "CreativeWork",
      "url": "https://training.galaxyproject.org//training-material/topics/introduction/",
      "name": "Introduction to Galaxy Analyses",
      "description": "Introduction to Galaxy Analyses",
      "provider": {
        "@type": "Organization",
        "email": "galaxytrainingnetwork@gmail.com",
        "name": "Galaxy Training Network",
        "url": "https://galaxyproject.org/teach/gtn/"
      }
    }
  ],
  "hasPart": [

  ],
  "author": [
    {
      "@type": "Person",
      "name": "Alireza Khanteymoori"
    },
    {
      "@type": "Person",
      "name": "Anup Kumar"
    },
    {
      "@type": "Person",
      "name": "Simon Bray"
    }
  ],
  "contributor": [
    {
      "@type": "Person",
      "name": "Alireza Khanteymoori"
    },
    {
      "@type": "Person",
      "name": "Anup Kumar"
    },
    {
      "@type": "Person",
      "name": "Simon Bray"
    }
  ],
  "about": [
    {
      "@type": "CreativeWork",
      "name": "Statistics and machine learning",
      "description": "Statistical Analyses for omics data and machine learning using Galaxy tools",
      "url": "https://training.galaxyproject.org//training-material/topics/statistics/"
    },
    {
      "@type": "DefinedTerm",
      "@id": "http://edamontology.org/topic_2269",
      "inDefinedTermSet": "http://edamontology.org",
      "termCode": "topic_2269",
      "url": "https://bioportal.bioontology.org/ontologies/EDAM/?p=classes&conceptid=http%3A%2F%2Fedamontology.org%2Ftopic_2269"
    }
  ]
}
    </script>

    <section class="tutorial">
        <h1 data-toc-skip>Classification in Machine Learning</h1>
        

        <div class="contributors-line">By: 

<a href="/training-material/hall-of-fame/khanteymoori/" class="contributor-badge"><img src="https://avatars.githubusercontent.com/khanteymoori" alt="Alireza Khanteymoori">Alireza Khanteymoori</a>, <a href="/training-material/hall-of-fame/anuprulez/" class="contributor-badge"><img src="https://avatars.githubusercontent.com/anuprulez" alt="Anup Kumar">Anup Kumar</a>, <a href="/training-material/hall-of-fame/simonbray/" class="contributor-badge"><img src="https://avatars.githubusercontent.com/simonbray" alt="Simon Bray">Simon Bray</a>

</div>

        <blockquote class="overview">
            <h3>Overview</h3>
            <strong><i class="far fa-question-circle" aria-hidden="true"></i><span class="visually-hidden">question</span> Questions</strong>
            <ul>
            
            <li><p>What is classification and how we can use classification techniques?</p>
</li>
            
            </ul>

            <strong><i class="fas fa-bullseye" aria-hidden="true"></i><span class="visually-hidden">objectives</span> Objectives</strong>
            <ul>
            
            <li><p>Learn classification background</p>
</li>
            
            <li><p>Learn what a quantitative structure-analysis relationship (QSAR) model is and how it can be constructed in Galaxy</p>
</li>
            
            <li><p>Learn to apply logistic regression, k-nearest neighbors, support verctor machines, random forests and bagging algorithms</p>
</li>
            
            <li><p>Learn how visualizations can be used to analyze the classification results</p>
</li>
            
            </ul>

            
            <strong><i class="fas fa-check-circle" aria-hidden="true"></i><span class="visually-hidden">requirements</span> Requirements</strong>
            <ul>
            
    <li>
    
        
        
        <a href="/training-material/topics/introduction">Introduction to Galaxy Analyses</a>
        
    
    </li>

            
            </ul>
            

            
            <p><strong><i class="fas fa-hourglass-half" aria-hidden="true"></i><span class="visually-hidden">time</span> Time estimation:</strong> 2 hours</p>
            

            

            
            

            
            <p id="supporting-materials"><strong><i class="fa fa-external-link" aria-hidden="true"></i> Supporting Materials</strong></p>
            <ul>
                <div class="supporting_material">
                

                
                    <li class="btn btn-default supporting_material">
<a class="topic-icon" href="https://zenodo.org/record/3738729#.XoZyHXUzaV4">
    <i class="far fa-copy" aria-hidden="true"></i><span class="visually-hidden">zenodo_link</span> Datasets
</a>

</li>
                

                
                    <li class="btn btn-default supporting_material">
    <a class="topic-icon" href="/training-material/topics/statistics/tutorials/classification_machinelearning/workflows/" title="Workflows" alt="Classification in Machine Learning workflows">
        <i class="fas fa-share-alt" aria-hidden="true"></i><span class="visually-hidden">workflow</span> Workflows
    </a>

</li>
                

                

                
                    <li class="btn btn-default supporting_material">

    <a href="#" class="btn btn-default dropdown-toggle topic-icon" data-toggle="dropdown" aria-expanded="false" title="Where to run the tutorial">
        <i class="fas fa-globe" aria-hidden="true"></i><span class="visually-hidden">instances</span> Available on these Galaxies
    </a>
    <ul class="dropdown-menu">
    
        <li>
            <a class="dropdown-item" href="https://github.com/galaxyproject/training-material/tree/master/topics/statistics/docker" title="Docker image for this tutorial">
                <i class="fab fa-docker" aria-hidden="true"></i><span class="visually-hidden">docker_image</span> Docker image
            </a>
        </li>
    
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
        <a class="dropdown-item" href="https://africa.usegalaxy.eu/" title="Galaxy Africa">
            Galaxy Africa
        </a>
        
    
        
    
        
        <a class="dropdown-item" href="https://test.galaxyproject.org/" title="Galaxy Test">
            Galaxy Test
        </a>
        
    
        
        <a class="dropdown-item" href="https://ecology.usegalaxy.eu/" title="Galaxy for Ecology">
            Galaxy for Ecology
        </a>
        
    
        
    
        
        <a class="dropdown-item" href="https://galaxy.genouest.org" title="Galaxy@GenOuest">
            Galaxy@GenOuest
        </a>
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
        <a class="dropdown-item" href="https://usegalaxy.eu" title="UseGalaxy.eu">
            UseGalaxy.eu
        </a>
        
    
        
    
        
        <a class="dropdown-item" href="https://usegalaxy.no/" title="UseGalaxy.no">
            UseGalaxy.no
        </a>
        
    
        
        <a class="dropdown-item" href="https://usegalaxy.org" title="UseGalaxy.org (Main)">
            UseGalaxy.org (Main)
        </a>
        
    
        
        <a class="dropdown-item" href="https://usegalaxy.org.au" title="UseGalaxy.org.au">
            UseGalaxy.org.au
        </a>
        
    
        
    
    </ul>


</li>
                
                </div>
            </ul>
            

            <p><strong> <i class="far fa-calendar" aria-hidden="true"></i><span class="visually-hidden">last_modification</span> Last modification:</strong> Jan 6, 2021 </p>
        </blockquote>

        <div class="container">
            <div class="row">
                <!-- sidebar, which will move to the top on a small screen -->
                <div class="col-sm-2">
                    <nav id="toc" data-toggle="toc" class="sticky-top"></nav>
                </div>
                <div class="col-sm-10">
                    <h1 class="no_toc" id="introduction">Introduction</h1>

<p>In this tutorial you will learn how to apply <span class="notranslate">Galaxy</span> tools to solve <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> problems. First, we will introduce classification briefly, and then examine logistic regression, which is an example of a linear classifier. Next, we will discuss the nearest neighbor classifier, which is a simple but nonlinear classifier. Then advanced classifiers, such as support vector machines, random forest and ensemble classifiers will be introduced and applied. Furthermore, we will show how to visualize the results in each step.</p>

<p>Finally, we will discuss how to train the classifiers by finding the values of their parameters that minimize a cost function. We will work through a real problem in the field of cheminformatics to learn how the classifiers and learning algorithms work.</p>

<p>Classification is a <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a> method in machine learning and the algorithm which is used for this learning task is called a classifier. In this tutorial we will build a classifier which can predict whether a chemical substance is biodegradable or not. Substances which degrade quickly are preferable to those which degrade slowly, as they do not accumulate and pose a risk to the environment. Therefore, it is useful to be able to predict easily in advance whether a substance is biodegradable prior to production and usage in consumer products.</p>

<blockquote class="agenda">
  <h3 id="agenda">Agenda</h3>

  <p>In this tutorial, we will cover:</p>

<ol id="markdown-toc">
  <li><a href="#classification" id="markdown-toc-classification">Classification</a></li>
  <li><a href="#quantitative-structure---activity-relationship-biodegradation" id="markdown-toc-quantitative-structure---activity-relationship-biodegradation">Quantitative structure - activity relationship biodegradation</a>    <ol>
      <li><a href="#get-train-and-test-datasets" id="markdown-toc-get-train-and-test-datasets">Get train and test datasets</a></li>
    </ol>
  </li>
  <li><a href="#learn-the-logistic-regression-classifier" id="markdown-toc-learn-the-logistic-regression-classifier">Learn the logistic regression classifier</a>    <ol>
      <li><a href="#predict-class-using-test-dataset" id="markdown-toc-predict-class-using-test-dataset">Predict class using test dataset</a></li>
      <li><a href="#visualize-the-logistic-regression-classification-results" id="markdown-toc-visualize-the-logistic-regression-classification-results">Visualize the logistic regression classification results</a></li>
    </ol>
  </li>
  <li><a href="#k-nearest-neighbor-knn" id="markdown-toc-k-nearest-neighbor-knn">K-Nearest Neighbor (KNN)</a></li>
  <li><a href="#support-vector-machines-svm" id="markdown-toc-support-vector-machines-svm">Support Vector Machines (SVM)</a></li>
  <li><a href="#random-forest" id="markdown-toc-random-forest">Random Forest</a></li>
  <li><a href="#create-data-processing-pipeline" id="markdown-toc-create-data-processing-pipeline">Create data processing pipeline</a>    <ol>
      <li><a href="#search-for-the-best-values-of-hyperparameters" id="markdown-toc-search-for-the-best-values-of-hyperparameters">Search for the best values of hyperparameters</a></li>
    </ol>
  </li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
</ol>

</blockquote>

<h1 id="classification">Classification</h1>

<p>Classification is the process of assigning every object from a collection to exactly one class from a known set of classes by learning a ‚Äúdecision boundary‚Äù in a dataset. This dataset is called a training dataset and contains multiple samples, together with a desired class for each sample. The training dataset contains ‚Äúfeatures‚Äù as columns and a <span class="notranslate">mapping</span> between these features and the class label is learned for each sample.</p>

<p>The performance of <span class="notranslate">mapping</span> is evaluated using a test dataset, which is separate from the training dataset. The test dataset contains only the feature columns, but not the class column. The class column is predicted using the <span class="notranslate">mapping</span> learned on the training dataset. An example of a classification task is assigning a patient (the object) to a group of healthy or ill (the classes) people on the basis of his or her medical record. In this tutorial, we will use a classifier to train a model using a training dataset, predict the targets for test dataset and visualize the results using plots.</p>

<figure id="figure-1"><img src="images/classification.png" alt="classification" /><figcaption><span class="figcaption-prefix">Figure 1:</span> Classification of samples belonging to different classes.</figcaption></figure>

<p>In figure <a href="#figure-1">1</a>, the line is a boundary which separates a class from another class (for example from tumor to no tumor). The task of a classifier is to learn this boundary, which can be used to classify or categorize an unseen/new sample. The line is the decision boundary; there are different ways to learn it, which correspond to different classification algorithms. If the dataset is linearly separable, linear classifiers can produce good classification results. However, when the dataset is complex and requires non-linear decision boundaries, more powerful classifiers like <code class="language-plaintext highlighter-rouge">support vector machine</code> or <code class="language-plaintext highlighter-rouge">ensemble</code> based classifiers may prove to be beneficial.</p>

<p>The data classification process includes two steps:</p>
<ol>
  <li>
    <p>Building the classifier or model: This step is the learning step, in which the classification algorithms build the classifier. The classifier is built from the training set made up of database samples and their associated class labels. Each sample that constitutes the training set is referred to as a class.</p>
  </li>
  <li>
    <p>Applying the classifier to a classification task: In this step, the classifier is used for classification. Here the test data is used to estimate the accuracy of classification rules. The classification rules can be applied to the new data samples if the accuracy is considered acceptable.</p>
  </li>
</ol>

<h1 id="quantitative-structure---activity-relationship-biodegradation">Quantitative structure - activity relationship biodegradation</h1>

<p>The classification problem we will study in this tutorial is related to biodegradation. Chemical substances which decay slowly will accumulate over time, which poses a threat to the environment. Therefore, it is useful to be able to predict in advance whether a substance will break down quickly or not.</p>

<p>Quantitative structure-activity relationship (QSAR) and quantitative structure-property relationship (QSPR) models attempt to predict the activity or property of chemicals based on their chemical structure. To achieve this, a database of compounds is collected for which the property of interest is known. For each compound, molecular descriptors are collected which describe the structure (for example: molecular weight, number of nitrogen atoms, number of carbon-carbon double bonds). Using these descriptors, a model is constructed which is capable of predicting the property of interest for a new, unknown molecule. In this tutorial we will use a database assembled from experimental data of the Japanese Ministry of Inte<span class="notranslate">rna</span>tional Trade and Industry to create a classification model for biodegradation. We then will be able to use this model to classify new molecules into one of two classes: biodegradable or non-biodegradable.</p>

<p>As a benchmark, we will use the <a href="https://pubs.acs.org/doi/10.1021/ci4000213">dataset</a> assembled by Mansouri et al. using data from the National Institute of Technology and Evaluation of Japan. This database contains 1055 molecules, together with precalculated molecular descriptors.</p>

<p>In this tutorial, we will apply a couple of <a href="https://scikit-learn.org/stable/">scikit-learn</a> machine learning tools to the dataset provided by Mansouri et al. to predict whether a molecule is biodegradable or not.
In the following part, we will perform classification on the biodegradability dataset using a linear classifier and then will create some plots to analyze the results.</p>

<h2 id="get-train-and-test-datasets">Get train and test datasets</h2>

<p>We have two datasets available; the training dataset contains 837 molecules, while the test dataset contains 218 molecules.</p>

<p>Let‚Äôs begin by uploading the necessary datasets.</p>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-data-upload"><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Data upload</h3>

  <ol>
    <li>Create a new history for this tutorial</li>
    <li>
      <p>Import the files from <a href="https://zenodo.org/record/3738729#.Xs1EeHUzY5k">Zenodo</a></p>

      <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>https://zenodo.org/record/3738729/files/train_rows.csv
https://zenodo.org/record/3738729/files/test_rows_labels.csv
https://zenodo.org/record/3738729/files/test_rows.csv
</code></pre></div>      </div>

      <blockquote class="tip">

        <h3 id="tip-tip-importing-data-via-links"><i class="far fa-lightbulb" aria-hidden="true"></i><span class="visually-hidden">tip</span> Tip: Importing data via links</h3>

        <ul>
          <li>Copy the link location</li>
          <li>
            <p>Open the <span class="notranslate">Galaxy</span> Upload Manager (<i class="fas fa-upload" aria-hidden="true"></i><span class="visually-hidden"><span class="notranslate">galaxy</span>-upload</span> on the top-right of the tool panel)</p>
          </li>
          <li>Select <strong>Paste/Fetch Data</strong></li>
          <li>
            <p>Paste the link into the text field</p>
          </li>
          <li>
            <p>Press <strong>Start</strong></p>
          </li>
          <li><strong>Close</strong> the window</li>
        </ul>

        <p>By default, <span class="notranslate">Galaxy</span> uses the URL as the name, so rename the files with a more useful name.</p>

      </blockquote>
    </li>
    <li>
      <p>Rename the datasets as <code class="language-plaintext highlighter-rouge">train_rows</code>, <code class="language-plaintext highlighter-rouge">test_rows_labels</code> and <code class="language-plaintext highlighter-rouge">test_rows</code> respectively.</p>

      <blockquote class="tip">

        <h3 id="tip-tip-renaming-a-dataset"><i class="far fa-lightbulb" aria-hidden="true"></i><span class="visually-hidden">tip</span> Tip: Renaming a dataset</h3>
        <ul>
          <li>Click on the <i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden"><span class="notranslate">galaxy</span>-pencil</span> <strong>pencil icon</strong> for the dataset to edit its attributes</li>
          <li>In the central panel, change the <strong>Name</strong> field</li>
          <li>Click the <strong>Save</strong> button</li>
        </ul>
      </blockquote>
    </li>
  </ol>

</blockquote>

<p class="comment">The <code class="language-plaintext highlighter-rouge">train_rows</code> contains a column <code class="language-plaintext highlighter-rouge">Class</code> which is the class label or target. We will evaluate our model on <code class="language-plaintext highlighter-rouge">test_rows</code> and compare the predicted class with the true class value in <code class="language-plaintext highlighter-rouge">test_rows_labels</code></p>

<blockquote class="details">
  <h3 id="details-preparing-the-data-for-classification"><i class="fas fa-info-circle" aria-hidden="true"></i><span class="visually-hidden">details</span> Preparing the data for classification</h3>

  <p>Preparing the data involves these following major tasks:</p>
  <ol>
    <li>Data cleaning: involves removing noise and treatment of missing values. The noise is removed by applying noise filtering techniques and the problem of missing values is solved by replacing a missing value with different techniques, for example substitution, mean imputation and regression imputation.</li>
    <li>Relevance analysis: the database may also have attributes which are irrelevant for classification. Correlation analysis is used to know whether any two given attributes are related - e.g. one of the features and the target variable.</li>
    <li>Normalization: the data is transformed using normalization. Normalization involves scaling all values for q given attribute in order to make them fall within a small specified range. Normalization is used when in the learning step, neural networks or the methods involving measurements are used.</li>
  </ol>

</blockquote>

<h1 id="learn-the-logistic-regression-classifier">Learn the logistic regression classifier</h1>

<p>As the first step, to learn the <span class="notranslate">mapping</span> between several features and the classes, we will apply the linear classifier. It learns features from the training dataset and maps all the rows to their respective class. The process of <span class="notranslate">mapping</span> gives a trained model. <a href="https://en.wikipedia.org/wiki/Logistic_regression">Logistic regression</a> is named for the function used at the core of the method, the logistic function, and it is an instance of supervised classification in which we know the correct label of the class for each sample and the algorithm estimate of the true class. We want to learn parameters (weight and bias for the line) that make the estimated class for each training observation as close as possible to the true class label. This requires two components; the first is a metric for how close the current class label is to the true label. Rather than measure similarity, we usually talk about the opposite of this, the distance between the classifier output and the desired output, and we call this distance, the loss function or the cost function.</p>

<p>The second thing we need is an optimization algorithm for iteratively updating the weights so as to minimize this loss function. The standard algorithm for this is gradient descent. So, the dataset is divided into two parts - training and test sets. The training set is used to train a classifier and the test set is used to evaluate the performance of the trained model.</p>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-train-logistic-regression-classifier"><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Train logistic regression classifier</h3>

  <ol>
    <li><strong>Generalized linear models</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span> with the following parameters to train the regressor:
      <ul>
        <li><em>‚ÄúSelect a Classification Task‚Äù</em>: <code class="language-plaintext highlighter-rouge">Train a model</code>
          <ul>
            <li><em>‚ÄúSelect a linear method‚Äù</em>: <code class="language-plaintext highlighter-rouge">Logistic Regression</code>
              <ul>
                <li><em>‚ÄúSelect input type‚Äù</em>: <code class="language-plaintext highlighter-rouge">tabular data</code>
                  <ul>
                    <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúTraining samples dataset‚Äù</em>: <code class="language-plaintext highlighter-rouge">train_rows</code></li>
                    <li><i class="far fa-check-square" aria-hidden="true"></i><span class="visually-hidden">param-check</span> <em>‚ÄúDoes the dataset contain header‚Äù</em>: <code class="language-plaintext highlighter-rouge">Yes</code></li>
                    <li><i class="fas fa-filter" aria-hidden="true"></i><span class="visually-hidden">param-select</span> <em>‚ÄúChoose how to select data by column‚Äù</em>: <code class="language-plaintext highlighter-rouge">All columns EXCLUDING some by column header name(s)</code>
                      <ul>
                        <li><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">param-text</span> <em>‚ÄúType header name(s)‚Äù</em>: <code class="language-plaintext highlighter-rouge">Class</code></li>
                      </ul>
                    </li>
                    <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúDataset containing class labels‚Äù</em>: <code class="language-plaintext highlighter-rouge">train_rows</code></li>
                    <li><i class="far fa-check-square" aria-hidden="true"></i><span class="visually-hidden">param-check</span> <em>‚ÄúDoes the dataset contain header‚Äù</em>: <code class="language-plaintext highlighter-rouge">Yes</code></li>
                    <li><i class="fas fa-filter" aria-hidden="true"></i><span class="visually-hidden">param-select</span> <em>‚ÄúChoose how to select data by column‚Äù</em>: <code class="language-plaintext highlighter-rouge">Select columns by column header name(s)</code>
                      <ul>
                        <li><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">param-text</span> <em>‚ÄúSelect target column(s)‚Äù</em>: <code class="language-plaintext highlighter-rouge">Class</code></li>
                      </ul>
                    </li>
                  </ul>
                </li>
              </ul>
            </li>
          </ul>
        </li>
      </ul>
    </li>
    <li>Rename the generated file to <code class="language-plaintext highlighter-rouge">LogisticRegression_model</code></li>
  </ol>
</blockquote>

<blockquote class="question">
  <h3 id="question-question"><i class="far fa-question-circle" aria-hidden="true"></i><span class="visually-hidden">question</span> Question</h3>

  <p>What is learned by the logistic regression model?</p>

  <blockquote class="solution">
    <h3 id="solution-solution"><i class="far fa-eye" aria-hidden="true"></i><span class="visually-hidden">solution</span> Solution</h3>

    <p>In the logistic regressoion model, the coefficients of the logistic regression algorithm have be estimated from our training data. This is done using <a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation">maximum-likelihood estimation</a>.</p>

  </blockquote>

</blockquote>

<h2 id="predict-class-using-test-dataset">Predict class using test dataset</h2>

<p>After learning on the training dataset, we should evaluate the performance on the test dataset to know whether the learning algorithm learned a good classifier from the training dataset or not. This classifier is used to predict a new sample and a similar accuracy is expected.</p>

<p>Now, we will predict the class in the test dataset using this classifier in order to see if it has learned important features which can be generalized on a new dataset. The test dataset (<code class="language-plaintext highlighter-rouge">test_rows</code>) contains the same number of features but does not contain the <code class="language-plaintext highlighter-rouge">Class</code> column. This is predicted using the trained classifier.</p>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-predict-class-using-the-logistic-regression-classifier"><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Predict class using the logistic regression classifier</h3>

  <ol>
    <li><strong>Generalized linear models</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span> with the following parameters to predict targets of test dataset using the trained model:
      <ul>
        <li><em>‚ÄúSelect a Classification Task‚Äù</em>: <code class="language-plaintext highlighter-rouge">Load a model and predict</code>
          <ul>
            <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúModels‚Äù</em>: <code class="language-plaintext highlighter-rouge">LogisticRegression_model</code></li>
            <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúData (tabular)‚Äù</em>: <code class="language-plaintext highlighter-rouge">test_rows</code></li>
            <li><i class="far fa-check-square" aria-hidden="true"></i><span class="visually-hidden">param-check</span> <em>‚ÄúDoes the dataset contain header‚Äù</em>: <code class="language-plaintext highlighter-rouge">Yes</code></li>
            <li><i class="fas fa-filter" aria-hidden="true"></i><span class="visually-hidden">param-select</span> <em>‚ÄúSelect the type of prediction‚Äù</em>: <code class="language-plaintext highlighter-rouge">Predict class labels</code></li>
          </ul>
        </li>
      </ul>
    </li>
    <li>Rename the generated file to <code class="language-plaintext highlighter-rouge">LogisticRegression_result</code></li>
  </ol>
</blockquote>

<h2 id="visualize-the-logistic-regression-classification-results">Visualize the logistic regression classification results</h2>

<p>We will evaluate the classification by comparing the predicted with the expected classes. In the previous step, we classified the test dataset (<code class="language-plaintext highlighter-rouge">LogisticRegression_result</code>). We have one more dataset (<code class="language-plaintext highlighter-rouge">test_rows_labels</code>) which contains the true class label of the test set. Using the true and predicted class labels in the test set, we will verify the performance by analyzing the plots. As you can see, <code class="language-plaintext highlighter-rouge">LogisticRegression_result</code> has no header, so first we should remove the header from <code class="language-plaintext highlighter-rouge">test_rows_labels</code> to compare.</p>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-remove-the-header"><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Remove the header</h3>

  <ol>
    <li><strong>Remove beginning</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span> with the following parameters:
      <ul>
        <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúRemove first‚Äù</em>: <code class="language-plaintext highlighter-rouge">1</code></li>
        <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚Äúfrom‚Äù</em>: <code class="language-plaintext highlighter-rouge">test_rows_labels</code></li>
      </ul>
    </li>
    <li>Rename the generated file to <code class="language-plaintext highlighter-rouge">test_rows_labels_noheader</code></li>
  </ol>
</blockquote>

<p>Now we visualize and analyze the classification using the ‚ÄúPlot confusion matrix, precision, recall and ROC and AUC curves‚Äù tool.</p>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-check-and-visualize-the-classification"><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Check and visualize the classification</h3>
  <ol>
    <li><strong>Plot confusion matrix, precision, recall and ROC and AUC curves</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span> with the following parameters to visualize the classification:
      <ul>
        <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúSelect input data file‚Äù</em>: <code class="language-plaintext highlighter-rouge">test_rows_labels_noheader</code></li>
        <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúSelect predicted data file‚Äù</em>: <code class="language-plaintext highlighter-rouge">LogisticRegression_result</code></li>
        <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúSelect trained model‚Äù</em>: <code class="language-plaintext highlighter-rouge">LogisticRegression_model</code></li>
      </ul>
    </li>
  </ol>
</blockquote>

<p>The visualization tool creates the following plots:</p>

<ol>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Confusion_matrix">Confusion matrix</a>: The confusion matrix summarizes the classification performance of a classifier with respect to the test data. It is a two-dimensional matrix; the horizontal axis (x-axis) shows the predicted labels and the vertical axis (y-axis) shows the true labels. Each rectangular box shows a count of samples falling into the four output combinations (true class, predicted class) - (1, 0), (1, 1), (0, 1) and (0, 0). In Figure 2, the confusion matrix of the predictions is a colour-coded heatmap. For a good prediction, the diagonal running from top-left to bottom-right should contain a smaller number of samples, because it shows the counts of incorrectly predicted samples. Hovering over each box in <span class="notranslate">Galaxy</span> shows the true and predicted class labels and the count of samples.</p>

    <figure id="figure-2"><img src="images/confusion_matrix_linear.png" alt="confusion_matrix" /><figcaption><span class="figcaption-prefix">Figure 2:</span> Confusion matrix for the logistic regression classifier. </figcaption></figure>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Precision_and_recall">Precision, recall and F1 score</a>: Precision, recall and F1 score. These scores determine the robustness of classification. It is important to analyze the plot for any classification task to verify the accuracy across different classes which provides more information about the balanced or imbalanced accuracy across multiple classes present in the dataset.</p>

    <figure id="figure-3"><img src="images/precision_recall_linear.png" alt="prf1_scores" /><figcaption><span class="figcaption-prefix">Figure 3:</span> Precision, recall and F1 score for the logistic regression classifier.</figcaption></figure>
  </li>
  <li>
    <p><a href="https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5">Receiver operator characteristics (ROC) and area under ROC (AUC)</a>: Receiver operator characteristics (ROC) and area under ROC (AUC). The ROC curve is shown in blue. For a good prediction, it should be more towards the top-left of this plot, which results in a high AUC value. For a bad prediction, it is close to the orange line (y = x), resulting in a low AUC value (closer to 0.5). An AUC value of exactly 0.5 means the prediction is doing no better than a random number generator at predicting the classes.</p>

    <figure id="figure-4"><img src="images/roc_linear.png" alt="roc_scores" /><figcaption><span class="figcaption-prefix">Figure 4:</span> Receiver operator characteristics (ROC) and area under ROC (AUC) for the logistic regression classifier.</figcaption></figure>
  </li>
</ol>

<p>These plots are important to visualize the quality of the classifier and the true and predicted classes.</p>

<blockquote class="question">
  <h3 id="question-question-1"><i class="far fa-question-circle" aria-hidden="true"></i><span class="visually-hidden">question</span> Question</h3>

  <p>Inspect the plots. What can you say about the classification?</p>

  <blockquote class="solution">
    <h3 id="solution-solution-1"><i class="far fa-eye" aria-hidden="true"></i><span class="visually-hidden">solution</span> Solution</h3>

    <p>Figures 2,3 and 4 show that the classification is acceptable, but as you will see in the next steps, the results can be improved.</p>

  </blockquote>
</blockquote>

<h1 id="k-nearest-neighbor-knn">K-Nearest Neighbor (KNN)</h1>

<p>At the second step, we will use k-nearest neighbor classifier. In the <a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm">k-nearest neighbor</a> classifier, a sample is classified by a majority vote of its neighbors.  The sample is assigned to the class which is most common among its k nearest neighbors.  k is a positive integer and typically it is small. For example, if k = 1, then the sample is simply assigned to the class of that single nearest neighbor. Surprisingly, when the number of data points is large, this classifier is not that bad. Choosing the best value of k is very important. If k is too small, the classifier will be sensitive to noise points and if k is too large, the neighborhood may include points from other classes and causes errors. To select the k that is right for your data, we recommend running the KNN algorithm several times with different values of k and choosing the k that reduces the number of errors the most.</p>

<blockquote class="question">
  <h3 id="question-question-2"><i class="far fa-question-circle" aria-hidden="true"></i><span class="visually-hidden">question</span> Question</h3>

  <p>What are advantages and disadvantages about this model?</p>

  <blockquote class="solution">
    <h3 id="solution-solution-2"><i class="far fa-eye" aria-hidden="true"></i><span class="visually-hidden">solution</span> Solution</h3>
    <p>Advantages:</p>
    <ul>
      <li>
        <p>It is a very simple algorithm to understand and interpret.</p>
      </li>
      <li>
        <p>It is very useful for nonlinear data because there is no assumption of linearity in this algorithm.</p>
      </li>
      <li>
        <p>It is a versatile algorithm, as we can use it for classification as well as regression.</p>
      </li>
      <li>
        <p>It has relatively high accuracy, but there are much better supervised learning models than KNN.</p>
      </li>
      <li>
        <p>It works very well in low dimensions for complex decision surfaces.</p>
      </li>
    </ul>

    <p>Disadvantages:</p>

    <ul>
      <li>
        <p>Classification is slow, because it stores all the training data.</p>
      </li>
      <li>
        <p>High memory storage required as compared to other supervised learning algorithms.</p>
      </li>
      <li>
        <p>Prediction is slow in case of big training samples.</p>
      </li>
      <li>
        <p>It is very sensitive to the scale of data as well as irrelevant features.</p>
      </li>
      <li>
        <p>It suffers a lot from the curse of dimensionality.</p>
      </li>
    </ul>

  </blockquote>
</blockquote>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-train-k-nearest-neighbor-classifier"><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Train k-nearest neighbor classifier</h3>

  <ol>
    <li><strong>Nearest Neighbors Classification</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span> with the following parameters to train the regressor:
      <ul>
        <li><em>‚ÄúSelect a Classification Task‚Äù</em>: <code class="language-plaintext highlighter-rouge">Train a model</code>
          <ul>
            <li><em>‚ÄúClassifier type‚Äù</em>: <code class="language-plaintext highlighter-rouge">Nearest Neighbors</code>
              <ul>
                <li><em>‚ÄúSelect input type‚Äù</em>: <code class="language-plaintext highlighter-rouge">tabular data</code>
                  <ul>
                    <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúTraining samples dataset‚Äù</em>: <code class="language-plaintext highlighter-rouge">train_rows</code></li>
                    <li><i class="far fa-check-square" aria-hidden="true"></i><span class="visually-hidden">param-check</span> <em>‚ÄúDoes the dataset contain header‚Äù</em>: <code class="language-plaintext highlighter-rouge">Yes</code></li>
                    <li><i class="fas fa-filter" aria-hidden="true"></i><span class="visually-hidden">param-select</span> <em>‚ÄúChoose how to select data by column‚Äù</em>: <code class="language-plaintext highlighter-rouge">All columns EXCLUDING some by column header name(s)</code>
                      <ul>
                        <li><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">param-text</span> <em>‚ÄúType header name(s)‚Äù</em>: <code class="language-plaintext highlighter-rouge">Class</code></li>
                      </ul>
                    </li>
                    <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúDataset containing class labels‚Äù</em>: <code class="language-plaintext highlighter-rouge">train_rows</code></li>
                    <li><i class="far fa-check-square" aria-hidden="true"></i><span class="visually-hidden">param-check</span> <em>‚ÄúDoes the dataset contain header‚Äù</em>: <code class="language-plaintext highlighter-rouge">Yes</code></li>
                    <li><i class="fas fa-filter" aria-hidden="true"></i><span class="visually-hidden">param-select</span> <em>‚ÄúChoose how to select data by column‚Äù</em>: <code class="language-plaintext highlighter-rouge">Select columns by column header name(s)</code>
                      <ul>
                        <li><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">param-text</span> <em>‚ÄúSelect target column(s)‚Äù</em>: <code class="language-plaintext highlighter-rouge">Class</code></li>
                      </ul>
                    </li>
                    <li><i class="fas fa-filter" aria-hidden="true"></i><span class="visually-hidden">param-select</span> <em>‚ÄúNeighbor selection method‚Äù</em>: <code class="language-plaintext highlighter-rouge">k-nearest neighbors</code></li>
                  </ul>
                </li>
              </ul>
            </li>
          </ul>
        </li>
      </ul>
    </li>
    <li>Rename the generated file to <code class="language-plaintext highlighter-rouge">NearestNeighbors_model</code></li>
  </ol>
</blockquote>

<blockquote class="question">
  <h3 id="question-question-3"><i class="far fa-question-circle" aria-hidden="true"></i><span class="visually-hidden">question</span> Question</h3>

  <p>What is the value of k (number of neighbors) for the model?</p>

  <blockquote class="solution">
    <h3 id="solution-solution-3"><i class="far fa-eye" aria-hidden="true"></i><span class="visually-hidden">solution</span> Solution</h3>
    <p>As you can see in the Advanced Options, the default value for the number of neighbors is 5, and we used the default value. You can set this parameter based on your problem and data.</p>

  </blockquote>
</blockquote>

<p>Now, we should evaluate the performance on the test dataset to find out whether the KNN classifier is a good model from the training dataset or not.</p>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-predict-class-using-the-k-nearest-neighbor-classifier"><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Predict class using the k-nearest neighbor classifier</h3>

  <ol>
    <li><strong>Nearest Neighbors Classification</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span> with the following parameters to predict targets of test dataset using the trained model:
      <ul>
        <li><em>‚ÄúSelect a Classification Task‚Äù</em>: <code class="language-plaintext highlighter-rouge">Load a model and predict</code>
          <ul>
            <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúModels‚Äù</em>: <code class="language-plaintext highlighter-rouge">NearestNeighbors_model</code></li>
            <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúData (tabular)‚Äù</em>: <code class="language-plaintext highlighter-rouge">test_rows</code></li>
            <li><i class="far fa-check-square" aria-hidden="true"></i><span class="visually-hidden">param-check</span> <em>‚ÄúDoes the dataset contain header‚Äù</em>: <code class="language-plaintext highlighter-rouge">Yes</code></li>
            <li><i class="fas fa-filter" aria-hidden="true"></i><span class="visually-hidden">param-select</span> <em>‚ÄúSelect the type of prediction‚Äù</em>: <code class="language-plaintext highlighter-rouge">Predict class labels</code></li>
          </ul>
        </li>
      </ul>
    </li>
    <li>Rename the generated file to <code class="language-plaintext highlighter-rouge">NearestNeighbors_result</code></li>
  </ol>
</blockquote>

<p>Now we visualize and analyze the classification. As you can see, <code class="language-plaintext highlighter-rouge">NearestNeighbors_result</code> has a header, so use <code class="language-plaintext highlighter-rouge">test_rows_labels</code> to compare.</p>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-check-and-visualize-the-classification-1"><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Check and visualize the classification</h3>
  <ol>
    <li><strong>Plot confusion matrix, precision, recall and ROC and AUC curves</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span> with the following parameters to visualize the classification:
      <ul>
        <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúSelect input data file‚Äù</em>: <code class="language-plaintext highlighter-rouge">test_rows_labels</code></li>
        <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúSelect predicted data file‚Äù</em>: <code class="language-plaintext highlighter-rouge">NearestNeighbors_result</code></li>
        <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúSelect trained model‚Äù</em>: <code class="language-plaintext highlighter-rouge">NearestNeighbors_model</code></li>
      </ul>
    </li>
  </ol>
</blockquote>

<p>The visualization tool creates diagrams for the Confusion matrix, Precision, recall and F1 score, Receiver operator characteristics (ROC) and area under ROC (AUC) as follows:</p>

<figure id="figure-5"><img src="images/confusion_matrix_NN.png" alt="confusion_matrix" /><figcaption><span class="figcaption-prefix">Figure 5:</span> Confusion matrix for the k-nearest neighbor classifier.</figcaption></figure>

<figure id="figure-6"><img src="images/precision_recall_NN.png" alt="prf1_scores" /><figcaption><span class="figcaption-prefix">Figure 6:</span> Precision, recall and F1 score for the k-nearest neighbor classifier.</figcaption></figure>

<figure id="figure-7"><img src="images/roc_NN.png" alt="roc_scores" /><figcaption><span class="figcaption-prefix">Figure 7:</span> Receiver operator characteristics (ROC) and area under ROC (AUC) for the k-nearest neighbor classifier.</figcaption></figure>

<h1 id="support-vector-machines-svm">Support Vector Machines (SVM)</h1>

<p><a href="https://en.wikipedia.org/wiki/Support-vector_machine">Support Vector Machines</a> (SVMs) have been extensively researched in the machine learning community for the last decade and actively applied to applications in various domains such as bioinformatics. SVM is a generalization of a classifier called maximal margin classifier and is introduced as a binary classifier intended to separate two classes when obtaining the optimal hyperplane and decision boundary. SVMs are based on the assumption that the input data can be linearly separable in a geometric space. The maximal margin classifier is simple, but it cannot be applied to the majority of datasets, since the classes must be separated by a linear boundary and this is often not the case when working with real world data. That is why the support vector classifier was introduced as an extension of the maximal margin classifier, which can be applied in a broader range of cases.</p>

<p>To solve this problem, SVM uses kernel functions to map the input to a high dimension feature space, i.e hyperplane, where a linear decision boundary is constructed in such a manner that the boundary maximises the margin between two classes. The kernel approach is simply an efficient computational approach for accommodating a non-linear boundary between classes.</p>

<p>Without going into technical details, a kernel is a function that quantifies the similarity of two observations. Two special properties of SVMs are that SVMs achieve (1) high generalization by maximizing the margin and (2) support an efficient learning of nonlinear functions by
kernel trick. In the next step, we will build a SVM classifier with our data.</p>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-train-a-svm-classifier"><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Train a SVM classifier</h3>

  <ol>
    <li><strong>Support vector machines (SVMs)</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span> with the following parameters to train the regressor:
      <ul>
        <li><em>‚ÄúSelect a Classification Task‚Äù</em>: <code class="language-plaintext highlighter-rouge">Train a model</code>
          <ul>
            <li><em>‚ÄúSelect a linear method‚Äù</em>: <code class="language-plaintext highlighter-rouge">Linear Support Vector Classification</code>
              <ul>
                <li><em>‚ÄúSelect input type‚Äù</em>: <code class="language-plaintext highlighter-rouge">tabular data</code>
                  <ul>
                    <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúTraining samples dataset‚Äù</em>: <code class="language-plaintext highlighter-rouge">train_rows</code></li>
                    <li><i class="far fa-check-square" aria-hidden="true"></i><span class="visually-hidden">param-check</span> <em>‚ÄúDoes the dataset contain header‚Äù</em>: <code class="language-plaintext highlighter-rouge">Yes</code></li>
                    <li><i class="fas fa-filter" aria-hidden="true"></i><span class="visually-hidden">param-select</span> <em>‚ÄúChoose how to select data by column‚Äù</em>: <code class="language-plaintext highlighter-rouge">All columns EXCLUDING some by column header name(s)</code>
                      <ul>
                        <li><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">param-text</span> <em>‚ÄúType header name(s)‚Äù</em>: <code class="language-plaintext highlighter-rouge">Class</code></li>
                      </ul>
                    </li>
                    <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúDataset containing class labels‚Äù</em>: <code class="language-plaintext highlighter-rouge">train_rows</code></li>
                    <li><i class="far fa-check-square" aria-hidden="true"></i><span class="visually-hidden">param-check</span> <em>‚ÄúDoes the dataset contain header‚Äù</em>: <code class="language-plaintext highlighter-rouge">Yes</code></li>
                    <li><i class="fas fa-filter" aria-hidden="true"></i><span class="visually-hidden">param-select</span> <em>‚ÄúChoose how to select data by column‚Äù</em>: <code class="language-plaintext highlighter-rouge">Select columns by column header name(s)</code>
                      <ul>
                        <li><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">param-text</span> <em>‚ÄúSelect target column(s)‚Äù</em>: <code class="language-plaintext highlighter-rouge">Class</code></li>
                      </ul>
                    </li>
                  </ul>
                </li>
              </ul>
            </li>
          </ul>
        </li>
      </ul>
    </li>
    <li>Rename the generated file to <code class="language-plaintext highlighter-rouge">SVM_model</code></li>
  </ol>
</blockquote>

<blockquote class="question">
  <h3 id="question-question-4"><i class="far fa-question-circle" aria-hidden="true"></i><span class="visually-hidden">question</span> Question</h3>

  <p>What is learned by the support vector machines?</p>

  <blockquote class="solution">
    <h3 id="solution-solution-4"><i class="far fa-eye" aria-hidden="true"></i><span class="visually-hidden">solution</span> Solution</h3>

    <p>The coefficients of the line with the maximal margin in the kernel space is learned in the training phase.</p>

  </blockquote>

</blockquote>

<p>Now we will evaluate the performance of the SVM classifier:</p>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-predict-class-svm-classifier"><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Predict class SVM classifier</h3>

  <ol>
    <li><strong>Support vector machines (SVMs)</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span> with the following parameters to predict targets of test dataset using the trained model:
      <ul>
        <li><em>‚ÄúSelect a Classification Task‚Äù</em>: <code class="language-plaintext highlighter-rouge">Load a model and predict</code>
          <ul>
            <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúModels‚Äù</em>: <code class="language-plaintext highlighter-rouge">SVM_model</code></li>
            <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúData (tabular)‚Äù</em>: <code class="language-plaintext highlighter-rouge">test_rows</code></li>
            <li><i class="far fa-check-square" aria-hidden="true"></i><span class="visually-hidden">param-check</span> <em>‚ÄúDoes the dataset contain header‚Äù</em>: <code class="language-plaintext highlighter-rouge">Yes</code></li>
            <li><i class="fas fa-filter" aria-hidden="true"></i><span class="visually-hidden">param-select</span> <em>‚ÄúSelect the type of prediction‚Äù</em>: <code class="language-plaintext highlighter-rouge">Predict class labels</code></li>
          </ul>
        </li>
      </ul>
    </li>
    <li>Rename the generated file to <code class="language-plaintext highlighter-rouge">SVM_result</code></li>
  </ol>
</blockquote>

<p>Now let‚Äôs visualize the results:</p>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-check-and-visualize-the-classification-2"><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Check and visualize the classification</h3>
  <ol>
    <li><strong>Plot confusion matrix, precision, recall and ROC and AUC curves</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span> with the following parameters to visualize the classification:
      <ul>
        <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúSelect input data file‚Äù</em>: <code class="language-plaintext highlighter-rouge">test_rows_labels</code></li>
        <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúSelect predicted data file‚Äù</em>: <code class="language-plaintext highlighter-rouge">SVM_result</code></li>
        <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúSelect trained model‚Äù</em>: <code class="language-plaintext highlighter-rouge">SVM_model</code></li>
      </ul>
    </li>
  </ol>
</blockquote>

<p>The visualization tool creates the following ROC plot:</p>

<figure id="figure-8"><img src="images/roc_svm.png" alt="roc_scores" /><figcaption><span class="figcaption-prefix">Figure 8:</span> Receiver operator characteristics (ROC) and area under ROC (AUC) for the SVM classifier.</figcaption></figure>

<h1 id="random-forest">Random Forest</h1>

<p><a href="https://en.wikipedia.org/wiki/Random_forest">Random forest</a> is an ensemble of decision trees, and usually trained with the ‚Äúbagging‚Äù method. The <a href="https://scikit-learn.org/stable/modules/ensemble.html#ensemble">Ensemble</a> method uses multiple learning models inte<span class="notranslate">rna</span>lly for better predictions and the general idea of the bagging method is that a combination of learning models increases the overall result. It uses multiple decision tree regressors inte<span class="notranslate">rna</span>lly and predicts by taking the collective performances of the predictions by multiple decision trees. It has a good predictive power and is robust to outliers. It creates an ensemble of weak learners (decision trees) and iteratively minimizes error.</p>

<p>One big advantage of random forest is that it can be used for both classification and regression problems. The main idea behind the random forest is adding additional randomness to the model, while growing the trees and instead of searching for the most important feature while splitting a node, it searches for the best feature among a random subset of features. This results in a better model because of wide diversity. Generally, the more trees in the forest, the more robust the model. Therefore, when using the random forest classifier, a larger number of trees in the forest gives higher accuracy results. Similarly there are two stages in the random forest algorithm: one is random forest creation, the other is to make a prediction from the random forest classifier created in the first stage.</p>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-train-random-forest"><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Train random forest</h3>

  <ol>
    <li><strong>Ensemble methods</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span> with the following parameters to train the regressor:
      <ul>
        <li><em>‚ÄúSelect a Classification Task‚Äù</em>: <code class="language-plaintext highlighter-rouge">Train a model</code>
          <ul>
            <li><em>‚ÄúSelect an ensemble method‚Äù</em>: <code class="language-plaintext highlighter-rouge">Random forest classifier</code>
              <ul>
                <li><em>‚ÄúSelect input type‚Äù</em>: <code class="language-plaintext highlighter-rouge">tabular data</code>
                  <ul>
                    <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúTraining samples dataset‚Äù</em>: <code class="language-plaintext highlighter-rouge">train_rows</code></li>
                    <li><i class="far fa-check-square" aria-hidden="true"></i><span class="visually-hidden">param-check</span> <em>‚ÄúDoes the dataset contain header‚Äù</em>: <code class="language-plaintext highlighter-rouge">Yes</code></li>
                    <li><i class="fas fa-filter" aria-hidden="true"></i><span class="visually-hidden">param-select</span> <em>‚ÄúChoose how to select data by column‚Äù</em>: <code class="language-plaintext highlighter-rouge">All columns EXCLUDING some by column header name(s)</code>
                      <ul>
                        <li><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">param-text</span> <em>‚ÄúType header name(s)‚Äù</em>: <code class="language-plaintext highlighter-rouge">Class</code></li>
                      </ul>
                    </li>
                    <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúDataset containing class labels‚Äù</em>: <code class="language-plaintext highlighter-rouge">train_rows</code></li>
                    <li><i class="far fa-check-square" aria-hidden="true"></i><span class="visually-hidden">param-check</span> <em>‚ÄúDoes the dataset contain header‚Äù</em>: <code class="language-plaintext highlighter-rouge">Yes</code></li>
                    <li><i class="fas fa-filter" aria-hidden="true"></i><span class="visually-hidden">param-select</span> <em>‚ÄúChoose how to select data by column‚Äù</em>: <code class="language-plaintext highlighter-rouge">Select columns by column header name(s)</code>
                      <ul>
                        <li><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">param-text</span> <em>‚ÄúSelect target column(s)‚Äù</em>: <code class="language-plaintext highlighter-rouge">Class</code></li>
                      </ul>
                    </li>
                  </ul>
                </li>
              </ul>
            </li>
          </ul>
        </li>
      </ul>
    </li>
    <li>Rename the generated file to <code class="language-plaintext highlighter-rouge">RandomForest_model</code></li>
  </ol>
</blockquote>

<blockquote class="question">
  <h3 id="question-question-5"><i class="far fa-question-circle" aria-hidden="true"></i><span class="visually-hidden">question</span> Question</h3>

  <p>What are the advantages of random forest classifier compared with KNN and SVM?</p>

  <blockquote class="solution">
    <h3 id="solution-solution-5"><i class="far fa-eye" aria-hidden="true"></i><span class="visually-hidden">solution</span> Solution</h3>
    <ol>
      <li>The overfitting problem will never arise when we use the random forest algorithm in any classification problem.</li>
      <li>The same random forest algorithm can be used for both classification and regression task.</li>
      <li>The random forest algorithm can be used for feature engineering, which means identifying the most important features out of the available features from the training dataset.</li>
    </ol>
  </blockquote>

</blockquote>

<p>After learning on the training dataset, we should evaluate the performance on the test dataset.</p>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-predict-targets-using-the-random-forest"><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Predict targets using the random forest</h3>

  <ol>
    <li><strong>Ensemble methods</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span> with the following parameters to predict targets of test dataset using the trained model:
      <ul>
        <li><em>‚ÄúSelect a Classification Task‚Äù</em>: <code class="language-plaintext highlighter-rouge">Load a model and predict</code>
          <ul>
            <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúModels‚Äù</em>: <code class="language-plaintext highlighter-rouge">RandomForest_model</code></li>
            <li><i class="far fa-file" aria-hidden="true"></i><span class="visually-hidden">param-file</span> <em>‚ÄúData (tabular)‚Äù</em>: <code class="language-plaintext highlighter-rouge">test_rows</code></li>
            <li><i class="far fa-check-square" aria-hidden="true"></i><span class="visually-hidden">param-check</span> <em>‚ÄúDoes the dataset contain header‚Äù</em>: <code class="language-plaintext highlighter-rouge">Yes</code></li>
            <li><i class="fas fa-filter" aria-hidden="true"></i><span class="visually-hidden">param-select</span> <em>‚ÄúSelect the type of prediction‚Äù</em>: <code class="language-plaintext highlighter-rouge">Predict class labels</code></li>
          </ul>
        </li>
      </ul>
    </li>
    <li>Rename the generated file to <code class="language-plaintext highlighter-rouge">RandomForest_result</code></li>
  </ol>
</blockquote>

<p>The visualization tool creates the following ROC plot:</p>

<figure id="figure-9"><img src="images/roc_rf.png" alt="roc_scores" /><figcaption><span class="figcaption-prefix">Figure 9:</span> Receiver operator characteristics (ROC) and area under ROC (AUC) for the random forest classifier.</figcaption></figure>

<blockquote class="question">
  <h3 id="question-question-6"><i class="far fa-question-circle" aria-hidden="true"></i><span class="visually-hidden">question</span> Question</h3>

  <p>Inspect the plots. What can you say about the classification?</p>

  <blockquote class="solution">
    <h3 id="solution-solution-6"><i class="far fa-eye" aria-hidden="true"></i><span class="visually-hidden">solution</span> Solution</h3>

    <p>Figures show that we achieved an AUC score of <code class="language-plaintext highlighter-rouge">1.0</code>  for the test set using random forest. It means the prediction is very good, in fact it has no error at all. Unfortunately, this is not usually the case when dealing with chemical data.</p>
  </blockquote>
</blockquote>

<h1 id="create-data-processing-pipeline">Create data processing pipeline</h1>

<p>At the last step, we will create a bagging classifier by using  the <strong>Pipeline builder</strong> tool. Bagging or Bootstrap Aggregating is a widely used ensemble learning algorithm in machine learning. The bagging algorithm creates multiple models from randomly taken subsets of the training dataset and then aggregates learners to build overall stronger classifiers that combine the predictions to produce a final prediction. The <strong>Pipeline builder</strong> tool builds the classifier and returns a zipped file. This tool creates another file which is tabular and contains a list of all the different hyperparameters of the preprocessors and estimators. This tabular file will be used in the <strong>Hyperparameter search</strong> tool to populate the list of hyperparameters with their respective (default) values.</p>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-create-pipeline"><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Create pipeline</h3>

  <ol>
    <li><strong>Pipeline builder</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span> with the following parameters:
      <ul>
        <li>In <em>‚ÄúFinal Estimator‚Äù</em>:
          <ul>
            <li><em>‚ÄúChoose the module that contains target estimator‚Äù</em>: <code class="language-plaintext highlighter-rouge">sklearn.ensemble</code>
              <ul>
                <li><em>‚ÄúChoose estimator class‚Äù</em>: <code class="language-plaintext highlighter-rouge">BaggingClassifier</code></li>
              </ul>
            </li>
          </ul>
        </li>
        <li>
          <p>In <em>‚ÄúOutput parameters for searchCV?‚Äù</em>: <code class="language-plaintext highlighter-rouge">Yes</code></p>

          <p>We choose <code class="language-plaintext highlighter-rouge">Final Estimator</code> as we have only the estimator and no preprocessor and need the parameters of only the estimator.</p>
        </li>
      </ul>
    </li>
  </ol>

</blockquote>

<h2 id="search-for-the-best-values-of-hyperparameters">Search for the best values of hyperparameters</h2>

<p>After extracting the parameter names from the <strong>Pipeline builder</strong> file, we will use the <strong>Hyperparameter search</strong> tool to find the best values for each hyperparameter. These values will lead us to create the best model based on the search space chosen for each hyperparameter. We use only one parameter <code class="language-plaintext highlighter-rouge">n_estimators</code> of <code class="language-plaintext highlighter-rouge">BaggingClassifier</code> for this task. This parameter specifies the number of bagging stages the learning process has to go through. The default value of <code class="language-plaintext highlighter-rouge">n_estimators</code> for this regressor is <code class="language-plaintext highlighter-rouge">10</code>. However, we are not sure if this gives the best accuracy. Therefore, it is important to set this parameter to different values to find the optimal one. We choose a value which is less than <code class="language-plaintext highlighter-rouge">10</code> and a few which are more than <code class="language-plaintext highlighter-rouge">10</code>. The hyperparameter search will look for the optimal number of estimators and gives the best-trained model as one of the outputs. This model is used in the next step to classify the test dataset.</p>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-hyperparameter-search"><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Hyperparameter search</h3>

  <ol>
    <li><strong>Hyperparameter search</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span> with the following parameters:
      <ul>
        <li><em>‚ÄúSelect a model selection search scheme‚Äù</em>: <code class="language-plaintext highlighter-rouge">GridSearchCV - Exhaustive search over specified parameter values for an estimator </code>
          <ul>
            <li><i class="far fa-copy" aria-hidden="true"></i><span class="visually-hidden">param-files</span> <em>‚ÄúChoose the dataset containing pipeline/estimator object‚Äù</em>: <code class="language-plaintext highlighter-rouge">zipped</code> file (output of <strong>Pipeline builder</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span>)</li>
            <li><i class="far fa-copy" aria-hidden="true"></i><span class="visually-hidden">param-files</span> <em>‚ÄúIs the estimator a deep learning model?‚Äù</em>: <code class="language-plaintext highlighter-rouge">NO</code> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span>)</li>
            <li>In <em>‚ÄúSearch parameters Builder‚Äù</em>:
              <ul>
                <li><i class="far fa-copy" aria-hidden="true"></i><span class="visually-hidden">param-files</span> <em>‚ÄúChoose the dataset containing parameter names‚Äù</em>: <code class="language-plaintext highlighter-rouge">tabular</code> file (output of <strong>Estimator attributes</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span>)</li>
                <li>In <em>‚ÄúParameter settings for search‚Äù</em>:
                  <ul>
                    <li><i class="far fa-plus-square" aria-hidden="true"></i><span class="visually-hidden">param-repeat</span> <em>‚Äú1: Parameter settings for search‚Äù</em>
                      <ul>
                        <li><em>‚ÄúChoose a parameter name (with current value)‚Äù</em>: <code class="language-plaintext highlighter-rouge">n_estimators: 10</code></li>
                        <li><em>‚ÄúSearch list‚Äù</em>: <code class="language-plaintext highlighter-rouge">[5,10,20,50]</code></li>
                      </ul>
                    </li>
                  </ul>
                </li>
              </ul>
            </li>
          </ul>
        </li>
        <li><em>‚ÄúSelect input type‚Äù</em>: <code class="language-plaintext highlighter-rouge">tabular data</code>
          <ul>
            <li><i class="far fa-copy" aria-hidden="true"></i><span class="visually-hidden">param-files</span> <em>‚ÄúTraining samples dataset‚Äù</em>: <code class="language-plaintext highlighter-rouge">train_rows</code> tabular file</li>
            <li><em>‚ÄúDoes the dataset contain header‚Äù</em>: <code class="language-plaintext highlighter-rouge">Yes</code></li>
            <li><em>‚ÄúChoose how to select data by column‚Äù</em>: <code class="language-plaintext highlighter-rouge">All columns BUT by column header name(s)</code>
              <ul>
                <li><em>‚ÄúType header name(s)‚Äù</em>: <code class="language-plaintext highlighter-rouge">Class</code></li>
              </ul>
            </li>
            <li><i class="far fa-copy" aria-hidden="true"></i><span class="visually-hidden">param-files</span> <em>‚ÄúDataset containing class labels or target values‚Äù</em>: <code class="language-plaintext highlighter-rouge">train_rows</code> tabular file</li>
            <li><em>‚ÄúDoes the dataset contain header‚Äù</em>: <code class="language-plaintext highlighter-rouge">Yes</code></li>
            <li><em>‚ÄúChoose how to select data by column‚Äù</em>: <code class="language-plaintext highlighter-rouge">Select columns by column header name(s)</code>
              <ul>
                <li><em>‚ÄúType header name(s)‚Äù</em>: <code class="language-plaintext highlighter-rouge">Class</code></li>
              </ul>
            </li>
          </ul>
        </li>
        <li><em>‚ÄúWhether to hold a portion of samples for test exclusively?‚Äù</em>: <code class="language-plaintext highlighter-rouge">Nope</code></li>
        <li><em>‚ÄúSave best estimator?‚Äù</em>: <code class="language-plaintext highlighter-rouge">Fitted best estimator or Detailed cv_results_from nested CV</code></li>
      </ul>
    </li>
  </ol>

</blockquote>

<blockquote class="question">
  <h3 id="question-question-7"><i class="far fa-question-circle" aria-hidden="true"></i><span class="visually-hidden">question</span> Question</h3>

  <p>What is the optimal number of estimators for the given dataset?</p>

  <p>Hint: Please look at the <code class="language-plaintext highlighter-rouge">mean_test_score</code> column in the tabular result from the <strong>Hyperparameter search</strong> tool.</p>

  <blockquote class="solution">
    <h3 id="solution-solution-7"><i class="far fa-eye" aria-hidden="true"></i><span class="visually-hidden">solution</span> Solution</h3>

    <p>20 - even though the default value of the number of estimators for Bagging Classifier is <code class="language-plaintext highlighter-rouge">10</code>, <code class="language-plaintext highlighter-rouge">20</code> gives the best accuracy. That‚Äôs why it is important to perform hyperparameter search to tune these parameters for any dataset.</p>

  </blockquote>

</blockquote>

<p>Using the <strong>Hyperparameter search</strong> tool, we found the best model, based on the training data. Now, we will predict age in the test dataset using this model.</p>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-predict-age"><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Predict age</h3>

  <ol>
    <li><strong>Ensemble methods for classification and regression</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span> with the following parameters:
      <ul>
        <li><em>‚ÄúSelect a Classification Task‚Äù</em>: <code class="language-plaintext highlighter-rouge">Load a model and predict</code>
          <ul>
            <li><i class="far fa-copy" aria-hidden="true"></i><span class="visually-hidden">param-files</span> <em>‚ÄúModels‚Äù</em>: <code class="language-plaintext highlighter-rouge">zipped</code> file (output of <strong>Hyperparameter search</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span>)</li>
            <li><i class="far fa-copy" aria-hidden="true"></i><span class="visually-hidden">param-files</span> <em>‚ÄúData (tabular)‚Äù</em>: <code class="language-plaintext highlighter-rouge">test_rows</code> tabular file</li>
            <li><em>‚ÄúDoes the dataset contain header‚Äù</em>: <code class="language-plaintext highlighter-rouge">Yes</code></li>
          </ul>
        </li>
      </ul>
    </li>
  </ol>

</blockquote>

<p>Now we will verify the performance by creating and inspecting the plots:</p>

<figure id="figure-10"><img src="images/confusion_matrix_bagging.png" alt="confusion_matrix" /><figcaption><span class="figcaption-prefix">Figure 10:</span> Confusion matrix for the bagging classifier.</figcaption></figure>

<figure id="figure-11"><img src="images/precision_recall_bagging.png" alt="prf1_scores" /><figcaption><span class="figcaption-prefix">Figure 11:</span> Precision, recall and F1 score for the bagging classifier.</figcaption></figure>

<figure id="figure-12"><img src="images/roc_bagging.png" alt="roc_scores" /><figcaption><span class="figcaption-prefix">Figure 12:</span> Residual plot between residual (predicted - true) and predicted targets. The plot shows a random pattern of points.</figcaption></figure>

<p>Figure 13 shows that we again achieved an AUC value of <code class="language-plaintext highlighter-rouge">1.00</code>, which shows that our model is highly effective at predicting whether or not a molecule is biodegradable.</p>

<h1 id="conclusion">Conclusion</h1>
<p>By following these steps, we learned how to build classifiers and visualize the classification results using <span class="notranslate">Galaxy</span>‚Äôs machine learning and plotting tools. The features of the training dataset are mapped to the classes. This <span class="notranslate">mapping</span> is used to make predictions on an unseen (test) dataset. The quality of classifiers is visualized using a plotting tool.</p>

<p>There are multiple other classification algorithms, a few are simpler to use (with fewer parameters) and some are more powerful, which can be tried out on this dataset and on other datasets as well. Different datasets can also be analyzed using these classifiers. The classifiers have many parameters which can be altered while performing the analyses to see if they affect the classification accuracy. It may be beneficial to perform a hyperparameter search to tune these parameters for different datasets. In addition, we learned the relevance of machine algorithms for QSAR analyses and constructed a model which successfully predicted an important chemical property - the biodegradability of a substance.</p>


                    
                    <blockquote class="key_points">
                        <h3><i class="fas fa-key" aria-hidden="true"></i><span class="visually-hidden">keypoints</span> Key points</h3>
                        <ul>
                            
                            <li><p>Classification is a supervised approach in machine learning.</p>
</li>
                            
                            <li><p>For classification tasks, data is divided into training and test sets.</p>
</li>
                            
                            <li><p>Using classification, the samples are learned using the training set and predicted using the test set.</p>
</li>
                            
                            <li><p>For each classification algorithm, it parameters should be optimised based on the dataset.</p>
</li>
                            
                            <li><p>Machine learning algorithms can be applied to chemical datasets to predict important properties.</p>
</li>
                            
                        </ul>
                    </blockquote>
                    

                    

                    

                    <h1>Feedback</h1>
                    <p class="text-muted">Did you use this material as an instructor? Feel free to give us feedback on <a href="https://github.com/galaxyproject/training-material/issues/1452" target="_blank">how it went</a>.</p>

                    <div id="feedback-button">
                        <img src="/training-material/shared/images/feedback.png" title="Click to activate" alt="Click here to load Google feedback frame" />
                    </div>
                    <div id="feedback-form">
                    </div>
                    <script type="text/javascript">
                        (function (window, document) {
                            function onDocumentReady(fn) {
                                if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
                                    fn();
                                } else {
                                    document.addEventListener('DOMContentLoaded', fn);
                                }
                            }

                            onDocumentReady(function () {
                                $("#feedback-button").click(function(evt){
                                    var e = $(evt.target)
                                    e.hide();

                                    $("#feedback-form").html(`
                                        <iframe id="feedback-google" class="google-form" src="https://docs.google.com/forms/d/e/1FAIpQLSd4VZptFTQ03kHkMz0JyW9b6_S8geU5KjNE_tLM0dixT3ZQmA/viewform?embedded=true&entry.1235803833=Classification in Machine Learning (Statistics and machine learning)">Loading...</iframe>
                                    `)
                                })
                            });
                        })(window, document);
                    </script>



                    <h1>Citing this Tutorial</h1>
                    <p>
                        <ol>
                            <li id="citation-text">Alireza Khanteymoori, Anup Kumar, Simon Bray, 2021 <b>Classification in Machine Learning (Galaxy Training Materials)</b>. <a href="/training-material/topics/statistics/tutorials/classification_machinelearning/tutorial.html">/training-material/topics/statistics/tutorials/classification_machinelearning/tutorial.html</a> Online; accessed TODAY
                            </li>
                            <li>
                            Batut et al., 2018 <b>Community-Driven Data Analysis Training for Biology</b> Cell Systems <a href="https://doi.org/10.1016%2Fj.cels.2018.05.012">10.1016/j.cels.2018.05.012</a>
                            </li>
                        </ol>
                    </p>


                    <blockquote class="details">
                      <h3><i class="fa fa-info-circle" aria-hidden="true"></i><span class="visually-hidden">details</span> BibTeX</h3>
                      <p style="display: none;">

                    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight">
<code id="citation-code">@misc{statistics-classification_machinelearning,
    author = "Alireza Khanteymoori and Anup Kumar and Simon Bray",
    title = "Classification in Machine Learning (Galaxy Training Materials)",
    year = "2021",
    month = "01",
    day = "06"
    url = "\url{/training-material/topics/statistics/tutorials/classification_machinelearning/tutorial.html}",
    note = "[Online; accessed TODAY]"
}
@article{Batut_2018,
        doi = {10.1016/j.cels.2018.05.012},
        url = {https://doi.org/10.1016%2Fj.cels.2018.05.012},
        year = 2018,
        month = {jun},
        publisher = {Elsevier {BV}},
        volume = {6},
        number = {6},
        pages = {752--758.e1},
        author = {B{\'{e}}r{\'{e}}nice Batut and Saskia Hiltemann and Andrea Bagnacani and Dannon Baker and Vivek Bhardwaj and Clemens Blank and Anthony Bretaudeau and Loraine Brillet-Gu{\'{e}}guen and Martin {\v{C}}ech and John Chilton and Dave Clements and Olivia Doppelt-Azeroual and Anika Erxleben and Mallory Ann Freeberg and Simon Gladman and Youri Hoogstrate and Hans-Rudolf Hotz and Torsten Houwaart and Pratik Jagtap and Delphine Larivi{\`{e}}re and Gildas Le Corguill{\'{e}} and Thomas Manke and Fabien Mareuil and Fidel Ram{\'{\i}}rez and Devon Ryan and Florian Christoph Sigloch and Nicola Soranzo and Joachim Wolff and Pavankumar Videm and Markus Wolfien and Aisanjiang Wubuli and Dilmurat Yusuf and James Taylor and Rolf Backofen and Anton Nekrutenko and Bj√∂rn Gr√ºning},
        title = {Community-Driven Data Analysis Training for Biology},
        journal = {Cell Systems}
}</code>
                    </pre></div></div>
                    </p>
                    </blockquote>


<script type="text/javascript">
// update the date on load, or leave fallback of 'today'
d = new Date();
document.getElementById("citation-code").innerHTML = document.getElementById("citation-code").innerHTML.replace("TODAY", d.toDateString());
document.getElementById("citation-text").innerHTML = document.getElementById("citation-text").innerHTML.replace("TODAY", d.toDateString());
</script>

                </div>
            </div>
        </div>

        <h3><i class="far fa-thumbs-up" aria-hidden="true"></i><span class="visually-hidden">congratulations</span> Congratulations on successfully completing this tutorial!</h3>

        

        
    </section>
</div>


<footer>
    <div class="container">
        <p>
            This material is the result of a collaborative work. Thanks to the
            <a href="https://wiki.galaxyproject.org/Teach/GTN">Galaxy Training Network</a>
            and all the <a href="/training-material/hall-of-fame">contributors</a> (Alireza Khanteymoori, Anup Kumar, Simon Bray)!
        </p>
        <p>
            Found a typo? Something is wrong in this tutorial? Edit it on
            <a href="https://github.com/galaxyproject/training-material/tree/master/topics/statistics/tutorials/classification_machinelearning/tutorial.md">GitHub</a>.
        </p>
        <p>
    The content of the tutorials and website is licensed under the <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
</p>
    </div>
</footer>

    </body>
    <script type="text/javascript" src="/training-material/assets/js/jquery.slim.min.js"></script>
    <script type="text/javascript" src="/training-material/assets/js/popper.min.js"></script>
    <script type="text/javascript" src="/training-material/assets/js/bootstrap.min.js?v=3"></script>
    <script type="text/javascript" src="/training-material/assets/js/details-element-polyfill.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="/training-material/assets/js/bootstrap-toc.min.js"></script>
    <script type="text/javascript" src="/training-material/assets/js/main.js"></script>
    <script type="text/javascript" src="/training-material/assets/js/theme.js"></script>

    <script type="text/javascript" src="/training-material/assets/js/clipboard.min.js"></script>
    <script type="text/javascript">
    var snippets=document.querySelectorAll('div.highlight');
    [].forEach.call(snippets,function(snippet){
        snippet.firstChild.insertAdjacentHTML('beforebegin','<button class="btn btn-light" data-clipboard-snippet><i class="fa fa-copy"></i>&nbsp;Copy</button>');
    });

    var clipboardSnippets=new ClipboardJS('[data-clipboard-snippet]',{
        target:function(trigger){return trigger.nextElementSibling;
    }});
    </script>
    

    <script type="text/javascript">
        if(window.location.hostname === "galaxyproject.github.io") {
            // Redirect
            var redirect = "https://training.galaxyproject.org" + window.location.pathname + window.location.search;
            $('div.container.main-content').prepend("<div class='alert alert-warning'><strong>Note: </strong>This content has a new home at <a href=\"" + redirect + "\">" + redirect + "</a>, which you will be redirected to in 5 seconds.</div>");

            window.setTimeout(function(){
                window.location.href = redirect;
            }, 5000)

        }
    </script>
</html>
