<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Slide Deck: Slide Deck: Hands-on: Image classification in Galaxy with fruit 360 dataset / Statistics and machine learning</title>
        
            <meta name="google-site-verification" content="9mOXn2JL833-i7-aioCCEuIdG4_tb6qjwUozB5GJnPQ" />

<!-- JavaScript Error Monitoring, and performance tracking. -->
<script
  src="https://browser.sentry-cdn.com/7.52.1/bundle.tracing.min.js"
  integrity="sha384-muuFXKS3752PNA4rPm9Uq6BLvOfV4CXyr9MHDBPvozOJJUWLKkogEFWOIRoVps43"
  crossorigin="anonymous"
></script>
<script type="text/javascript">
if(localStorage.getItem('sentry-opt-out') !== 'opt-out' && navigator.doNotTrack !== "1") {
	console.log("Sentry: opt-in");
	Sentry.init({
		dsn: "https://45e0ec6e4373462b92969505df37cf40@sentry.galaxyproject.org/10",
		release: "galaxy-training-network@a2080641ce5cc103113670367074a642f1dc59af",
		integrations: [new Sentry.BrowserTracing(), new Sentry.Replay()],
		sampleRate: 0.1,
		tracesSampleRate: 0.1,
		// Capture Replay for no sessions by default
		replaysSessionSampleRate: 0.01,
		// plus for 1% of sessions with an error
		replaysOnErrorSampleRate: 0.01,
		// PII OFF
		sendDefaultPii: false, // Off by default but just in case.
		environment: "production",
	});
}
</script>

<!-- Page view tracking -->
<script async defer data-domain="training.galaxyproject.org" src="https://plausible.galaxyproject.eu/js/plausible.js"></script>
<script>
if(localStorage.getItem('plausible-opt-out') !== 'opt-out' && navigator.doNotTrack !== "1") {
	localStorage.removeItem("plausible_ignore")
	console.log("Plausible: opt-in");
} else {
	// if they're opting-out, or DNT
	// we might get one page by accident but we won't get future ones.
	localStorage.setItem("plausible_ignore", "true")
}
</script>

        
        <link rel="shortcut icon" href="/training-material/favicon.ico" type="image/x-icon">
        <link rel="alternate" type="application/atom+xml" href="/training-material/feed.xml">
        <link rel="canonical" href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/fruit_360/slides-plain.html">
        <link rel="license" href="https://spdx.org/licenses/CC-BY-4.0">
        <link rel="preload" href="/training-material/assets/fonts/AtkinsonHyperlegible/Atkinson-Hyperlegible-Regular-102a.woff2" as="font" type="font/woff2" crossorigin>
        <link rel="preload" href="/training-material/assets/fonts/AtkinsonHyperlegible/Atkinson-Hyperlegible-Bold-102a.woff2" as="font" type="font/woff2" crossorigin>
        <link rel="preload" href="/training-material/assets/fonts/AtkinsonHyperlegible/Atkinson-Hyperlegible-Italic-102a.woff2" as="font" type="font/woff2" crossorigin>
        
        <link rel="preload" href="/training-material/assets/css/main.css?v=3" as="style">
        <link rel='preload' href='/training-material/assets/js/bundle.theme.f1f2de89.js' as='script'>
<link rel='preload' href='/training-material/assets/js/bundle.main.105e595f.js' as='script'>
        <link rel="stylesheet" href="/training-material/assets/css/main.css?v=3">
        <link rel="manifest" href="/training-material/manifest.json">
        <meta name="theme-color" content="#2c3143"/>
	

        <meta name="DC.identifier" content="https://github.com/galaxyproject/training-material">
<meta name="DC.type" content="text">
<meta name="DC.title" content="Image classification in Galaxy with fruit 360 dataset">
<meta name="DC.publisher" content="Galaxy Training Network">
<meta name="DC.date" content="2021-12-01 13:21:06 +0000">
<meta name="DC.creator" content="Kaivan Kamali"><meta name="description" content="# What is a convolutional neural network (CNN)?  ???  What is a convolutional neural network (CNN)?  ---  # Convolutional Neural Network (CNN)  - Increasing popularity of social media in past decade  - Image and video processing tasks have become very important - FNN could not scale up to image and video processing tasks - CNN specifically tailored for image and video processing tasks  ---  # Inspiration for CNN  - In 1959 Hubel & Wiesel did an experiment to understand how visual cortex of brain processes visual info  - Recorded activity of neurons in visual cortex of a cat  - While moving a bright line in front of the cat - Some cells fired when bright line is shown at a particular angle/location  - Called these *simple* cells - Other cells fired when bright line was shown regardless of angle/location  - Seemed to detect movement  - Called these *complex* cells - Seemed complex cells receive inputs from multiple simple cells  - Have an hierarchical structure - Hubel and Wiesel won ...">
        <meta property="og:site_name" content="Galaxy Training Network">
	<meta property="og:title" content="Statistics and machine learning / Slide Deck: Hands-on: Image classification in Galaxy with fruit 360 dataset">
        <meta property="og:description" content="# What is a convolutional neural network (CNN)?  ???  What is a convolutional neural network (CNN)?  ---  # Convolutional Neural Network (CNN)  - Increasing popularity of social media in past decade  - Image and video processing tasks have become very important - FNN could not scale up to image and video processing tasks - CNN specifically tailored for image and video processing tasks  ---  # Inspiration for CNN  - In 1959 Hubel & Wiesel did an experiment to understand how visual cortex of brain processes visual info  - Recorded activity of neurons in visual cortex of a cat  - While moving a bright line in front of the cat - Some cells fired when bright line is shown at a particular angle/location  - Called these *simple* cells - Other cells fired when bright line was shown regardless of angle/location  - Seemed to detect movement  - Called these *complex* cells - Seemed complex cells receive inputs from multiple simple cells  - Have an hierarchical structure - Hubel and Wiesel won ...">
        
        <meta property="og:image" content="/training-material/assets/images/GTNLogo1000.png"></head>
    <body data-spy="scroll" data-target="#toc" data-brightness="auto" data-contrast="auto">
        <script  src='/training-material/assets/js/bundle.theme.f1f2de89.js'></script>
        <header>
    <nav class="navbar navbar-expand-md navbar-dark" aria-label="Site Navigation">
        <div class="container">
            <a class="navbar-brand" href="/training-material/">
                <img src="/training-material/assets/images/GTN-60px.png" height="30" alt="Galaxy Training Network logo">
                
                    Galaxy Training!
                
            </a>

            <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#top-navbar" aria-controls="top-navbar" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="top-navbar">
                <ul class="navbar-nav">
                    <li class="nav-item">
                        
			

                        
                    </li>

                    <li class="nav-item">
                        <a class="nav-link" href="/training-material/learning-pathways" title="Learning Pathways">
                           <i class="fas fa-graduation-cap" aria-hidden="true"></i><span class="visually-hidden">curriculum</span> Learning Pathways
                        </a>
                    </li>

                    <li class="nav-item dropdown">
    <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-expanded="false" title="Help">
        <i class="far fa-question-circle" aria-hidden="true"></i><span class="visually-hidden">help</span> Help
    </a>
    <div class="dropdown-menu dropdown-menu-right">
        <!-- disable Tess for now
        <form method="get" action="https://tess.elixir-europe.org/materials">
            <input type="text" id="search" name="q" value="" style="margin-left: 0.5em;/*! border-radius: 0px; */">
            <input type="hidden" value="Galaxy Training" name="content_provider">
            <input type="submit" value="Search on TeSS" style="width: 92%;border-radius: 0px;margin: 0.5em;background: #f47d20;border: 0px;padding: 0.25em;" class="">
        </form>
        -->

	<a class="dropdown-item" href="/training-material/faqs/index.html" title="Check our FAQs">
           <i class="far fa-question-circle" aria-hidden="true"></i><span class="visually-hidden">question</span> FAQs
        </a>
        
        <a class="dropdown-item" href="https://help.galaxyproject.org/" title="Discuss on Galaxy Help">
            <i class="far fa-comments" aria-hidden="true"></i><span class="visually-hidden">feedback</span> Galaxy Help Forum
        </a>
        <a class="dropdown-item" href="https://gitter.im/Galaxy-Training-Network/Lobby" title="Discuss on gitter">
           <i class="fab fa-gitter" aria-hidden="true"></i><span class="visually-hidden">gitter</span> Discuss on Gitter
        </a>
    </div>
</li>


                    <li class="nav-item dropdown">
    <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-expanded="false" title="Settings">
	<i class="fas fa-cog" aria-hidden="true"></i><span class="visually-hidden">galaxy-gear</span> Settings
    </a>
    <div class="dropdown-menu dropdown-menu-right">

	<h6 class="dropdown-header">Preferences</h6>

	<a href="/training-material/user/theme.html" class="dropdown-item">
		<i class="fas fa-palette" aria-hidden="true"></i><span class="visually-hidden">gtn-theme</span> Theme
	</a>

	<a href="/training-material/user/privacy.html" class="dropdown-item">
		<i class="fas fa-lock" aria-hidden="true"></i><span class="visually-hidden">pref-dataprivate</span> Data Privacy
	</a>

	<div class="dropdown-divider"></div>

	<h6 class="dropdown-header">For Everyone</h6>

        <a class="dropdown-item" href="https://github.com/galaxyproject/training-material/edit/main/./topics/statistics/tutorials/fruit_360/slides.html">
          <i class="fab fa-github" aria-hidden="true"></i><span class="visually-hidden">github</span> Propose a change or correction
        </a>

	<h6 class="dropdown-header">Instructor Utilities</h6>

        <a class="dropdown-item" href="/training-material/stats.html">
            <i class="fas fa-chart-bar" aria-hidden="true"></i><span class="visually-hidden">galaxy-barchart</span> GTN statistics
        </a>

        <a class="dropdown-item" href="https://plausible.galaxyproject.eu/training.galaxyproject.org?period=12mo&page=/training-material/topics/statistics/tutorials/fruit_360/slides-plain.html">
            <i class="fas fa-chart-bar" aria-hidden="true"></i><span class="visually-hidden">galaxy-barchart</span> Page View Metrics
        </a>

        <!-- link to feedback -->
        
            <a class="dropdown-item" href="/training-material/feedback.html">
                <i class="fas fa-chart-bar" aria-hidden="true"></i><span class="visually-hidden">galaxy-barchart</span> GTN feedback
            </a>
        

        <div class="dropdown-item">
            <div>
                <i class="fas fa-history" aria-hidden="true"></i><span class="visually-hidden">galaxy-rulebuilder-history</span> Previous Versions
            </div>

            <div id="archive-selector">
            
                <a class="btn btn-warning" href="https://training.galaxyproject.org/archive/">Older Versions</a>
            </div>

        </div>

    </div>
</li>


                    <!-- Search bar-->
                    <li class="nav-item">
                      <div id="navbarSupportedContent" role="search">
                        <!-- Search form -->
                        <form class="form-inline mr-auto" method="GET" action="/training-material/search2">
                          <i class="fas fa-search nav-link" aria-hidden="true"></i>
                          <div class="md-form mb-2">
                            <input name="query" class="form-control nicer" type="text" placeholder="Search Tutorials" aria-label="Search">
                          </div>
                        </form>
                      </div>
                    </li>
                </ul>
            </div>
        </div>
    </nav>
</header>

        
        <div class="container main-content" role="main">
        <section class="tutorial">
	<a href="https://github.com/galaxyproject/training-material/blob/main//topics/statistics/tutorials/fruit_360/slides.html">View markdown source on GitHub</a>
	<h1>Image classification in Galaxy with fruit 360 dataset</h1>
		<h2>Contributors</h2>
<div markdown="0">

	<div class="contributors-line">
		Authors: <a href="/training-material/hall-of-fame/kxk302/" class="contributor-badge contributor-kxk302"><img src="https://avatars.githubusercontent.com/kxk302?s=36" alt="Kaivan Kamali avatar" width="36" class="avatar" />
    Kaivan Kamali</a>
	</div>

</div>


		
		<h2>Questions</h2>
		<ul>
		
		<li><p>How to solve an image classification problem using convolutional neural network (CNN)?</p>
</li>
		
		</ul>
		

		
		<h2>Objectives</h2>
		<ul>
		
		<li><p>Learn how to create a CNN using Galaxy’s deep learning tools</p>
</li>
		
		<li><p>Solve an image classification problem on fruit 360 dataset using CNN in Galaxy</p>
</li>
		
		</ul>
		

		
		<h2>Requirements</h2>
		<ul>
		
		
    <li>
    
        
        
        <a href="/training-material/topics/statistics">Statistics and machine learning</a>
        
            <ul>
                
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                            
                            <li> Hands-on: Hands-on: Deep Learning (Part 3) - Convolutional neural networks (CNN):
                            
                                <a href="/training-material/topics/statistics/tutorials/CNN/slides.html"><i class="fab fa-slideshare" aria-hidden="true"></i><span class="visually-hidden">slides</span> slides</a>
                                
                            
                            
                                
                                    - <a href="/training-material/topics/statistics/tutorials/CNN/tutorial.html"><i class="fas fa-laptop" aria-hidden="true"></i><span class="visually-hidden">tutorial</span> hands-on</a>
                                
                            
                            </li>
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                        
                    
                
            </ul>
        
    
    </li>

		</ul>
		

		<div><strong> <i class="far fa-calendar" aria-hidden="true"></i><span class="visually-hidden">last_modification</span> Published:</strong> Dec 1, 2021 </div>
		<div><strong> <i class="far fa-calendar" aria-hidden="true"></i><span class="visually-hidden">last_modification</span> Last Updated:</strong> Dec 1, 2021 </div>

	<hr />


	<h1 id="what-is-a-convolutional-neural-network-cnn">What is a convolutional neural network (CNN)?</h1>

<p><span>Speaker Notes</span></p>

<p>What is a convolutional neural network (CNN)?</p>

<hr />

<h1 id="convolutional-neural-network-cnn">Convolutional Neural Network (CNN)</h1>

<ul>
  <li>Increasing popularity of social media in past decade
    <ul>
      <li>Image and video processing tasks have become very important</li>
    </ul>
  </li>
  <li>FNN could not scale up to image and video processing tasks</li>
  <li>CNN specifically tailored for image and video processing tasks</li>
</ul>

<hr />

<h1 id="inspiration-for-cnn">Inspiration for CNN</h1>

<ul>
  <li>In 1959 Hubel &amp; Wiesel did an experiment to understand how visual cortex of brain processes visual info
    <ul>
      <li>Recorded activity of neurons in visual cortex of a cat</li>
      <li>While moving a bright line in front of the cat</li>
    </ul>
  </li>
  <li>Some cells fired when bright line is shown at a particular angle/location
    <ul>
      <li>Called these <em>simple</em> cells</li>
    </ul>
  </li>
  <li>Other cells fired when bright line was shown regardless of angle/location
    <ul>
      <li>Seemed to detect movement</li>
      <li>Called these <em>complex</em> cells</li>
    </ul>
  </li>
  <li>Seemed complex cells receive inputs from multiple simple cells
    <ul>
      <li>Have an hierarchical structure</li>
    </ul>
  </li>
  <li>Hubel and Wiesel won Noble prize in 1981</li>
</ul>

<hr />

<h1 id="inspiration-for-cnn-1">Inspiration for CNN</h1>

<ul>
  <li>Inspired by complex/simple cells, Fukushima proposed <em>Neocognitron</em> (1980)
    <ul>
      <li>Hierarchical neural network used for handwritten Japanese character recognition</li>
      <li>First CNN, had its own training algorithm</li>
    </ul>
  </li>
  <li>In 1989, LeCun proposed CNN that was trained by backpropagation</li>
  <li>CNN got popular when outperformed other models at ImageNet Challenge
    <ul>
      <li>Competition in object classification/detection</li>
      <li>On hundreds of object categories and millions of images</li>
      <li>Run annually from 2010 to present</li>
    </ul>
  </li>
  <li>Notable CNN architectures that won ImageNet challenge
    <ul>
      <li>AlexNet (2012), ZFNet (2013), GoogLeNet &amp; VGG (2014), ResNet (2015)</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="architecture-of-cnn">Architecture of CNN</h1>

<ul>
  <li>A typical CNN has 4 layers
    <ul>
      <li>Input layer</li>
      <li>Convolution layer</li>
      <li>Pooling layer</li>
      <li>Fully connected layer</li>
    </ul>
  </li>
  <li>We will explain a 2D CNN here
    <ul>
      <li>Same concepts apply to a 1 (or 3) dimensional CNN</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="input-layer">Input layer</h1>

<ul>
  <li>Example input a 28 pixel by 28 pixel grayscale image</li>
  <li>Unlike FNN, we do not “flatten” the input to a 1D vector
    <ul>
      <li>input is presented to network in 2D as 28 x 28 matrix</li>
      <li>This makes capturing spatial relationships easier</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="convolution-layer">Convolution layer</h1>

<ul>
  <li>Composed of multiple filters (kernels)</li>
  <li>Filters for 2D image are also 2D</li>
  <li>Suppose we have a 3 by 3 filter (9 values in total)
    <ul>
      <li>Values are randomly set to 0 or 1</li>
    </ul>
  </li>
  <li>Convolution: placing 3 by 3 filter on the top left corner of image
    <ul>
      <li>Multiply filter values by pixel values, add the results</li>
      <li>Move filter to right one pixel at a time, and repeat this process</li>
      <li>When at top right corner, move filter down one pixel and repeat process</li>
      <li>Process ends when we get to bottom right corner of image</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="3-by-3-filter">3 by 3 Filter</h1>

<p><img src="/training-material/topics/statistics/images/Conv_no_padding_no_strides.gif" alt="A 3 by 3 filter applied to a 4 by 4 image, resulting in a 2 by 2 image" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="convolution-operator-parameters">Convolution operator parameters</h1>

<ul>
  <li>Filter size</li>
  <li>Padding</li>
  <li>Stride</li>
  <li>Dilation</li>
  <li>Activation function</li>
</ul>

<hr />

<h1 id="filter-size">Filter size</h1>

<ul>
  <li>Filter size can be 5 by 5, 3 by 3, and so on</li>
  <li>Larger filter sizes should be avoided
    <ul>
      <li>As learning algorithm needs to learn filter values (weights)</li>
    </ul>
  </li>
  <li>Odd sized filters are preferred to even sized filters
    <ul>
      <li>Nice geometric property of all input pixels being around output pixel</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="padding">Padding</h1>

<ul>
  <li>After applying 3 by 3 filter to 4 by 4 image, we get a 2 by 2 image
  – Size of the image has gone down</li>
  <li>If we want to keep image size the same, we can use padding
    <ul>
      <li>We pad input in every direction with 0’s before applying filter</li>
      <li>If padding is 1 by 1, then we add 1 zero in every direction</li>
      <li>If padding is 2 by 2, then we add 2 zeros in every direction, and so on</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="3-by-3-filter-with-padding-of-1">3 by 3 filter with padding of 1</h1>

<p><img src="/training-material/topics/statistics/images/Conv_same_padding_no_strides.gif" alt="A 3 by 3 filter applied to a 5 by 5 image, with padding of 1, resulting in a 5 by 5 image" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="stride">Stride</h1>

<ul>
  <li>How many pixels we move filter to the right/down is stride</li>
  <li>Stride 1: move filter one pixel to the right/down</li>
  <li>Stride 2: move filter two pixels to the right/down</li>
</ul>

<hr />

<h1 id="3-by-3-filter-with-stride-of-2">3 by 3 filter with stride of 2</h1>

<p><img src="/training-material/topics/statistics/images/Conv_no_padding_strides.gif" alt="A 3 by 3 filter applied to a 5 by 5 image, with stride of 2, resulting in a 2 by 2 image" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="dilation">Dilation</h1>

<ul>
  <li>When we apply 3 by 3 filter, output affected by pixels in 3 by 3 subset of image</li>
  <li>Dilation: To have a larger receptive field (portion of image affecting filter’s output)</li>
  <li>If dilation set to 2, instead of contiguous 3 by 3 subset of image, every other pixel of a 5 by 5 subset of image affects output</li>
</ul>

<hr />

<h1 id="3-by-3-filter-with-dilation-of-2">3 by 3 filter with dilation of 2</h1>

<p><img src="/training-material/topics/statistics/images/Conv_dilation.gif" alt="A 3 by 3 filter applied to a 7 by 7 image, with dilation of 2, resulting in a 3 by 3 image" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="activation-function">Activation function</h1>

<ul>
  <li>After filter applied to whole image, apply activation function to output to introduce non-linearity</li>
  <li>Preferred activation function in CNN is ReLU</li>
  <li>ReLU leaves outputs with positive values as is, replaces negative values with 0</li>
</ul>

<hr />

<h1 id="relu-activation-function">Relu activation function</h1>

<p><img src="/training-material/topics/statistics/images/Conv_ReLU.png" alt="Two matrices representing filter output before and after ReLU activation function is applied" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="single-channel-2d-convolution">Single channel 2D convolution</h1>

<p><img src="/training-material/topics/statistics/images/Conv_single_input_channel.png" alt="One matrix representing an input vector and another matrix representing a filter, along with calculation for single input channel two dimensional convolution operation" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="triple-channel-2d-convolution">Triple channel 2D convolution</h1>

<p><img src="/training-material/topics/statistics/images/Conv_multiple_input_channel.png" alt="Three matrices representing an input vector and another three matrices representing a filter, along with calculation for multiple input channel two dimensional convolution operation" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="triple-channel-2d-convolution-in-3d">Triple channel 2D convolution in 3D</h1>

<p><img src="/training-material/topics/statistics/images/Conv_multiple_channel_3d.gif" alt="Multiple cubes representing input vector, filter, and output in a 3 channel 2 dimensional convolution operation" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="change-channel-size">Change channel size</h1>

<ul>
  <li>Output of a multi-channel 2D filter is a single channel 2D image</li>
  <li>Applying <em>multiple</em> filters results in a multi-channel 2D image</li>
  <li>E.g., if input image is 28 x 28 x 3 (rows x columns x channels)
    <ul>
      <li>We apply a 3 x 3 filter with 1 x 1 padding, we get a 28 x 28 x 1 image</li>
      <li>If we apply 15 such filters, we get a 28 x 28 x 15</li>
    </ul>
  </li>
  <li>Number of filters allows us to increase or decrease channel size</li>
</ul>

<hr />

<h1 id="pooling-layer">Pooling layer</h1>

<ul>
  <li>Pooling layer performs down sampling to reduce spatial dimensionality of input</li>
  <li>This decreases number of parameters
    <ul>
      <li>Reduces learning time/computation</li>
      <li>Reduces likelihood of overfitting</li>
    </ul>
  </li>
  <li>Most popular type is <em>max</em> pooling
    <ul>
      <li>Usually a 2 x 2 filter with a stride of 2</li>
      <li>Returns maximum value as it slides over input data</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="fully-connected-layer">Fully connected layer</h1>

<ul>
  <li>Last layer in a CNN</li>
  <li>Connect all nodes from previous layer to this fully connected layer
    <ul>
      <li>Which is responsible for classification of the image</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="an-example-cnn">An example CNN</h1>

<p><img src="/training-material/topics/statistics/images/Conv_CNN.png" alt="A convolutional neural network with 3 convolution layers followed by 3 pooling layers" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="an-example-cnn-1">An example CNN</h1>

<ul>
  <li>A typical CNN has several convolution plus pooling layers
    <ul>
      <li>Each responsible for feature extraction at different levels of abstraction</li>
      <li>E.g., filters in first layer detect horizental, vertical, and diagonal edges</li>
      <li>Filters in the next layer detect shapes</li>
      <li>Filters in the last layer detect collection of shapes</li>
    </ul>
  </li>
  <li>Filter values randomly initialized, learned by learning algorithm</li>
  <li>CNN not only do classification, but can also automatically do feature extraction
    <ul>
      <li>Distinguishes CNN from other classification techniques (like Support Vector Machines)</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="fruit-360-dataset">Fruit 360 dataset</h1>

<ul>
  <li>A dataset with 90,380 images of 131 fruits and vegetables
    <ul>
      <li>Images are 100 by 100 pixel and are color (RGB) images (3 values per pixel)</li>
      <li>67,692 images in training dataset and 22,688 images in test dataset</li>
      <li>https://www.kaggle.com/moltean/fruits</li>
    </ul>
  </li>
  <li>This tutorial’s dataset is a subset of fruit 360 dataset
    <ul>
      <li>Containing only 10 fruits/vegetables</li>
      <li>Selected a subset of images, so dataset size is smaller and CNN trains faster</li>
      <li>
        <h2 id="5015-images-in-training-dataset-and-1679-images-in-test-dataset">5,015 images in training dataset, and 1,679 images in test dataset</h2>
      </li>
    </ul>
  </li>
</ul>

<h1 id="utilities-for-creating-a-subset-of-fruit-360-dataset">Utilities for creating a subset of fruit 360 dataset</h1>

<ul>
  <li>The utilities and instructions at https://github.com/kxk302/fruit_dataset_utilities</li>
  <li>First, creat feature vectors for each image
    <ul>
      <li>Images are 100 by 100 pixel color (RGB) images</li>
      <li>Each image represented by 30,000 values (100 X 100 X 3)</li>
    </ul>
  </li>
  <li>Second, we selected a subset of 10 fruit/vegetable images
    <ul>
      <li>Training and test dataset sizes went from 7 GB and 2.5 GB to 500 MB and 177 MB</li>
    </ul>
  </li>
  <li>Third, we created separate files for feature vectors and labels</li>
  <li>Finally, mapped labels for 10 selected fruits/vegetables to a 0 to 9 range
    <ul>
      <li>
        <h2 id="full-dataset-labels-are-in-the-0-to-130-range">Full dataset labels are in the 0 to 130 range</h2>
      </li>
    </ul>
  </li>
</ul>

<h1 id="classification-of-fruitvegetable-images-with-cnn">Classification of fruit/vegetable images with CNN</h1>

<ul>
  <li>We define a CNN and train it using fruit 360 dataset training data</li>
  <li>Goal is to learn a model such that given image of a fruit/vegetable we predict its label (0 to 9)</li>
  <li>
    <h2 id="we-then-evaluate-the-trained-cnn-on-test-dataset-and-plot-the-confusion-matrix">We then evaluate the trained CNN on test dataset and plot the confusion matrix</h2>
  </li>
</ul>

<h1 id="for-references-please-see-tutorials-references-section">For references, please see tutorial’s References section</h1>

<hr />

<ul>
  <li>Galaxy Training Materials (<a href="https://training.galaxyproject.org">training.galaxyproject.org</a>)</li>
</ul>

<p><img src="/training-material/topics/introduction/images/gtn_stats.png" alt="Screenshot of the gtn stats page with 21 topics, 170 tutorials, 159 contributors, 16 scientific topics, and a growing community" /></p>

<p><span>Speaker Notes</span></p>

<ul>
  <li>If you would like to learn more about Galaxy, there are a large number of tutorials available.</li>
  <li>These tutorials cover a wide range of scientific domains.</li>
</ul>

<hr />

<h1 id="getting-help">Getting Help</h1>

<ul>
  <li>
    <p><strong>Help Forum</strong> (<a href="https://help.galaxyproject.org">help.galaxyproject.org</a>)</p>

    <p><img src="/training-material/topics/introduction/images/galaxy_help.png" alt="Galaxy Help" /></p>
  </li>
  <li>
    <p><strong>Gitter Chat</strong></p>
    <ul>
      <li><a href="https://gitter.im/galaxyproject/Lobby">Main Chat</a></li>
      <li><a href="https://gitter.im/Galaxy-Training-Network/Lobby">Galaxy Training Chat</a></li>
      <li>Many more channels (scientific domains, developers, admins)</li>
    </ul>
  </li>
</ul>

<p><span>Speaker Notes</span></p>

<ul>
  <li>If you get stuck, there are ways to get help.</li>
  <li>You can ask your questions on the help forum.</li>
  <li>Or you can chat with the community on Gitter.</li>
</ul>

<hr />

<h1 id="join-an-event">Join an event</h1>

<ul>
  <li>Many Galaxy events across the globe</li>
  <li>Event Horizon: <a href="https://galaxyproject.org/events">galaxyproject.org/events</a></li>
</ul>

<p><img src="/training-material/topics/introduction/images/event_horizon.png" alt="Event schedule" /></p>

<p><span>Speaker Notes</span></p>

<ul>
  <li>There are frequent Galaxy events all around the world.</li>
  <li>You can find upcoming events on the Galaxy Event Horizon.</li>
</ul>


	<hr />








<h2>Thank you!</h2>

This material is the result of a collaborative work. Thanks to the <a href="https://training.galaxyproject.org" aria-label="Visit the GTN">Galaxy Training Network</a> and all the contributors!


<img src="/training-material/assets/images/GTNLogo1000.png" alt="Galaxy Training Network" style="height: 100px;"/>


Tutorial Content is licensed under

  <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.

</section>





        </div>
        <footer>
	<hr />
	<div class="container">
		<div class="row">
			<div class="col-sm-6" style="text-align: left">
				<p>
					The <a href="https://galaxyproject.org/teach/gtn/">Galaxy Training Network</a>
					provides researchers with online training materials, connects them with local trainers, and helps promoting FAIR and Open Science practices worldwide. All contributions are subject to the <a rel="code-of-conduct" href="https://galaxyproject.org/community/coc/">Galaxy Project Code of Conduct</a>.
				</p>
				<p>
				The GTN infrastructure is licensed under <a rel="license" href="https://github.com/galaxyproject/training-material/blob/main/LICENSE.md">MIT</a>
				</p>
				<p>
				Revision <a href="https://github.com/galaxyproject/training-material/commit/a2080641ce5cc103113670367074a642f1dc59af">a208064</a>, built with Jekyll (4.3.2 | production)
				</p>
			</div>
			<div class="col-sm-6" style="text-align: right">
				
				<p>
					<i>This Material</i>:
					
					is licensed under
					<a rel="license" href="https://spdx.org/licenses/CC-BY-4.0">
						Creative Commons Attribution 4.0 International License
					</a>
				</p>
				<p>
					<a href="https://github.com/galaxyproject/training-material/edit/main/./topics/statistics/tutorials/fruit_360/slides.html" title="Edit on GitHub">
					<i class="fab fa-github" aria-hidden="true"></i><span class="visually-hidden">github</span> Edit on GitHub
					</a>
				</p>
			</div>
		</div>
	</div>
</footer>


        <script  async defer src='/training-material/assets/js/bundle.main.105e595f.js'></script>

	
	
    </body>
</html>
