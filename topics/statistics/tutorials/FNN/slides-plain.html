<!DOCTYPE html>
<html lang="en" dir="auto">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Slides: Feedforward neural networks (FNN) 
 Deep Learning - Part 1 / Deep Learning (Part 1) - Feedforward neural networks (FNN) / Statistics and machine learning</title>
        
            <meta name="google-site-verification" content="9mOXn2JL833-i7-aioCCEuIdG4_tb6qjwUozB5GJnPQ" />

<!-- JavaScript Error Monitoring, and performance tracking. -->
<script
  src="https://browser.sentry-cdn.com/7.52.1/bundle.tracing.min.js"
  integrity="sha384-muuFXKS3752PNA4rPm9Uq6BLvOfV4CXyr9MHDBPvozOJJUWLKkogEFWOIRoVps43"
  crossorigin="anonymous"
></script>
<script type="text/javascript">
if(localStorage.getItem('sentry-opt-out') !== 'opt-out' && navigator.doNotTrack !== "1") {
	console.log("Sentry: opt-in");
	Sentry.init({
		dsn: "https://45e0ec6e4373462b92969505df37cf40@sentry.galaxyproject.org/10",
		release: "galaxy-training-network@85a7961793dc2a2db4826b275894b5a496547357",
		integrations: [new Sentry.BrowserTracing(), new Sentry.Replay()],
		sampleRate: 0.1,
		tracesSampleRate: 0.1,
		// Capture Replay for no sessions by default
		replaysSessionSampleRate: 0.01,
		// plus for 1% of sessions with an error
		replaysOnErrorSampleRate: 0.01,
		// PII OFF
		sendDefaultPii: false, // Off by default but just in case.
		environment: "production",
	});
}
</script>

<!-- Page view tracking -->
<script defer data-domain="training.galaxyproject.org" src="https://plausible.galaxyproject.eu/js/plausible.js"></script>
<script>
if(localStorage.getItem('plausible-opt-out') !== 'opt-out' && navigator.doNotTrack !== "1") {
	localStorage.removeItem("plausible_ignore")
	console.log("Plausible: opt-in");
	window.plausible = window.plausible || function() { (window.plausible.q = window.plausible.q || []).push(arguments) }
} else {
	// if they're opting-out, or DNT
	// we might get one page by accident but we won't get future ones.
	localStorage.setItem("plausible_ignore", "true")
}
</script>

        
        <link rel="shortcut icon" href="/training-material/favicon.ico" type="image/x-icon">
        <link rel="alternate" type="application/atom+xml" href="/training-material/feed.xml">
        <link rel="canonical" href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/FNN/slides-plain.html">
        <link rel="license" href="https://spdx.org/licenses/CC-BY-4.0">
        <link rel="preload" href="/training-material/assets/fonts/AtkinsonHyperlegible/Atkinson-Hyperlegible-Regular-102a.woff2" as="font" type="font/woff2" crossorigin>
        <link rel="preload" href="/training-material/assets/fonts/AtkinsonHyperlegible/Atkinson-Hyperlegible-Bold-102a.woff2" as="font" type="font/woff2" crossorigin>
        <link rel="preload" href="/training-material/assets/fonts/AtkinsonHyperlegible/Atkinson-Hyperlegible-Italic-102a.woff2" as="font" type="font/woff2" crossorigin>
        
        <link rel="preload" href="/training-material/assets/css/main.css?v=3" as="style">
        <link rel='preload' href='/training-material/assets/js/bundle.theme.f1f2de89.js' as='script'>
<link rel='preload' href='/training-material/assets/js/bundle.main.40d4e218.js' as='script'>
        <link rel="stylesheet" href="/training-material/assets/css/main.css?v=3">
        <link rel="manifest" href="/training-material/manifest.json">
        <meta name="theme-color" content="#2c3143"/>
	

        <meta name="DC.identifier" content="https://github.com/galaxyproject/training-material">
<meta name="DC.type" content="text">
<meta name="DC.title" content="Feedforward neural networks (FNN) 
 Deep Learning - Part 1">
<meta name="DC.publisher" content="Galaxy Training Network">
<meta name="DC.date" content="2021-07-27 12:20:31 +0000">
<meta name="DC.creator" content="Kaivan Kamali"><meta name="description" content="# What is an artificial neural network?  ???  What is an artificial neural network?  ---  # Artificial Neural Networks  - ML discipline roughly inspired by how neurons in a human brain work - Huge resurgence due to availability of data and computing capacity - Various types of neural networks (Feedforward, Recurrent, Convolutional) - FNN applied to classification, clustering, regression, and association  ---  # Inspiration for neural networks  - Neuron a special biological cell with information processing ability  - Receives signals from other neurons through its *dendrites*  - If the signals received exceeds a threshold, the neuron fires  - Transmits signals to other neurons via its *axon* - *Synapse*: contact between axon of a neuron and denderite of another  - Synapse either enhances/inhibits the signal that passes through it  - Learning occurs by changing the effectiveness of synapse  ![Sketch of a biological neuron and its components]({{site.baseurl}}/topics/statistics/images/F...">
        <meta property="og:site_name" content="Galaxy Training Network">
	<meta property="og:title" content="Statistics and machine learning / Deep Learning (Part 1) - Feedforward neural networks (FNN) / Slides: Feedforward neural networks (FNN) 
 Deep Learning - Part 1">
        <meta property="og:description" content="# What is an artificial neural network?  ???  What is an artificial neural network?  ---  # Artificial Neural Networks  - ML discipline roughly inspired by how neurons in a human brain work - Huge resurgence due to availability of data and computing capacity - Various types of neural networks (Feedforward, Recurrent, Convolutional) - FNN applied to classification, clustering, regression, and association  ---  # Inspiration for neural networks  - Neuron a special biological cell with information processing ability  - Receives signals from other neurons through its *dendrites*  - If the signals received exceeds a threshold, the neuron fires  - Transmits signals to other neurons via its *axon* - *Synapse*: contact between axon of a neuron and denderite of another  - Synapse either enhances/inhibits the signal that passes through it  - Learning occurs by changing the effectiveness of synapse  ![Sketch of a biological neuron and its components]({{site.baseurl}}/topics/statistics/images/F...">
        
	<meta property="og:image" content="https://training.galaxyproject.org/training-material/assets/images/GTNLogo1000.png"></head>
    <body data-spy="scroll" data-target="#toc" data-brightness="auto" data-contrast="auto">
        <script  src='/training-material/assets/js/bundle.theme.f1f2de89.js'></script>
        <header>
    <nav class="navbar navbar-expand-md navbar-dark" aria-label="Site Navigation">
        <div class="container">
            <a class="navbar-brand" href="/training-material/">
                <img src="/training-material/assets/images/GTN-60px.png" height="30" alt="Galaxy Training Network logo">
                
                    Galaxy Training!
                
            </a>

            <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#top-navbar" aria-controls="top-navbar" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="top-navbar">
                <ul class="navbar-nav">
                    <li class="nav-item">
                        
			

                        
                    </li>

                    <li class="nav-item">
                        
                        <a class="nav-link" href="/training-material/learning-pathways" title="Learning Pathways">
                           <i class="fas fa-graduation-cap" aria-hidden="true"></i><span class="visually-hidden">curriculum</span> Learning Pathways
                        </a>
                        
                    </li>

                    <li class="nav-item dropdown">
    <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-expanded="false" title="Help">
        <i class="far fa-question-circle" aria-hidden="true"></i><span class="visually-hidden">help</span> Help
    </a>
    <div class="dropdown-menu dropdown-menu-right">
	<a class="dropdown-item" href="/training-material/faqs/index.html" title="Check our FAQs">
           <i class="far fa-question-circle" aria-hidden="true"></i><span class="visually-hidden">question</span> FAQs
        </a>
        
        <a class="dropdown-item" href="https://help.galaxyproject.org/" title="Discuss on Galaxy Help">
            <i class="far fa-comments" aria-hidden="true"></i><span class="visually-hidden">feedback</span> Galaxy Help Forum
        </a>
        <a class="dropdown-item" href="https://gitter.im/Galaxy-Training-Network/Lobby" title="Discuss on gitter">
           <i class="fab fa-gitter" aria-hidden="true"></i><span class="visually-hidden">gitter</span> Discuss on Matrix
        </a>
    </div>
</li>


                    <li class="nav-item dropdown">
    <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-expanded="false" title="Settings">
	<i class="fas fa-cog" aria-hidden="true"></i><span class="visually-hidden">galaxy-gear</span> Settings
    </a>
    <div class="dropdown-menu dropdown-menu-right">

	<h6 class="dropdown-header">Preferences</h6>

	<a href="/training-material/user/theme.html" class="dropdown-item">
		<i class="fas fa-palette" aria-hidden="true"></i><span class="visually-hidden">gtn-theme</span> Theme
	</a>

	<a href="/training-material/user/privacy.html" class="dropdown-item">
		<i class="fas fa-lock" aria-hidden="true"></i><span class="visually-hidden">pref-dataprivate</span> Data Privacy
	</a>

	<div class="dropdown-divider"></div>

	<h6 class="dropdown-header">For Everyone</h6>

        <a class="dropdown-item" href="https://github.com/galaxyproject/training-material/edit/main/./topics/statistics/tutorials/FNN/slides.html">
          <i class="fab fa-github" aria-hidden="true"></i><span class="visually-hidden">github</span> Propose a change or correction
        </a>

	<h6 class="dropdown-header">Instructor Utilities</h6>

        <a class="dropdown-item" href="/training-material/stats.html">
            <i class="fas fa-chart-column" aria-hidden="true"></i><span class="visually-hidden">galaxy-barchart</span> GTN statistics
        </a>

        <a class="dropdown-item" href="https://plausible.galaxyproject.eu/training.galaxyproject.org?period=12mo&page=/training-material/topics/statistics/tutorials/FNN/slides-plain.html">
            <i class="fas fa-chart-column" aria-hidden="true"></i><span class="visually-hidden">galaxy-barchart</span> Page View Metrics
        </a>

        <!-- link to feedback -->
        
            <a class="dropdown-item" href="/training-material/feedback.html">
                <i class="fas fa-chart-column" aria-hidden="true"></i><span class="visually-hidden">galaxy-barchart</span> GTN feedback
            </a>
        

        <div class="dropdown-item">
            <div>
                <i class="fas fa-history" aria-hidden="true"></i><span class="visually-hidden">galaxy-rulebuilder-history</span> Previous Versions
            </div>

            <div id="archive-selector">
            
                <a class="btn btn-warning" href="https://training.galaxyproject.org/archive/">Older Versions</a>
            </div>

        </div>

    </div>
</li>


                    <!-- Search bar-->
                    <li class="nav-item">
                      <div id="navbarSupportedContent" role="search">
                        <!-- Search form -->
                        <form class="form-inline mr-auto" method="GET" action="/training-material/search2">
                          <i class="fas fa-search nav-link" aria-hidden="true"></i>
                          <div class="md-form mb-2">
                            <input name="query" class="form-control nicer" type="text" placeholder="Search Tutorials" aria-label="Search">
                          </div>
                        </form>
                      </div>
                    </li>
                </ul>
            </div>
        </div>
    </nav>
</header>

        
        <div class="container main-content" role="main">
        <section class="tutorial">
	<a href="https://github.com/galaxyproject/training-material/blob/main//topics/statistics/tutorials/FNN/slides.html">View markdown source on GitHub</a>
	<h1>Feedforward neural networks (FNN) 
 Deep Learning - Part 1</h1>
		<h2>Contributors</h2>
<div markdown="0">

	<div class="contributors-line">
		Authors: <a href="/training-material/hall-of-fame/kxk302/" class="contributor-badge contributor-kxk302"><img src="https://avatars.githubusercontent.com/kxk302?s=36" alt="Kaivan Kamali avatar" width="36" class="avatar" />
    Kaivan Kamali</a>
	</div>

</div>


		
		<h2>Questions</h2>
		<ul>
		
		<li><p>What is a feedforward neural network (FNN)?</p>
</li>
		
		<li><p>What are some applications of FNN?</p>
</li>
		
		</ul>
		

		
		<h2>Objectives</h2>
		<ul>
		
		<li><p>Understand the inspiration for neural networks</p>
</li>
		
		<li><p>Learn activation functions &amp; various problems solved by neural networks</p>
</li>
		
		<li><p>Discuss various loss/cost functions and backpropagation algorithm</p>
</li>
		
		<li><p>Learn how to create a neural network using Galaxy’s deep learning tools</p>
</li>
		
		<li><p>Solve a sample regression problem via FNN in Galaxy</p>
</li>
		
		</ul>
		

		
		<h2>Requirements</h2>
		<ul>
		

		
    
        
        
        
            
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                        
                        
                            
                                <li>
                                  <a href="/training-material/topics/statistics/tutorials/intro_deep_learning/tutorial.html"><i class="fas fa-laptop" aria-hidden="true"></i><span class="visually-hidden">tutorial</span> Hands-on: Introduction to deep learning</a>
                                </li>
                            
                        
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            
        
    


		</ul>
		

		<div><strong> <i class="far fa-calendar" aria-hidden="true"></i><span class="visually-hidden">last_modification</span> Published:</strong> Jun 2, 2021 </div>
		<div><strong> <i class="far fa-calendar" aria-hidden="true"></i><span class="visually-hidden">last_modification</span> Last Updated:</strong> Jul 27, 2021 </div>

	<hr />


	<h1 id="what-is-an-artificial-neural-network">What is an artificial neural network?</h1>

<p><span>Speaker Notes</span></p>

<p>What is an artificial neural network?</p>

<hr />

<h1 id="artificial-neural-networks">Artificial Neural Networks</h1>

<ul>
  <li>ML discipline roughly inspired by how neurons in a human brain work</li>
  <li>Huge resurgence due to availability of data and computing capacity</li>
  <li>Various types of neural networks (Feedforward, Recurrent, Convolutional)</li>
  <li>FNN applied to classification, clustering, regression, and association</li>
</ul>

<hr />

<h1 id="inspiration-for-neural-networks">Inspiration for neural networks</h1>

<ul>
  <li>Neuron a special biological cell with information processing ability
    <ul>
      <li>Receives signals from other neurons through its <em>dendrites</em></li>
      <li>If the signals received exceeds a threshold, the neuron fires</li>
      <li>Transmits signals to other neurons via its <em>axon</em></li>
    </ul>
  </li>
  <li><em>Synapse</em>: contact between axon of a neuron and denderite of another
    <ul>
      <li>Synapse either enhances/inhibits the signal that passes through it</li>
      <li>Learning occurs by changing the effectiveness of synapse</li>
    </ul>
  </li>
</ul>

<p><img src="/training-material/topics/statistics/images/FNN_bio_neuron.png" alt="Sketch of a biological neuron and its components" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="celebral-cortex">Celebral cortex</h1>

<ul>
  <li>Outter most layer of brain, 2 to 3 mm thick, surface area of 2,200 sq. cm</li>
  <li>Has about 10^11 neurons
    <ul>
      <li>Each neuron connected to 10^3 to 10^4 neurons</li>
      <li>Human brain has 10^14 to 10^15 connections</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="celebral-cortex-1">Celebral cortex</h1>

<ul>
  <li>Neurons communicate by signals ms in duration
    <ul>
      <li>Signal transmission frequency up to several hundred Hertz</li>
      <li>Millions of times slower than an electronic circuit</li>
      <li>Complex tasks like face recognition done within a few hundred ms</li>
      <li>Computation involved cannot take more than 100 serial steps</li>
    </ul>
  </li>
  <li>The information sent from one neuron to another is very small
    <ul>
      <li>Critical information not transmitted</li>
      <li>But captured by the interconnections</li>
    </ul>
  </li>
  <li>Distributed computation/representation of the brain
    <ul>
      <li>Allows slow computing elements to perform complex tasks quickly</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="perceptron">Perceptron</h1>

<p><img src="/training-material/topics/statistics/images/FFNN_no_hidden.png" alt="Neurons forming the input and output layers of a single layer feedforward neural network" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="learning-in-perceptron">Learning in Perceptron</h1>

<ul>
  <li>Given a set of input-output pairs (called <em>training set</em>)</li>
  <li>Learning algorithm iteratively adjusts model parameters
    <ul>
      <li>Weights and biases</li>
    </ul>
  </li>
  <li>So the model can accurately map inputs to outputs</li>
  <li>Perceptron learning algorithm</li>
</ul>

<hr />

<h1 id="limitations-of-perceptron">Limitations of Perceptron</h1>

<ul>
  <li>Single layer FNN cannot solve problems in which data is not linearly separable
    <ul>
      <li>E.g., the XOR problem</li>
    </ul>
  </li>
  <li>Adding one (or more) hidden layers enables FNN to represent any function
    <ul>
      <li><em>Universal Approximation Theorem</em></li>
    </ul>
  </li>
  <li>Perceptron learning algorithm could not extend to  multi-layer FNN
    <ul>
      <li>AI winter</li>
    </ul>
  </li>
  <li><em>Backpropagation</em> algorithm in 80’s enabled learning in multi-layer FNN</li>
</ul>

<hr />

<h1 id="multi-layer-fnn">Multi-layer FNN</h1>

<p><img src="/training-material/topics/statistics/images/FFNN.png" alt="Neurons forming the input, output, and hidden layers of a multi-layer feedforward neural network" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<ul>
  <li>More hidden layers (and more neurons in each hidden layer)
    <ul>
      <li>Can estimate more complex functions</li>
      <li>More parameters increases training time</li>
      <li>More likelihood of <em>overfitting</em></li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="activation-functions">Activation functions</h1>

<p><img src="/training-material/topics/statistics/images/FNN_activation_functions.png" alt="Table showing the formula, graph, derivative, and range of common activation functions" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="supervised-learning">Supervised learning</h1>

<ul>
  <li>Training set of size <em>m</em>: { (x^1,y^1),(x^2,y^2),…,(x^m,y^m) }
    <ul>
      <li>Each pair (x^i,y^i) is called a <em>training example</em></li>
      <li>x^i is called <em>feature vector</em></li>
      <li>Each element of feature vector is called a <em>feature</em></li>
      <li>Each x^i corresponds to a <em>label</em> y^i</li>
    </ul>
  </li>
  <li>We assume an unknown function y=f(x) maps feature vectors to labels</li>
  <li>The goal is to use the training set to learn or estimate f
    <ul>
      <li>We want the estimate to be close to f(x) not only for training set</li>
      <li>But for training examples not in training set</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="classification-problems">Classification problems</h1>

<p><img src="/training-material/topics/statistics/images/FNN_output_encoding.png" alt="Three images illustrating binary, multiclass, and multilabel classifications and their label representation" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="output-layer">Output layer</h1>

<ul>
  <li>Binary classification
    <ul>
      <li>Single neuron in output layer</li>
      <li>Sigmoid activation function</li>
      <li>Activation &gt; 0.5, output 1</li>
      <li>Activation &lt;= 0.5, output 0</li>
    </ul>
  </li>
  <li>Multilabel classification
    <ul>
      <li>As many neurons in output layer as number of classes</li>
      <li>Sigmoid activation function</li>
      <li>Activation &gt; 0.5, output 1</li>
      <li>
        <h2 id="activation--05-output-0">Activation &lt;= 0.5, output 0</h2>
      </li>
    </ul>
  </li>
</ul>

<h1 id="output-layer-continued">Output layer (Continued)</h1>

<ul>
  <li>Multiclass classification
    <ul>
      <li>As many neurons in output layer as number of classes</li>
      <li><em>Softmax</em> activation function</li>
      <li>Takes input to neurons in output layer</li>
      <li>Creates a probability distribution, sum of outputs adds up to 1</li>
      <li>The neuron with the highest proability is the predicted label</li>
    </ul>
  </li>
  <li>Regression problem
    <ul>
      <li>Single neuron in output layer</li>
      <li>Linear activation function</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="losscost-functions">Loss/Cost functions</h1>

<ul>
  <li>During training, for each training example (x^i,y^i), we present x^i to neural network
    <ul>
      <li>Compare predicted output with label y^1</li>
      <li>Need loss function to measure difference between predicted &amp; expected output</li>
    </ul>
  </li>
  <li>Use <em>Cross entropy</em> loss function for classification problems</li>
  <li>And <em>Quadratic</em> loss function for regression problems
    <ul>
      <li>Quadratic cost function is also called <em>Mean Squared Error (MSE)</em></li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="cross-entropy-losscost-functions">Cross Entropy Loss/Cost functions</h1>

<p><img src="/training-material/topics/statistics/images/FNN_Cross_Entropy_Loss.png" alt="Cross Entropy loss function" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<p><img src="/training-material/topics/statistics/images/FNN_Cross_Entropy_Cost.png" alt="Cross Entropy cost function" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="quadratic-losscost-functions">Quadratic Loss/Cost functions</h1>

<p><img src="/training-material/topics/statistics/images/FNN_Quadratic_Loss.png" alt="Quadratic loss function" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<p><img src="/training-material/topics/statistics/images/FNN_Quadratic_Cost.png" alt="Quadratic cost function" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="backpropagation-bp-learning-algorithm">Backpropagation (BP) learning algorithm</h1>

<ul>
  <li>A <em>gradient descent</em> technique
    <ul>
      <li>Find local minimum of a function by iteratively moving in opposite direction of gradient of function at current point</li>
    </ul>
  </li>
  <li>Goal of learning is to minimize cost function given training set
    <ul>
      <li>Cost function is a function of network weights &amp; biases of all neurons in all layers</li>
      <li>Backpropagation iteratively computes gradient of cost function relative to each weight and bias</li>
      <li>Updates weights and biases in the opposite direction of gradient</li>
      <li>Gradients (partial derivatives) are used to update weights and biases</li>
      <li>To find a local minimum</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="backpropagation-error">Backpropagation error</h1>

<p><img src="/training-material/topics/statistics/images/FNN_BP_Error.png" alt="Backpropagation error" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="backpropagation-formulas">Backpropagation formulas</h1>

<p><img src="/training-material/topics/statistics/images/FNN_BP.png" alt="Backpropagation formulas" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="types-of-gradient-descent">Types of Gradient Descent</h1>

<ul>
  <li><em>Batch</em> gradient descent
    <ul>
      <li>Calculate gradient for each weight/bias for <em>all</em> samples</li>
      <li>Average gradients and update weights/biases</li>
      <li>Slow, if we have too many samples</li>
    </ul>
  </li>
  <li><em>Stochastic</em> gradient descent
    <ul>
      <li>Update weights/biases based on gradient of <em>each</em> sample</li>
      <li>Fast. Not accurate if sample gradient not representiative</li>
    </ul>
  </li>
  <li><em>Mini-batch</em> gradient descent
    <ul>
      <li>Middle ground solution</li>
      <li>Calculate gradient for each weight/bias for all samples in <em>batch</em>
        <ul>
          <li>batch size is much smaller than training set size</li>
        </ul>
      </li>
      <li>Average batch gradients and update weights/biases</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="vanishing-gradient-problem">Vanishing gradient problem</h1>

<ul>
  <li>Second BP equation is recursive
    <ul>
      <li>We have derivative of activation function</li>
      <li>Calc. error in layer prior to output: 1 mult. by derivative value</li>
      <li>Calc. error in two layers prior output: 2 mult. by derivative values</li>
    </ul>
  </li>
  <li>If derivative values are small (e.g. for Sigmoid), product of multiple small values will be a very small value
    <ul>
      <li>Since error values decide updates for biases/weights</li>
      <li>Update to biases/weights in first layers will be very small
        <ul>
          <li>Slowing the learning algorithm to a halt</li>
        </ul>
      </li>
      <li>The reason Sigmoid not used in deep networks
        <ul>
          <li>Why ReLU is popular in deep networks</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="car-purchase-price-prediction">Car purchase price prediction</h1>

<ul>
  <li>Given 5 features of an individual (age, gender, miles driven per day, personal debt, and monthly income)
    <ul>
      <li>And, money they spent buying a car</li>
      <li>Learn a FNN to predict how much someone will spend buying a car</li>
    </ul>
  </li>
  <li>We evaluate FNN on test dataset and plot graphs to assess the model’s performance
    <ul>
      <li>Training dataset has 723 training examples</li>
      <li>Test dataset has 242 test examples</li>
      <li>Input features scaled to be in 0 to 1 range</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="for-references-please-see-tutorials-references-section">For references, please see tutorial’s References section</h1>

<hr />

<ul>
  <li>Galaxy Training Materials (<a href="https://training.galaxyproject.org">training.galaxyproject.org</a>)</li>
</ul>

<p><img src="/training-material/topics/introduction/images/gtn_stats.png" alt="Screenshot of the gtn stats page with 21 topics, 170 tutorials, 159 contributors, 16 scientific topics, and a growing community" /></p>

<p><span>Speaker Notes</span></p>

<ul>
  <li>If you would like to learn more about Galaxy, there are a large number of tutorials available.</li>
  <li>These tutorials cover a wide range of scientific domains.</li>
</ul>

<hr />

<h1 id="getting-help">Getting Help</h1>

<ul>
  <li>
    <p><strong>Help Forum</strong> (<a href="https://help.galaxyproject.org">help.galaxyproject.org</a>)</p>

    <p><img src="/training-material/topics/introduction/images/galaxy_help.png" alt="Galaxy Help" /></p>
  </li>
  <li>
    <p><strong>Gitter Chat</strong></p>
    <ul>
      <li><a href="https://gitter.im/galaxyproject/Lobby">Main Chat</a></li>
      <li><a href="https://gitter.im/Galaxy-Training-Network/Lobby">Galaxy Training Chat</a></li>
      <li>Many more channels (scientific domains, developers, admins)</li>
    </ul>
  </li>
</ul>

<p><span>Speaker Notes</span></p>

<ul>
  <li>If you get stuck, there are ways to get help.</li>
  <li>You can ask your questions on the help forum.</li>
  <li>Or you can chat with the community on Gitter.</li>
</ul>

<hr />

<h1 id="join-an-event">Join an event</h1>

<ul>
  <li>Many Galaxy events across the globe</li>
  <li>Event Horizon: <a href="https://galaxyproject.org/events">galaxyproject.org/events</a></li>
</ul>

<p><img src="/training-material/topics/introduction/images/event_horizon.png" alt="Event schedule" /></p>

<p><span>Speaker Notes</span></p>

<ul>
  <li>There are frequent Galaxy events all around the world.</li>
  <li>You can find upcoming events on the Galaxy Event Horizon.</li>
</ul>


	<hr />








<h2>Thank you!</h2>

This material is the result of a collaborative work. Thanks to the <a href="https://training.galaxyproject.org" aria-label="Visit the GTN">Galaxy Training Network</a> and all the contributors!


<img src="/training-material/assets/images/GTNLogo1000.png" alt="Galaxy Training Network" style="height: 100px;"/>


Tutorial Content is licensed under

  <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.

</section>






        </div>
        <footer>
	<hr />
	<div class="container">
		<div class="row">
			<div class="col-sm-3">
				<span style="font-size: 2em">GTN</span>
				<p>
					The GTN provides researchers with a free, open repository of online training
					materials, with a focus on hands-on training that aims to be directly applicable for learners.
					We aim to connect researchers and learners with local trainers, and events worldwide.
				</p>
				<p>
					We promote FAIR and Open Science practices worldwide, are committed to the accessibility of this platform and training for everyone.
				</p>
			</div>
			<div class="col-sm-3">
				<span style="font-size: 1.3em">About Us</span>
				<ul class="no-bullets">
					<li><a href="/training-material/faqs/gtn/gtn-what-is-it.html">About</a></li>
					<li><a rel="code-of-conduct" href="https://galaxyproject.org/community/coc/">Code of Conduct</a></li>
					<li><a href="/training-material/accessibility.html">Accessibility</a></li>
					<li><a href="/training-material/faqs/gtn/fair_training.html">100% FAIR Training</a></li>
					<li><a href="/training-material/faqs/gtn/collaborative_development.html">Collaborative Development</a></li>
				</ul>
				<span style="font-size: 1.3em">Page</span>
				<ul class="no-bullets">
					

					

					<li>
						<a rel="license" href="https://spdx.org/licenses/CC-BY-4.0">
							Content licensed under Creative Commons Attribution 4.0 International License
						</a>
					</li>
					<li>
						<a href="https://github.com/galaxyproject/training-material/edit/main/./topics/statistics/tutorials/FNN/slides.html">
						<i class="fab fa-github" aria-hidden="true"></i><span class="visually-hidden">github</span> Edit on GitHub
						</a>
					</li>
					<li>
						<a href="https://github.com/galaxyproject/training-material/commits/main/./topics/statistics/tutorials/FNN/slides.html">
						<i class="fab fa-github" aria-hidden="true"></i><span class="visually-hidden">github</span> View Changes on GitHub
						</a>
					</li>
				</ul>
			</div>
			<div class="col-sm-3">
				<span style="font-size: 1.3em">Support</span>
				<ul class="no-bullets">
					<li><a rel="me" href="/training-material/faqs/galaxy/">Galaxy FAQs</a></li>
					<li><a rel="me" href="https://help.galaxyproject.org">Galaxy Help Forum</a></li>
					<li><a rel="me" href="http://gxy.io/gtn-slack">GTN Slack Chat</a></li>
					<li><a rel="me" href="https://matrix.to/#/%23Galaxy-Training-Network_Lobby%3Agitter.im">GTN Matrix Chat</a></li>
					<li><a rel="me" href="https://matrix.to/#/#galaxyproject_Lobby:gitter.im">Galaxy Matrix Chat</a></li>
				</ul>
				<span style="font-size: 1.3em">Framework</span>
				<ul class="no-bullets">
					<li>Revision <a href="https://github.com/galaxyproject/training-material/commit/85a7961793dc2a2db4826b275894b5a496547357">85a7961</a></li>
					<li><a rel="license" href="https://github.com/galaxyproject/training-material/blob/main/LICENSE.md">MIT</a> Licensed</li>
					<li><a href="https://jekyllrb.com/">Jekyll(4.3.2 | production)</a></li>
				</ul>
			</div>
			<div class="col-sm-3">
				<span style="font-size: 1.3em">Follow Us!</span>
				<ul class="no-bullets">
					<li><span style="fill: var(--hyperlink);"><?xml version="1.0" encoding="UTF-8" standalone="no"?><svg   width="1em"   height="1em"   viewBox="0 0 8.4937906 9.1084023"   version="1.1"   id="svg356"   xmlns="http://www.w3.org/2000/svg"   xmlns:svg="http://www.w3.org/2000/svg">  <g     id="layer1"     transform="translate(-70.566217,-144.26757)">    <path       style="fill-opacity:1;stroke:none;stroke-width:0.0179182"       d="m 76.39081,152.24155 c -0.737138,0.20763 -1.554999,0.29101 -2.311453,0.14333 -0.475335,-0.0928 -0.891898,-0.32923 -1.031589,-0.82423 -0.04356,-0.15434 -0.06132,-0.32388 -0.06142,-0.48378 0.353724,0.0457 0.702251,0.1304 1.057176,0.17407 0.701338,0.0864 1.394702,0.0784 2.096434,0.008 0.744056,-0.0745 1.433711,-0.21546 2.060598,-0.64854 0.243974,-0.16855 0.474672,-0.39133 0.603487,-0.66252 0.181421,-0.38195 0.175886,-0.89336 0.204447,-1.30803 0.0923,-1.34029 0.20588,-2.98599 -1.076708,-3.846 -0.499561,-0.33497 -1.208891,-0.39913 -1.791824,-0.45742 -0.987026,-0.0987 -1.971078,-0.0946 -2.956509,0.0338 -0.841146,0.10961 -1.595223,0.31468 -2.1065,1.0443 -0.493296,0.70396 -0.509564,1.52563 -0.509564,2.34729 0,1.37831 -0.05534,2.87744 0.595934,4.13911 0.504703,0.97774 1.498709,1.29589 2.52184,1.41832 0.473239,0.0566 0.96049,0.0849 1.434158,0.0172 0.328853,-0.0471 0.650325,-0.0999 0.966886,-0.20511 0.08957,-0.0298 0.266911,-0.0614 0.322027,-0.14486 0.04089,-0.0618 0.0099,-0.15812 0.0035,-0.22545 -0.01611,-0.16924 -0.02094,-0.34967 -0.02096,-0.51963 m -1.594723,-5.48298 c 0.214822,-0.25951 0.315898,-0.56088 0.60922,-0.75705 0.687899,-0.46006 1.692038,-0.11202 1.992096,0.63161 0.214571,0.5317 0.140174,1.15913 0.140174,1.72017 v 1.03925 c 0,0.0911 0.04009,0.30954 -0.01842,0.38339 -0.04193,0.053 -0.173018,0.0287 -0.232436,0.0287 h -0.698809 v -1.88142 c 0,-0.28413 0.04813,-0.63823 -0.09912,-0.89591 -0.234746,-0.4108 -0.875019,-0.36105 -1.092116,0.0358 -0.123368,0.22555 -0.116792,0.50369 -0.116792,0.75257 v 1.0751 h -0.931726 v -1.05718 c 0,-0.2555 0.0024,-0.53932 -0.121773,-0.77049 -0.21432,-0.39919 -0.857782,-0.44403 -1.090217,-0.0358 -0.147324,0.25871 -0.09604,0.61056 -0.09604,0.89591 v 1.88142 H 72.09042 v -1.98893 c 0,-0.4711 -0.01604,-0.95902 0.233201,-1.3797 0.585269,-0.98786 2.133584,-0.74836 2.472454,0.32253 z"       id="path2318" />  </g></svg></span> <a rel="me" href="https://mstdn.science/@gtn">Mastodon</a></li>
					<li><span style="fill: var(--hyperlink);"><svg  viewBox="0 0 64 57" width="1em" ><path style="fill-opacity:1;stroke:none;stroke-width:0.0179182" d="M13.873 3.805C21.21 9.332 29.103 20.537 32 26.55v15.882c0-.338-.13.044-.41.867-1.512 4.456-7.418 21.847-20.923 7.944-7.111-7.32-3.819-14.64 9.125-16.85-7.405 1.264-15.73-.825-18.014-9.015C1.12 23.022 0 8.51 0 6.55 0-3.268 8.579-.182 13.873 3.805ZM50.127 3.805C42.79 9.332 34.897 20.537 32 26.55v15.882c0-.338.13.044.41.867 1.512 4.456 7.418 21.847 20.923 7.944 7.111-7.32 3.819-14.64-9.125-16.85 7.405 1.264 15.73-.825 18.014-9.015C62.88 23.022 64 8.51 64 6.55c0-9.818-8.578-6.732-13.873-2.745Z"></path></svg></span><a rel="me" href="https://bsky.app/profile/galaxytraining.bsky.social"> Bluesky</a></li>
				</ul>
			</div>
		</div>
	</div>
</footer>


        <script  async defer src='/training-material/assets/js/bundle.main.40d4e218.js'></script>

	
	

    </body>
</html>
