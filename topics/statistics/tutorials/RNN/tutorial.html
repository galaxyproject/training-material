<!DOCTYPE html>
<html lang="en" dir="auto">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Hands-on: Deep Learning (Part 2) - Recurrent neural networks (RNN) / Deep Learning (Part 2) - Recurrent neural networks (RNN) / Statistics and machine learning</title>
        
            <meta name="google-site-verification" content="9mOXn2JL833-i7-aioCCEuIdG4_tb6qjwUozB5GJnPQ" />

<!-- JavaScript Error Monitoring, and performance tracking. -->
<script
  src="https://browser.sentry-cdn.com/7.52.1/bundle.tracing.min.js"
  integrity="sha384-muuFXKS3752PNA4rPm9Uq6BLvOfV4CXyr9MHDBPvozOJJUWLKkogEFWOIRoVps43"
  crossorigin="anonymous"
></script>
<script type="text/javascript">
if(localStorage.getItem('sentry-opt-out') !== 'opt-out' && navigator.doNotTrack !== "1") {
	console.log("Sentry: opt-in");
	Sentry.init({
		dsn: "https://45e0ec6e4373462b92969505df37cf40@sentry.galaxyproject.org/10",
		release: "galaxy-training-network@5f9c6d1af07b03871570c2addd54488777a85eec",
		integrations: [new Sentry.BrowserTracing(), new Sentry.Replay()],
		sampleRate: 0.1,
		tracesSampleRate: 0.1,
		// Capture Replay for no sessions by default
		replaysSessionSampleRate: 0.01,
		// plus for 1% of sessions with an error
		replaysOnErrorSampleRate: 0.01,
		// PII OFF
		sendDefaultPii: false, // Off by default but just in case.
		environment: "production",
	});
}
</script>

<!-- Page view tracking -->
<script defer data-domain="training.galaxyproject.org" src="https://plausible.galaxyproject.eu/js/plausible.js"></script>
<script>
if(localStorage.getItem('plausible-opt-out') !== 'opt-out' && navigator.doNotTrack !== "1") {
	localStorage.removeItem("plausible_ignore")
	console.log("Plausible: opt-in");
	window.plausible = window.plausible || function() { (window.plausible.q = window.plausible.q || []).push(arguments) }
} else {
	// if they're opting-out, or DNT
	// we might get one page by accident but we won't get future ones.
	localStorage.setItem("plausible_ignore", "true")
}
</script>

        
        <link rel="shortcut icon" href="/training-material/favicon.ico" type="image/x-icon">
        <link rel="alternate" type="application/atom+xml" href="/training-material/feed.xml">
        <link rel="canonical" href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/RNN/tutorial.html">
        <link rel="license" href="https://spdx.org/licenses/CC-BY-4.0">
        <link rel="preload" href="/training-material/assets/fonts/AtkinsonHyperlegible/Atkinson-Hyperlegible-Regular-102a.woff2" as="font" type="font/woff2" crossorigin>
        <link rel="preload" href="/training-material/assets/fonts/AtkinsonHyperlegible/Atkinson-Hyperlegible-Bold-102a.woff2" as="font" type="font/woff2" crossorigin>
        <link rel="preload" href="/training-material/assets/fonts/AtkinsonHyperlegible/Atkinson-Hyperlegible-Italic-102a.woff2" as="font" type="font/woff2" crossorigin>
        
        <link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" as="script" crossorigin>
        
        <link rel="preload" href="/training-material/assets/css/main.css?v=3" as="style">
        <link rel='preload' href='/training-material/assets/js/bundle.theme.f1f2de89.js' as='script'>
<link rel='preload' href='/training-material/assets/js/bundle.main.40d4e218.js' as='script'>
        <link rel="stylesheet" href="/training-material/assets/css/main.css?v=3">
        <link rel="manifest" href="/training-material/manifest.json">
        <meta name="theme-color" content="#2c3143"/>
	

        <meta name="DC.identifier" content="https://github.com/galaxyproject/training-material">
<meta name="DC.type" content="text">
<meta name="DC.title" content="Deep Learning (Part 2) - Recurrent neural networks (RNN)">
<meta name="DC.publisher" content="Galaxy Training Network">
<meta name="DC.date" content="2024-06-14 09:56:50 +0000">
<meta name="DC.creator" content="Kaivan Kamali"><meta name="description" content="Statistical Analyses for omics data and machine learning using Galaxy tools">
        <meta property="og:site_name" content="Galaxy Training Network">
	<meta property="og:title" content="Statistics and machine learning / Deep Learning (Part 2) - Recurrent neural networks (RNN) / Hands-on: Deep Learning (Part 2) - Recurrent neural networks (RNN)">
        <meta property="og:description" content="Statistical Analyses for omics data and machine learning using Galaxy tools">
        <meta property="og:image" content="https://galaxy-training.s3.amazonaws.com/social/topics/statistics/tutorials/RNN/tutorial.png">
	<script type="application/ld+json">


{
  "@context": "http://schema.org",
  "@type": "LearningResource",
  "http://purl.org/dc/terms/conformsTo": {
    "@id": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
    "@type": "CreativeWork"
  },
  "audience": {
    "@type": "EducationalAudience",
    "educationalRole": "Students"
  },
  "citation": [
    {
      "@type": "CreativeWork",
      "name": "Galaxy Training: A Powerful Framework for Teaching!",
      "url": "https://doi.org/10.1371/journal.pcbi.1010752"
    },
    {
      "@type": "CreativeWork",
      "name": "Community-Driven Data Analysis Training for Biology",
      "url": "https://doi.org/10.1016/j.cels.2018.05.012"
    }
  ],
  "discussionUrl": "https://gitter.im/Galaxy-Training-Network/Lobby",
  "headline": "Deep Learning (Part 2) - Recurrent neural networks (RNN)",
  "interactivityType": "mixed",
  "isAccessibleForFree": true,
  "isFamilyFriendly": true,
  "license": "https://spdx.org/licenses/CC-BY-4.0.html",
  "producer": {
    "@type": "Organization",
    "http://purl.org/dc/terms/conformsTo": {
      "@id": "https://bioschemas.org/profiles/Organization/0.2-DRAFT-2019_07_19",
      "@type": "Organization"
    },
    "id": "https://training.galaxyproject.org",
    "email": "galaxytrainingnetwork@gmail.com",
    "name": "Galaxy Training Network",
    "legalName": "Galaxy Training Network",
    "alternateName": "GTN",
    "url": "https://training.galaxyproject.org",
    "logo": "https://training.galaxyproject.org/training-material/assets/images/GTNLogo1000.png",
    "fundingModel": "The GTN's infrastructure relies on GitHub and the Galaxy Project for hosting costs. There are no full time paid staff members of the GTN. Individuals are occasionally funded on GTN-adjacent projects.",
    "keywords": [
      "galaxy",
      "bioinformatics",
      "training",
      "fair",
      "accessible"
    ],
    "status": "active",
    "foundingDate": "2015-06-29",
    "socialMedia": "https://mstdn.science/@gtn",
    "type": "project"
  },
  "provider": {
    "@type": "Organization",
    "http://purl.org/dc/terms/conformsTo": {
      "@id": "https://bioschemas.org/profiles/Organization/0.2-DRAFT-2019_07_19",
      "@type": "Organization"
    },
    "id": "https://training.galaxyproject.org",
    "email": "galaxytrainingnetwork@gmail.com",
    "name": "Galaxy Training Network",
    "legalName": "Galaxy Training Network",
    "alternateName": "GTN",
    "url": "https://training.galaxyproject.org",
    "logo": "https://training.galaxyproject.org/training-material/assets/images/GTNLogo1000.png",
    "fundingModel": "The GTN's infrastructure relies on GitHub and the Galaxy Project for hosting costs. There are no full time paid staff members of the GTN. Individuals are occasionally funded on GTN-adjacent projects.",
    "keywords": [
      "galaxy",
      "bioinformatics",
      "training",
      "fair",
      "accessible"
    ],
    "status": "active",
    "foundingDate": "2015-06-29",
    "socialMedia": "https://mstdn.science/@gtn",
    "type": "project"
  },
  "sourceOrganization": {
    "@type": "Organization",
    "http://purl.org/dc/terms/conformsTo": {
      "@id": "https://bioschemas.org/profiles/Organization/0.2-DRAFT-2019_07_19",
      "@type": "Organization"
    },
    "id": "https://training.galaxyproject.org",
    "email": "galaxytrainingnetwork@gmail.com",
    "name": "Galaxy Training Network",
    "legalName": "Galaxy Training Network",
    "alternateName": "GTN",
    "url": "https://training.galaxyproject.org",
    "logo": "https://training.galaxyproject.org/training-material/assets/images/GTNLogo1000.png",
    "fundingModel": "The GTN's infrastructure relies on GitHub and the Galaxy Project for hosting costs. There are no full time paid staff members of the GTN. Individuals are occasionally funded on GTN-adjacent projects.",
    "keywords": [
      "galaxy",
      "bioinformatics",
      "training",
      "fair",
      "accessible"
    ],
    "status": "active",
    "foundingDate": "2015-06-29",
    "socialMedia": "https://mstdn.science/@gtn",
    "type": "project"
  },
  "workTranslation": [

  ],
  "creativeWorkStatus": "Active",
  "dateModified": "2024-06-14 09:56:50 +0000",
  "datePublished": "2021-02-23 08:46:07 +0000",
  "copyrightHolder": {
    "@type": "Organization",
    "http://purl.org/dc/terms/conformsTo": {
      "@id": "https://bioschemas.org/profiles/Organization/0.2-DRAFT-2019_07_19",
      "@type": "Organization"
    },
    "id": "https://training.galaxyproject.org",
    "email": "galaxytrainingnetwork@gmail.com",
    "name": "Galaxy Training Network",
    "legalName": "Galaxy Training Network",
    "alternateName": "GTN",
    "url": "https://training.galaxyproject.org",
    "logo": "https://training.galaxyproject.org/training-material/assets/images/GTNLogo1000.png",
    "fundingModel": "The GTN's infrastructure relies on GitHub and the Galaxy Project for hosting costs. There are no full time paid staff members of the GTN. Individuals are occasionally funded on GTN-adjacent projects.",
    "keywords": [
      "galaxy",
      "bioinformatics",
      "training",
      "fair",
      "accessible"
    ],
    "status": "active",
    "foundingDate": "2015-06-29",
    "socialMedia": "https://mstdn.science/@gtn",
    "type": "project"
  },
  "funder": [

  ],
  "funding": [

  ],
  "identifier": "https://gxy.io/GTN:T00259",
  "accessMode": [
    "textual",
    "visual"
  ],
  "accessModeSufficient": [
    "textual",
    "visual"
  ],
  "accessibilityControl": [
    "fullKeyboardControl",
    "fullMouseControl"
  ],
  "accessibilityFeature": [
    "alternativeText",
    "tableOfContents"
  ],
  "accessibilitySummary": "The text aims to be as accessible as possible. Image descriptions will vary per tutorial, from images being completely inaccessible, to images with good descriptions for non-visual users.",
  "isPartOf": {
    "@type": "CreativeWork",
    "name": "Statistics and machine learning",
    "description": "Statistical Analyses for omics data and machine learning using Galaxy tools",
    "url": "https://training.galaxyproject.org/training-material/topics/statistics/"
  },
  "abstract": "Artificial neural networks are a machine learning discipline roughly inspired by how neurons in a",
  "learningResourceType": "e-learning",
  "name": "Deep Learning (Part 2) - Recurrent neural networks (RNN)",
  "url": "https://training.galaxyproject.org/training-material/topics/statistics/tutorials/RNN/tutorial.html",
  "version": 14,
  "timeRequired": "PT2H",
  "teaches": "- Understand the difference between feedforward neural networks (FNN) and RNN\n- Learn various RNN types and architectures\n- Learn how to create a neural network using Galaxy's deep learning tools\n- Solve a sentiment analysis problem on IMDB movie review dataset using RNN in Galaxy",
  "keywords": [
    "Statistics and machine learning"
  ],
  "description": "## Abstract\n\nArtificial neural networks are a machine learning discipline roughly inspired by how neurons in a\n\n\n## About This Material\n\nThis is a Hands-on Tutorial from the GTN which is usable either for individual self-study, or as a teaching material in a classroom.\n\n\n## Questions this  will address\n\n - What is a recurrent neural network (RNN)?\n - What are some applications of RNN?\n\n\n## Learning Objectives\n\n- Understand the difference between feedforward neural networks (FNN) and RNN\n- Learn various RNN types and architectures\n- Learn how to create a neural network using Galaxy's deep learning tools\n- Solve a sentiment analysis problem on IMDB movie review dataset using RNN in Galaxy\n\n",
  "inLanguage": {
    "@type": "Language",
    "name": "English",
    "alternateName": "en"
  },
  "competencyRequired": [
    {
      "@context": "http://schema.org",
      "@type": "LearningResource",
      "url": "https://training.galaxyproject.org/training-material/topics/introduction/",
      "name": "Introduction to Galaxy Analyses",
      "description": "Introduction to Galaxy Analyses",
      "provider": {
        "@type": "Organization",
        "http://purl.org/dc/terms/conformsTo": {
          "@id": "https://bioschemas.org/profiles/Organization/0.2-DRAFT-2019_07_19",
          "@type": "Organization"
        },
        "id": "https://training.galaxyproject.org",
        "email": "galaxytrainingnetwork@gmail.com",
        "name": "Galaxy Training Network",
        "legalName": "Galaxy Training Network",
        "alternateName": "GTN",
        "url": "https://training.galaxyproject.org",
        "logo": "https://training.galaxyproject.org/training-material/assets/images/GTNLogo1000.png",
        "fundingModel": "The GTN's infrastructure relies on GitHub and the Galaxy Project for hosting costs. There are no full time paid staff members of the GTN. Individuals are occasionally funded on GTN-adjacent projects.",
        "keywords": [
          "galaxy",
          "bioinformatics",
          "training",
          "fair",
          "accessible"
        ],
        "status": "active",
        "foundingDate": "2015-06-29",
        "socialMedia": "https://mstdn.science/@gtn",
        "type": "project"
      }
    },
    {
      "@context": "http://schema.org",
      "@type": "LearningResource",
      "url": "https://training.galaxyproject.org/training-material/topics/statistics/tutorials/intro_deep_learning/tutorial.html",
      "name": "Introduction to deep learning",
      "description": "Hands-on for 'Introduction to deep learning' tutorial",
      "learningResourceType": "e-learning",
      "interactivityType": "expositive",
      "provider": {
        "@type": "Organization",
        "http://purl.org/dc/terms/conformsTo": {
          "@id": "https://bioschemas.org/profiles/Organization/0.2-DRAFT-2019_07_19",
          "@type": "Organization"
        },
        "id": "https://training.galaxyproject.org",
        "email": "galaxytrainingnetwork@gmail.com",
        "name": "Galaxy Training Network",
        "legalName": "Galaxy Training Network",
        "alternateName": "GTN",
        "url": "https://training.galaxyproject.org",
        "logo": "https://training.galaxyproject.org/training-material/assets/images/GTNLogo1000.png",
        "fundingModel": "The GTN's infrastructure relies on GitHub and the Galaxy Project for hosting costs. There are no full time paid staff members of the GTN. Individuals are occasionally funded on GTN-adjacent projects.",
        "keywords": [
          "galaxy",
          "bioinformatics",
          "training",
          "fair",
          "accessible"
        ],
        "status": "active",
        "foundingDate": "2015-06-29",
        "socialMedia": "https://mstdn.science/@gtn",
        "type": "project"
      }
    },
    {
      "@context": "http://schema.org",
      "@type": "LearningResource",
      "url": "https://training.galaxyproject.org/training-material/topics/statistics/tutorials/FNN/slides.html",
      "name": "Feedforward neural networks (FNN) \n Deep Learning - Part 1",
      "description": "Slides for 'Feedforward neural networks (FNN) \n Deep Learning - Part 1' tutorial",
      "learningResourceType": "slides",
      "interactivityType": "expositive",
      "provider": {
        "@type": "Organization",
        "http://purl.org/dc/terms/conformsTo": {
          "@id": "https://bioschemas.org/profiles/Organization/0.2-DRAFT-2019_07_19",
          "@type": "Organization"
        },
        "id": "https://training.galaxyproject.org",
        "email": "galaxytrainingnetwork@gmail.com",
        "name": "Galaxy Training Network",
        "legalName": "Galaxy Training Network",
        "alternateName": "GTN",
        "url": "https://training.galaxyproject.org",
        "logo": "https://training.galaxyproject.org/training-material/assets/images/GTNLogo1000.png",
        "fundingModel": "The GTN's infrastructure relies on GitHub and the Galaxy Project for hosting costs. There are no full time paid staff members of the GTN. Individuals are occasionally funded on GTN-adjacent projects.",
        "keywords": [
          "galaxy",
          "bioinformatics",
          "training",
          "fair",
          "accessible"
        ],
        "status": "active",
        "foundingDate": "2015-06-29",
        "socialMedia": "https://mstdn.science/@gtn",
        "type": "project"
      }
    },
    {
      "@context": "http://schema.org",
      "@type": "LearningResource",
      "url": "https://training.galaxyproject.org/training-material/topics/statistics/tutorials/FNN/tutorial.html",
      "name": "Deep Learning (Part 1) - Feedforward neural networks (FNN)",
      "description": "Hands-on for 'Deep Learning (Part 1) - Feedforward neural networks (FNN)' tutorial",
      "learningResourceType": "e-learning",
      "interactivityType": "expositive",
      "provider": {
        "@type": "Organization",
        "http://purl.org/dc/terms/conformsTo": {
          "@id": "https://bioschemas.org/profiles/Organization/0.2-DRAFT-2019_07_19",
          "@type": "Organization"
        },
        "id": "https://training.galaxyproject.org",
        "email": "galaxytrainingnetwork@gmail.com",
        "name": "Galaxy Training Network",
        "legalName": "Galaxy Training Network",
        "alternateName": "GTN",
        "url": "https://training.galaxyproject.org",
        "logo": "https://training.galaxyproject.org/training-material/assets/images/GTNLogo1000.png",
        "fundingModel": "The GTN's infrastructure relies on GitHub and the Galaxy Project for hosting costs. There are no full time paid staff members of the GTN. Individuals are occasionally funded on GTN-adjacent projects.",
        "keywords": [
          "galaxy",
          "bioinformatics",
          "training",
          "fair",
          "accessible"
        ],
        "status": "active",
        "foundingDate": "2015-06-29",
        "socialMedia": "https://mstdn.science/@gtn",
        "type": "project"
      }
    }
  ],
  "author": [
    {
      "@context": "https://schema.org",
      "@type": "Person",
      "http://purl.org/dc/terms/conformsTo": {
        "@id": "https://bioschemas.org/profiles/Person/0.3-DRAFT",
        "@type": "CreativeWork"
      },
      "url": "https://training.galaxyproject.org/training-material/hall-of-fame/kxk302/",
      "mainEntityOfPage": "https://training.galaxyproject.org/training-material/hall-of-fame/kxk302/",
      "name": "Kaivan Kamali",
      "image": "https://avatars.githubusercontent.com/kxk302",
      "description": "A contributor to the GTN project.",
      "memberOf": [
        {
          "@type": "Organization",
          "http://purl.org/dc/terms/conformsTo": {
            "@id": "https://bioschemas.org/profiles/Organization/0.2-DRAFT-2019_07_19",
            "@type": "Organization"
          },
          "id": "https://training.galaxyproject.org",
          "email": "galaxytrainingnetwork@gmail.com",
          "name": "Galaxy Training Network",
          "legalName": "Galaxy Training Network",
          "alternateName": "GTN",
          "url": "https://training.galaxyproject.org",
          "logo": "https://training.galaxyproject.org/training-material/assets/images/GTNLogo1000.png",
          "fundingModel": "The GTN's infrastructure relies on GitHub and the Galaxy Project for hosting costs. There are no full time paid staff members of the GTN. Individuals are occasionally funded on GTN-adjacent projects.",
          "keywords": [
            "galaxy",
            "bioinformatics",
            "training",
            "fair",
            "accessible"
          ],
          "status": "active",
          "foundingDate": "2015-06-29",
          "socialMedia": "https://mstdn.science/@gtn",
          "type": "project"
        }
      ]
    }
  ],
  "about": [
    {
      "@type": "CreativeWork",
      "name": "Statistics and machine learning",
      "description": "Statistical Analyses for omics data and machine learning using Galaxy tools",
      "url": "https://training.galaxyproject.org/training-material/topics/statistics/"
    },
    {
      "@type": "DefinedTerm",
      "@id": "http://edamontology.org/topic_2269",
      "inDefinedTermSet": "http://edamontology.org",
      "termCode": "topic_2269",
      "url": "https://bioportal.bioontology.org/ontologies/EDAM/?p=classes&conceptid=http%3A%2F%2Fedamontology.org%2Ftopic_2269"
    }
  ],
  "educationalLevel": "Beginner",
  "mentions": [
    {
      "@type": "Thing",
      "url": "https://training.galaxyproject.org/training-material/topics/statistics/tutorials/RNN/workflows/",
      "name": "Associated Workflows"
    },
    {
      "@type": "Thing",
      "url": "https://zenodo.org/record/4477881",
      "name": "Associated Training Datasets"
    }
  ]
}</script></head>
    <body data-spy="scroll" data-target="#toc" data-brightness="auto" data-contrast="auto">
        <script  src='/training-material/assets/js/bundle.theme.f1f2de89.js'></script>
        <header>
    <nav class="navbar navbar-expand-md navbar-dark" aria-label="Site Navigation">
        <div class="container">
            <a class="navbar-brand" href="/training-material/">
                <img src="/training-material/assets/images/GTN-60px.png" height="30" alt="Galaxy Training Network logo">
                
                    Galaxy Training!
                
            </a>

            <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#top-navbar" aria-controls="top-navbar" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="top-navbar">
                <ul class="navbar-nav">
                    <li class="nav-item">
                        
                        <a class="nav-link" href="/training-material/topics/statistics" title="Go back to list of tutorials">
                            <i class="far fa-folder" aria-hidden="true"></i> Statistics and machine learning
                        </a>
                        
                    </li>

                    <li class="nav-item">
                        
                        <a class="nav-link" href="/training-material/learning-pathways" title="Learning Pathways">
                           <i class="fas fa-graduation-cap" aria-hidden="true"></i><span class="visually-hidden">curriculum</span> Learning Pathways
                        </a>
                        
                    </li>

                    <li class="nav-item dropdown">
    <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-expanded="false" title="Help">
        <i class="far fa-question-circle" aria-hidden="true"></i><span class="visually-hidden">help</span> Help
    </a>
    <div class="dropdown-menu dropdown-menu-right">
	<a class="dropdown-item" href="/training-material/faqs/index.html" title="Check our FAQs">
           <i class="far fa-question-circle" aria-hidden="true"></i><span class="visually-hidden">question</span> FAQs
        </a>
        
        
        
        <a class="dropdown-item" href="/training-material/topics/statistics/faqs/" title="Check our FAQs for the Statistics and machine learning topic">
           <i class="far fa-question-circle" aria-hidden="true"></i><span class="visually-hidden">question</span> Topic FAQs
        </a>
        
        
        
        <a class="dropdown-item" href="https://help.galaxyproject.org/" title="Discuss on Galaxy Help">
            <i class="far fa-comments" aria-hidden="true"></i><span class="visually-hidden">feedback</span> Galaxy Help Forum
        </a>
        <a class="dropdown-item" href="https://gitter.im/Galaxy-Training-Network/Lobby" title="Discuss on gitter">
           <i class="fab fa-gitter" aria-hidden="true"></i><span class="visually-hidden">gitter</span> Discuss on Matrix
        </a>
    </div>
</li>


                    <li class="nav-item dropdown">
    <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-expanded="false" title="Settings">
	<i class="fas fa-cog" aria-hidden="true"></i><span class="visually-hidden">galaxy-gear</span> Settings
    </a>
    <div class="dropdown-menu dropdown-menu-right">

	<h6 class="dropdown-header">Preferences</h6>

	<a href="/training-material/user/theme.html" class="dropdown-item">
		<i class="fas fa-palette" aria-hidden="true"></i><span class="visually-hidden">gtn-theme</span> Theme
	</a>

	<a href="/training-material/user/privacy.html" class="dropdown-item">
		<i class="fas fa-lock" aria-hidden="true"></i><span class="visually-hidden">pref-dataprivate</span> Data Privacy
	</a>

	<div class="dropdown-divider"></div>

	<h6 class="dropdown-header">For Everyone</h6>

        <a class="dropdown-item" href="https://github.com/galaxyproject/training-material/edit/main/topics/statistics/tutorials/RNN/tutorial.md">
          <i class="fab fa-github" aria-hidden="true"></i><span class="visually-hidden">github</span> Propose a change or correction
        </a>

	<h6 class="dropdown-header">Instructor Utilities</h6>

        <a class="dropdown-item" href="/training-material/stats.html">
            <i class="fas fa-chart-column" aria-hidden="true"></i><span class="visually-hidden">galaxy-barchart</span> GTN statistics
        </a>

        <a class="dropdown-item" href="https://plausible.galaxyproject.eu/training.galaxyproject.org?period=12mo&page=/training-material/topics/statistics/tutorials/RNN/tutorial.html">
            <i class="fas fa-chart-column" aria-hidden="true"></i><span class="visually-hidden">galaxy-barchart</span> Page View Metrics
        </a>

        <!-- link to feedback -->
        
            
            
                <a class="dropdown-item" href="/training-material/feedback.html">
                    <i class="fas fa-chart-column" aria-hidden="true"></i><span class="visually-hidden">galaxy-barchart</span> GTN feedback
                </a>
            
        

        <div class="dropdown-item">
            <div>
                <i class="fas fa-history" aria-hidden="true"></i><span class="visually-hidden">galaxy-rulebuilder-history</span> Previous Versions
            </div>

            <div id="archive-selector">
            
                <a class="btn btn-warning" href="https://training.galaxyproject.org/archive/">Older Versions</a>
            </div>

        </div>

    </div>
</li>


                    <!-- Search bar-->
                    <li class="nav-item">
                      <div id="navbarSupportedContent" role="search">
                        <!-- Search form -->
                        <form class="form-inline mr-auto" method="GET" action="/training-material/search2">
                          <i class="fas fa-search nav-link" aria-hidden="true"></i>
                          <div class="md-form mb-2">
                            <input name="query" class="form-control nicer" type="text" placeholder="Search Tutorials" aria-label="Search">
                          </div>
                        </form>
                      </div>
                    </li>
                </ul>
            </div>
        </div>
    </nav>
</header>

        
        <div class="container main-content" role="main">
        














<!-- Gitter -->






<article class="tutorial topic-statistics">
    <h1 data-toc-skip>Deep Learning (Part 2) - Recurrent neural networks (RNN)</h1>
    

    <section aria-labelledby="overview-box" id="tutorial-metadata">
    <div markdown="0">

	<div class="contributors-line">
		Authors: <a href="/training-material/hall-of-fame/kxk302/" class="contributor-badge contributor-kxk302"><img src="https://avatars.githubusercontent.com/kxk302?s=36" alt="Kaivan Kamali avatar" width="36" class="avatar" />
    Kaivan Kamali</a>
	</div>

</div>


    <blockquote class="overview">
        <div id="overview-box" class="box-title">Overview</div>
        
        <img alt="Creative Commons License: CC-BY" class="float-right" style="border-width:0; display: inline-block; margin:0" src="/training-material/assets/images/cc-by.png" width="88" height="31"/>
        
        <strong><i class="far fa-question-circle" aria-hidden="true"></i> Questions:</strong>
        <ul>
        
        <li><p>What is a recurrent neural network (RNN)?</p>
</li>
        
        <li><p>What are some applications of RNN?</p>
</li>
        
        </ul>

        <strong><i class="fas fa-bullseye" aria-hidden="true"></i> Objectives: </strong>
        <ul>
        
        <li><p>Understand the difference between feedforward neural networks (FNN) and RNN</p>
</li>
        
        <li><p>Learn various RNN types and architectures</p>
</li>
        
        <li><p>Learn how to create a neural network using Galaxy’s deep learning tools</p>
</li>
        
        <li><p>Solve a sentiment analysis problem on IMDB movie review dataset using RNN in Galaxy</p>
</li>
        
        </ul>

        
        <strong><i class="fas fa-check-circle" aria-hidden="true"></i> Requirements:</strong>
        <ul>
        
    
        
        
        
        <li>
          <a href="/training-material/topics/introduction">Introduction to Galaxy Analyses</a>
        </li>
        
    


        
    
        
        
        
            
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                        
                        
                            
                                <li>
                                  <a href="/training-material/topics/statistics/tutorials/intro_deep_learning/tutorial.html"><i class="fas fa-laptop" aria-hidden="true"></i><span class="visually-hidden">tutorial</span> Hands-on: Introduction to deep learning</a>
                                </li>
                            
                        
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                        
                            <li>
                              <a href="/training-material/topics/statistics/tutorials/FNN/slides.html"><i class="fab fa-slideshare" aria-hidden="true"></i><span class="visually-hidden">slides</span> Slides: Deep Learning (Part 1) - Feedforward neural networks (FNN)</a>
                            </li>
                        
                        
                            
                                <li>
                                  <a href="/training-material/topics/statistics/tutorials/FNN/tutorial.html"><i class="fas fa-laptop" aria-hidden="true"></i><span class="visually-hidden">tutorial</span> Hands-on: Deep Learning (Part 1) - Feedforward neural networks (FNN)</a>
                                </li>
                            
                        
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            
        
    


        </ul>
        

        
        <div><strong><i class="fas fa-hourglass-half" aria-hidden="true"></i> Time estimation:</strong> 2 hours</div>
        

        

        

        

        <div id="supporting-materials"><strong><i class="fa fa-external-link" aria-hidden="true"></i> Supporting Materials:</strong></div>
        <ul class="supporting_material">
            
                <li class="btn btn-default"><a href="/training-material/topics/statistics/tutorials/RNN/slides.html" title="Slides for this tutorial">
                    <i class="fab fa-slideshare" aria-hidden="true"></i> Slides
                </a></li>
            

            
                <li class="btn btn-default supporting_material">


<a class="btn btn-default topic-icon" title="Zenodo datasets used in this tutorial" href="https://zenodo.org/record/4477881">
    <i class="far fa-copy" aria-hidden="true"></i>&nbsp;Datasets
</a>

</li>
            

            
                <li class="btn btn-default supporting_material">


    <a class="btn btn-default topic-icon" href="/training-material/topics/statistics/tutorials/RNN/workflows/" title="Deep Learning (Part 2) - Recurrent neural networks (RNN) workflows">
        <i class="fas fa-share-alt" aria-hidden="true"></i>&nbsp;Workflows
    </a>

</li>
            

            

            

            

            

            
            
            
                <li class="btn btn-default supporting_material">    <a class="topic-icon" href="/training-material/topics/statistics/tutorials/RNN/faqs/" title="Frequently Asked Questions">
        <i class="far fa-question-circle" aria-hidden="true"></i> FAQs
    </a>
</li>
            

            <!-- Check the GTN Video Library for recordings of this tutorial or associated slides -->
            











<li class="btn btn-default supporting_material">


  <!-- dropdown with all recordings -->
  <a href="/training-material/topics/statistics/tutorials/RNN/recordings/" class="btn btn-default dropdown-toggle topic-icon" data-toggle="dropdown" aria-expanded="false" title="Latest recordings of this material in the GTN Video Library">
        <i class="fas fa-video" aria-hidden="true"></i><span class="visually-hidden">video</span>&nbsp;Recordings
  </a>


  <ul class="dropdown-menu">
    

    
      
      
      
    <li><a class="dropdown-item" href="/training-material/topics/statistics/tutorials/RNN/recordings/index.html#tutorial-recording-15-february-2021" title="View the recording for this tutorial">
                <i class="fas fa-video" aria-hidden="true"></i><span class="visually-hidden">video</span> Tutorial (February 2021) - 50m</a>
    </li>
      
    
    <li><a class="dropdown-item" href="/training-material/topics/statistics/tutorials/RNN/recordings/" title="View all recordings for this tutorial">
                <i class="fas fa-video" aria-hidden="true"></i><span class="visually-hidden">video</span> View All</a>
    </li>

  </ul>

  
</li>
  





            
                
                <li class="btn btn-default supporting_material">






    <a href="#" class="dropdown-toggle" data-toggle="dropdown" aria-expanded="false" title="Where to run the tutorial">
        <i class="fas fa-globe" aria-hidden="true"></i><span class="visually-hidden">instances</span>&nbsp;Available on these Galaxies 
    </a>
    <ul class="dropdown-menu">
        
	<li class="dropdown-header">
		<b>Known Working</b>
	</li>
	
	

    
	<li>
		<a class="dropdown-item" href="https://usegalaxy.eu" title="">
			UseGalaxy.eu <abbr title="This instance supports the precise tool versions used in this tutorial">✅</abbr> <abbr title="This is a UseGalaxy.* server which meets minimum requirements for a public Galaxy">⭐️</abbr>
		</a>
	</li>
    
	<li>
		<a class="dropdown-item" href="https://usegalaxy.org" title="">
			UseGalaxy.org (Main) <abbr title="This instance supports the precise tool versions used in this tutorial">✅</abbr> <abbr title="This is a UseGalaxy.* server which meets minimum requirements for a public Galaxy">⭐️</abbr>
		</a>
	</li>
    
	<li>
		<a class="dropdown-item" href="https://usegalaxy.org.au" title="">
			UseGalaxy.org.au <abbr title="This instance supports the precise tool versions used in this tutorial">✅</abbr> <abbr title="This is a UseGalaxy.* server which meets minimum requirements for a public Galaxy">⭐️</abbr>
		</a>
	</li>
    
    
	<li>
		<a class="dropdown-item" href="https://usegalaxy.cz/" title="">
			UseGalaxy.cz <abbr title="This instance supports the precise tool versions used in this tutorial">✅</abbr>
		</a>
	</li>
    
    
    
	<li class="dropdown-header">
		<b>Possibly Working</b>
	</li>
    
	<li>
		<a class="dropdown-item" href="https://usegalaxy.be/" title="">
			UseGalaxy.be
		</a>
	</li>
    
    

    </ul>

</li>
                
            
        </ul>

        <div><strong><i class="far fa-calendar" aria-hidden="true"></i> Published:</strong> Feb 23, 2021 </div>
        <div><strong><i class="far fa-calendar" aria-hidden="true"></i> Last modification:</strong> Jun 14, 2024 </div>
        <div><strong><i class="fas fa-balance-scale" aria-hidden="true"></i> License:</strong>
		
            Tutorial Content is licensed under
            
              <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
            
            The GTN Framework is licensed under <a rel="license" href="https://github.com/galaxyproject/training-material/blob/main/LICENSE.md">MIT</a>
        </div>
        
        <div><strong><i class="fas fa-fingerprint" aria-hidden="true"></i><span class="visually-hidden">purl</span> <abbr title="Persistent URL">PURL</abbr>:</strong> <a href="https://gxy.io/GTN:T00259">https://gxy.io/GTN:T00259</a> </div>
        

	
	

	
	
	<div><strong><i class="far fa-star" aria-hidden="true"></i><span class="visually-hidden">rating</span> Rating:</strong> <a href="#feedback-responses">4.5</a> (0 recent ratings, 2 all time)</div>
	
	<div><strong><i class="fas fa-code-commit" aria-hidden="true"></i><span class="visually-hidden">version</span> Revision:</strong> 14 </div>

    </blockquote>
    </section>

    <div class="container">
        <div class="row">
            <!-- sidebar, which will move to the top on a small screen -->
            <div class="col-sm-2 hide-when-printing">
                <nav id="toc" data-toggle="toc" class="sticky-top" aria-label="Table of Contents"></nav>
            </div>
            <div class="col-sm-10">
                 

                <section aria-label="Tutorial Content" id="tutorial-content">
                <p>Artificial neural networks are a machine learning discipline roughly inspired by how neurons in a
human brain work. In the past decade, there has been a huge resurgence of neural networks thanks
to the vast availability of data and enormous increases in computing capacity (successfully
training complex neural networks in some domains requires lots of data and compute capacity). There
are various types of neural networks (feedforward, recurrent, etc). In this tutorial, we discuss
recurrent neural networks (RNN), which model sequential data, and have been successfully applied to language
generation, machine translation, speech recognition, image description, and text summarization
(<span class="citation"><a href="#wen-etal-2015-semantically">Wen <i>et al.</i> 2015</a></span>, <span class="citation"><a href="#cho-etal-2014-learning">Cho <i>et al.</i> 2014</a></span>, <span class="citation"><a href="#LimEtAl">Lim <i>et al.</i> 2016</a></span>,
<span class="citation"><a href="#karpathyEtAl">Karpathy and Fei-Fei 2017</a></span>, <span class="citation"><a href="#li-etal-2017-deep">Li <i>et al.</i> 2017</a></span>). We start by explaining how RNN differ from
feedforward networks (FNN), describe various RNN architectures, and solve a sentiment analysis problem
using RNN in Galaxy.</p>

<blockquote class="agenda">
  <div class="box-title agenda-title" id="agenda">Agenda</div>

  <p>In this tutorial, we will cover:</p>

<ol id="markdown-toc">
  <li><a href="#feedforward-neural-networks-fnn" id="markdown-toc-feedforward-neural-networks-fnn">Feedforward neural networks (FNN)</a>    <ol>
      <li><a href="#single-layer-fnn" id="markdown-toc-single-layer-fnn">Single layer FNN</a></li>
      <li><a href="#multi-layer-fnn" id="markdown-toc-multi-layer-fnn">Multi-layer FNN</a></li>
      <li><a href="#learning-algorithm" id="markdown-toc-learning-algorithm">Learning algorithm</a></li>
    </ol>
  </li>
  <li><a href="#recurrent-neural-networks" id="markdown-toc-recurrent-neural-networks">Recurrent neural networks</a>    <ol>
      <li><a href="#possible-rnn-inputsoutputs" id="markdown-toc-possible-rnn-inputsoutputs">Possible RNN inputs/outputs</a></li>
      <li><a href="#rnn-architectures" id="markdown-toc-rnn-architectures">RNN architectures</a></li>
    </ol>
  </li>
  <li><a href="#text-representation-schemes" id="markdown-toc-text-representation-schemes">Text representation schemes</a>    <ol>
      <li><a href="#text-preprocessing" id="markdown-toc-text-preprocessing">Text preprocessing</a></li>
      <li><a href="#bag-of-words-and-tf-idf" id="markdown-toc-bag-of-words-and-tf-idf">Bag of words and TF-IDF</a></li>
      <li><a href="#one-hot-encoding-ohe" id="markdown-toc-one-hot-encoding-ohe">One hot encoding (OHE)</a></li>
      <li><a href="#word2vec" id="markdown-toc-word2vec">Word2Vec</a></li>
    </ol>
  </li>
  <li><a href="#get-data" id="markdown-toc-get-data">Get Data</a></li>
  <li><a href="#sentiment-classification-of-imdb-movie-reviews-with-rnn" id="markdown-toc-sentiment-classification-of-imdb-movie-reviews-with-rnn">Sentiment Classification of IMDB movie reviews with RNN</a>    <ol>
      <li><a href="#create-a-deep-learning-model-architecture" id="markdown-toc-create-a-deep-learning-model-architecture">Create a deep learning model architecture</a></li>
      <li><a href="#create-a-deep-learning-model" id="markdown-toc-create-a-deep-learning-model">Create a deep learning model</a></li>
      <li><a href="#deep-learning-training-and-evaluation" id="markdown-toc-deep-learning-training-and-evaluation">Deep learning training and evaluation</a></li>
      <li><a href="#model-prediction" id="markdown-toc-model-prediction">Model Prediction</a></li>
      <li><a href="#machine-learning-visualization-extension" id="markdown-toc-machine-learning-visualization-extension">Machine Learning Visualization Extension</a></li>
    </ol>
  </li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
</ol>

</blockquote>

<h1 id="feedforward-neural-networks-fnn">Feedforward neural networks (FNN)</h1>

<p>In feedforward neural networks (FNN) a single training example is presented to the network,
after which the network generates an output. For example, a lung X-ray image is passed
to a FNN, and the network predicts tumor or no tumor.</p>

<h2 id="single-layer-fnn">Single layer FNN</h2>

<figure id="figure-1" style="max-width: 90%;"><img src="../../images/FFNN_no_hidden.png" alt="Neurons forming the input and output layers of a single layer feedforward neural network. " width="233" height="463" loading="lazy" /><a target="_blank" href="../../images/FFNN_no_hidden.png" rel="noopener noreferrer"><small>Open image in new tab</small></a><br /><br /><figcaption><span class="figcaption-prefix"><strong>Figure 1</strong>:</span> Single layer feedforward neural network</figcaption></figure>

<p>Figure 1 shows a single layer FNN, where the input is 3 dimensional. Each input field is multiplied by a
weight. Afterwards, the results are summed up, along with a bias, and passed to an activation function.</p>

<figure id="figure-2" style="max-width: 90%;"><img src="../../images/activation.gif" alt="An activation function (such as Sigmoid, Tanh, etc.) applied to the input of the only neuron in the output layer of a feedforward neural network. " width="147" height="53" loading="lazy" /><a target="_blank" href="../../images/activation.gif" rel="noopener noreferrer"><small>Open image in new tab</small></a><br /><br /><figcaption><span class="figcaption-prefix"><strong>Figure 2</strong>:</span> Activation of the output neuron o1. Activation function f could be Sigmoid, Tanh, ReLU, etc.</figcaption></figure>

<p>The activation function can have many forms (sigmoid, tanh, ReLU, linear, step function, sign function, etc.).
Output layer neurons usually have <em>sigmoid</em> or <em>tanh</em> functions. For more information on the listed activation
functions, please refer to <span class="citation"><a href="#nwankpaEtAl">Nwankpa <i>et al.</i> 2018</a></span>.</p>

<figure id="figure-3" style="max-width: 90%;"><img src="../../images/sigmoid.gif" alt="Mathmatical formula for Sigmoid activation function. " width="231" height="39" loading="lazy" /><a target="_blank" href="../../images/sigmoid.gif" rel="noopener noreferrer"><small>Open image in new tab</small></a><br /><br /><figcaption><span class="figcaption-prefix"><strong>Figure 3</strong>:</span> Sigmoid activation function</figcaption></figure>

<h2 id="multi-layer-fnn">Multi-layer FNN</h2>

<p>Minsky and Papert showed that a single layer FNN cannot solve problems in which the data is not linearly separable,
such as the XOR problem (<span class="citation"><a href="#Newell780">Newell 1969</a></span>). Adding one (or more) hidden layers to FNN enables it to solve problems
in which data is non-linearly separable. Per Universal Approximation Theorem, a FNN with one hidden layer can represent
any function (<span class="citation"><a href="#Cybenko1989">Cybenko 1989</a></span>), although in practice training such a model is very difficult (if not impossible),
hence, we usually add multiple hidden layers to solve complex problems.</p>

<figure id="figure-4" style="max-width: 90%;"><img src="../../images/FFNN.png" alt="Neurons forming the input, output, and hidden layers of a multi-layer feedforward neural network. " width="361" height="461" loading="lazy" /><a target="_blank" href="../../images/FFNN.png" rel="noopener noreferrer"><small>Open image in new tab</small></a><br /><br /><figcaption><span class="figcaption-prefix"><strong>Figure 4</strong>:</span> Feedforward neural network with a hidden layer. Biases to hidden/output layer neurons are omitted for clarity</figcaption></figure>

<h2 id="learning-algorithm">Learning algorithm</h2>

<p>In supervised learning, we are given a set of input-output pairs, called the <em>training set</em>. Given the training set, the learning algorithm
(iteratively) adjusts the model parameters, so that the model can accurately map inputs to outputs. We usually have another set of input-output
pairs, called the <em>test set</em>, which is not used by the learning algorithm. When the learning algorithm completes, we assess the learned model by
providing the test set inputs to the model and comparing the model outputs to test set outputs. We need to define a <strong>loss function</strong> to objectively
measure how much the model output is off of the expected output. For classification problems we use the <strong>cross entropy</strong> loss function.</p>

<figure id="figure-5" style="max-width: 90%;"><img src="../../images/CrossEntropy.gif" alt="Mathematical formula for calculating the cross entropy loss function, which quantifies the difference between the predicted and desired output of a neural network. " width="241" height="51" loading="lazy" /><a target="_blank" href="../../images/CrossEntropy.gif" rel="noopener noreferrer"><small>Open image in new tab</small></a><br /><br /><figcaption><span class="figcaption-prefix"><strong>Figure 5</strong>:</span> Cross entropy loss function</figcaption></figure>

<p>The loss function is calculated for each input-output pair in the training set. The average of the calculated loss functions for all training
set input-output pairs is called the <strong>Cost function</strong>. The goal of the learning algorithm is to minimize the cost function. The cost function
is a function of network weights and biases of all neurons in all layers. The <strong>backpropagation</strong> learning algorithm <span class="citation"><a href="#Rumelhart1986">Rumelhart <i>et al.</i> 1986</a></span>
iteratively computes the gradient of cost function relative to each weight and bias, then updates the weights and biases in the opposite
direction of the gradient, to find the local minimum.</p>

<figure id="figure-6" style="max-width: 90%;"><img src="../../images/CostFunction.gif" alt="Mathematical formula for calcuating the cross entropy cost function, which is just the average of cross entropy loss functions for training samples. " width="270" height="54" loading="lazy" /><a target="_blank" href="../../images/CostFunction.gif" rel="noopener noreferrer"><small>Open image in new tab</small></a><br /><br /><figcaption><span class="figcaption-prefix"><strong>Figure 6</strong>:</span> Cross entropy cost function</figcaption></figure>

<h1 id="recurrent-neural-networks">Recurrent neural networks</h1>

<p>Unlike FNN, in RNN the output of the network at time <em>t</em> is used as network input
at time <em>t+1</em>. In RNN, a training example is a sequence, which is presented to the
network one at a time. For example, a sequence of English words is passed to a
RNN, one at a time, and the network generates a sequence of Persian words, one
at a time. RNN handle sequential data, whether its temporal or ordinal.</p>

<h2 id="possible-rnn-inputsoutputs">Possible RNN inputs/outputs</h2>

<p>There are 4 possible input/output combinations for RNN and each have a specific application. <em>One-to-one</em> is basically a FNN. <em>One-to-many</em> is
where we have one input and a variable number of outputs. One example application is image captioning, where a single image is provided
as input and a variable number of words (which caption the image) is returned as output (see Figure 7).</p>

<figure id="figure-7" style="max-width: 90%;"><img src="../../images/RNN_1_to_n.png" alt="Neurons forming a one-to-many recurrent neural network. " width="596" height="644" loading="lazy" /><a target="_blank" href="../../images/RNN_1_to_n.png" rel="noopener noreferrer"><small>Open image in new tab</small></a><br /><br /><figcaption><span class="figcaption-prefix"><strong>Figure 7</strong>:</span> One-to-many RNN</figcaption></figure>

<p><em>Many-to-one</em> RNN combination has a variable number of inputs and a single output. One example application is document sentiment
classification, where a variable number of words in a document are presented as input, and a single output predicts whether the document
has a positive or negative sentiment regarding a topic (see Figure 8).</p>

<figure id="figure-8" style="max-width: 90%;"><img src="../../images/RNN_n_to_1.png" alt="Neurons forming a many-to-one recurrent neural network. " width="560" height="475" loading="lazy" /><a target="_blank" href="../../images/RNN_n_to_1.png" rel="noopener noreferrer"><small>Open image in new tab</small></a><br /><br /><figcaption><span class="figcaption-prefix"><strong>Figure 8</strong>:</span> Many-to-one RNN</figcaption></figure>

<p>Finally there is many-to-many RNN, which have two types: one in which the number of inputs and outputs match, e.g., in labeling the video frames the number
of frames matches the number of labels, and the other in which the number of inputs and outputs do not match, e.g., in language translation
we pass in <em>n</em> words in English and get <em>m</em> words in Italian (see Figure 9).</p>

<figure id="figure-9" style="max-width: 90%;"><img src="../../images/RNN_n_to_m.png" alt="Neurons forming a many-to-many recurrent neural network. " width="560" height="475" loading="lazy" /><a target="_blank" href="../../images/RNN_n_to_m.png" rel="noopener noreferrer"><small>Open image in new tab</small></a><br /><br /><figcaption><span class="figcaption-prefix"><strong>Figure 9</strong>:</span> Many-to-many RNN</figcaption></figure>

<h2 id="rnn-architectures">RNN architectures</h2>

<p>Mainly, there are three types of RNN: 1) Vanilla RNN, 2) LSTM (<span class="citation"><a href="#hochreiter1997long">Hochreiter and Schmidhuber 1997</a></span>), and 3) GRU (<span class="citation"><a href="#cho-etal-2014-learning">Cho <i>et al.</i> 2014</a></span>).
A Vanilla RNN, simply combines the state information from the previous timestamp with the input from the current timestamp to generate the
state information and output for current timestamp. A problem with Vanilla RNN is that training deep RNN networks is impossible due to the
<strong>vanishing gradient</strong> problem. Basically, weights/biases are updated according to the gradient of the loss functions relative to
the weights/biases. The gradients are calculated recursively from the output layer towards the input layer (hence, the name <em>backpropagation</em>).
The gradient of the input layer is the product of the gradient of the subsequent layers. If those gradients are small, the gradient of the input
layer (which is the product of multiple small values) will very small, resulting in very small updates to weights/biases of the initial layers
of the RNN, effectively halting the learning process.</p>

<p>LSTM and GRU are two RNN architectures that address vanishing gradient problem. Full description of LSTM/GRU is beyond the scope of this
tutorial (please refer to <span class="citation"><a href="#hochreiter1997long">Hochreiter and Schmidhuber 1997</a></span> and <span class="citation"><a href="#cho-etal-2014-learning">Cho <i>et al.</i> 2014</a></span>), but in a nutshell both LSTM and GRU use <strong>gates</strong> such that the weights/biases updates in previous
layers are calculated via a series of additions (not multiplications). Hence, these architectures can learn even when the RNN has hundreds or
thousands of layers.</p>

<h1 id="text-representation-schemes">Text representation schemes</h1>

<p>In this tutorial we perform sentiment analysis on IMDB (https://www.imdb.com/) movie reviews dataset (<span class="citation"><a href="#maas-EtAl">Maas <i>et al.</i> 2011</a></span>). We train our RNN on
the training dataset, which is made up of 25,000 movie reviews, some positive and some negative. We then test our RNN on the test set, which is
also made up of 25,000 movie reviews, again some positive and some negative. The training and test sets have no overlap. Since we are dealing with
text data, it’s a good idea to review various mechanisms for representing text data. Before that, we are going to briefly discuss how to preprocess
text documents.</p>

<h2 id="text-preprocessing">Text preprocessing</h2>

<p>The first step is to tokenize a document, i.e., break it down into words. Next, we remove the punctuation marks, URLs, and stop words – words like
‘a’, ‘of’, ‘the’, etc. that happen frequently in all documents and do not have much value in discriminating between documents. Next, we normalize
the text, e.g., replace ‘brb’ with ‘Be right back’, etc. Then, We then run the spell checker to fix typos and also make all words lowercase. Next, we perform stemming or lemmatization. Namely, if we have words like ‘organizer’, ‘organize’, ‘organized’, and ‘organization’ we want to reduce all of them to a single word. Stemming cuts the end of these words to come up with a single root (e.g., ‘organiz’). The root may not be an actual word.
Meanwhile, lemmatization is smarter in that it reduces the word variants to a root that is actually a word (e.g., ‘organize’). All of these steps help reduce
the number of features in feature vector of a document and should make the training of our model faster/easier.</p>

<p>For this introductory tutorial, we do minimal text preprocessing. We ignore the top 50 words in IMDB reviews (mostly stop words) and include
the next 10,000 words in our dataset. Reviews are limited to 500 words. They are trimmed if they are longer and padded if they are shorter.</p>

<h2 id="bag-of-words-and-tf-idf">Bag of words and TF-IDF</h2>

<p>If you don’t care about the order of the words in a document, you can use bag of words (BoW) or term frequency inverse document frequency (TF-IDF).
In these models we have a 2 dimensional array. The rows represent the documents (in our example, the movie reviews) and the columns
represent the words in our vocabulary (all the unique words in all the documents). If a word is not present in a document, we have a zero
at the corresponding row and column as the entry. If a word is present in the document, we have a one as the entry – Alternatively, we could use
the word count or frequency.</p>

<figure id="figure-10" style="max-width: 90%;"><img src="../../images/BoW.png" alt="Table showing a bag-of-words representation of sample documents. " width="1349" height="78" loading="lazy" /><a target="_blank" href="../../images/BoW.png" rel="noopener noreferrer"><small>Open image in new tab</small></a><br /><br /><figcaption><span class="figcaption-prefix"><strong>Figure 10</strong>:</span> Bag of words (BoW) representation</figcaption></figure>

<p>Suppose we have the following 2 documents: 1) Magic passed the basketball to Kareem, and 2) Lebron stole the basketball from Curry. The BoW
representation of these documents is given in Figure 10.</p>

<p>BoW’s advantage is its simplicity, yet it does not take into account the rarity of a word across documents, which unlike common words are
important for document classification.</p>

<p>In TF-IDF, similar to BoW we have an entry for each document-word pair. In TD-IDF, the entry is the product of 1) term frequency, the
frequency of a word in a document, and 2) inverse document frequency, the inverse of the number of documents that have the word divided
by the total number of documents (we usually use logarithm of the IDF).</p>

<p>TF-IDF takes into account the rarity of a word across documents, and like BoW, it also does not capture word order or word meaning in documents. BoW
and TF-IDF are suitable representations for when word order is not important. They are used in document classification problems, like spam detection.</p>

<h2 id="one-hot-encoding-ohe">One hot encoding (OHE)</h2>

<p>OHE is a technique to convert categorical variables such as words into a vector. Suppose our vocabulary has 3 words: orange, apple, banana.
Each word for this vocabulary is represented by a vector of size 3. Orange is represented by a vector whose first element is 1 and other
elements are 0; apple is represented by a vector whose second element is 1 and other elements are 0; and banana is represented by a
vector whose third element is 1 and other elements are 0. As you can see only one element in the vector is 1 and the rest are 0’s. The same
concept applies if the size of the vocabulary is N.</p>

<figure id="figure-11" style="max-width: 90%;"><img src="../../images/OHE.gif" alt="Mathematical vectors representing one-hot-encoding representation of words orange, apple, and banana. " width="359" height="66" loading="lazy" /><a target="_blank" href="../../images/OHE.gif" rel="noopener noreferrer"><small>Open image in new tab</small></a><br /><br /><figcaption><span class="figcaption-prefix"><strong>Figure 11</strong>:</span> One hot encoding (OHE) representation</figcaption></figure>

<p>The problem with OHE is that for very large vocabulary sizes (say, 100,000 words) it requires tremendous amount of storage. Also, it has no
concept of word similarity.</p>

<h2 id="word2vec">Word2Vec</h2>

<p>In Word2Vec, each word is represented as an <em>n</em> dimensional vector (<em>n</em> being much smaller than vocabulary size), such that the words that have
similar meanings are closer to each other in the vector space, and words that don’t have a similar meaning are farther apart. Words are
considered to have a similar meaning if they co-occur often in documents. There are 2 Word2Vec architectures, one that predicts the probability
of a word given the surrounding words (continuous BoW), and one that given a word predicts the probability of the surrounding words (continuous
skip-gram).</p>

<p>In this tutorial, we find an <em>n</em> dimensional representation of the IMDB movie review words, not based on word meanings, but based on how they
improve the sentiment classification task. The <em>n</em> dimensional representation is learned by the learning algorithm, simply by reducing the
cost function via backpropagation.</p>

<h1 id="get-data">Get Data</h1>

<blockquote class="notranslate hands_on">
  <div class="box-title hands-on-title" id="hands-on-data-upload"><i class="fas fa-pencil-alt" aria-hidden="true" ></i> Hands-on: Data upload</div>

  <ol>
    <li>
      <p>Create a new history for this tutorial</p>

      <!--SNIPPET-->
      <blockquote class="tip">   <div class="box-title tip-title" id="tip-creating-a-new-history"><button class="gtn-boxify-button tip" type="button" aria-controls="tip-creating-a-new-history" aria-expanded="true"><i class="far fa-lightbulb" aria-hidden="true"></i> <span>Tip: Creating a new history</span><span class="fold-unfold fa fa-minus-square"></span></button></div>   <p>To create a new history simply click the <i class="fas fa-plus" aria-hidden="true"></i><span class="visually-hidden">new-history</span> icon at the top of the history panel:</p>   <p><img src="/training-material/shared/images/history_create_new.svg" alt="UI for creating new history" /></p>   <!-- the original drawing can be found here https://docs.google.com/drawings/d/1cCBrLAo4kDGic5QyB70rRiWJAKTenTU8STsKDaLcVU8/edit?usp=sharing --> </blockquote>
      <p><!--END_SNIPPET--></p>
    </li>
    <li>
      <p>Import the files from <a href="https://zenodo.org/record/4477881">Zenodo</a> and choose the type of data as <code class="language-plaintext highlighter-rouge">tabular</code></p>

      <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>https://zenodo.org/record/4477881/files/X_test.tsv
https://zenodo.org/record/4477881/files/X_train.tsv
https://zenodo.org/record/4477881/files/y_test.tsv
https://zenodo.org/record/4477881/files/y_train.tsv
</code></pre></div>      </div>

      <!--SNIPPET-->
      <blockquote class="tip">   <div class="box-title tip-title" id="tip-importing-via-links"><button class="gtn-boxify-button tip" type="button" aria-controls="tip-importing-via-links" aria-expanded="true"><i class="far fa-lightbulb" aria-hidden="true"></i> <span>Tip: Importing via links</span><span class="fold-unfold fa fa-minus-square"></span></button></div>   <ul>   <li>Copy the link location</li>   <li>     <p>Click <i class="fas fa-upload" aria-hidden="true"></i><span class="visually-hidden">galaxy-upload</span> <strong>Upload Data</strong> at the top of the tool panel</p>   </li>   <li>Select <i class="fa fa-edit" aria-hidden="true"></i><span class="visually-hidden">galaxy-wf-edit</span> <strong>Paste/Fetch Data</strong></li>   <li>     <p>Paste the link(s) into the text field</p>   </li>   <li>     <p>Press <strong>Start</strong></p>   </li>   <li><strong>Close</strong> the window</li> </ul> </blockquote>
      <p><!--END_SNIPPET--></p>
    </li>
    <li>
      <p>Rename the datasets as <code class="language-plaintext highlighter-rouge">X_test</code>, <code class="language-plaintext highlighter-rouge">X_train</code>, <code class="language-plaintext highlighter-rouge">y_test</code>, and <code class="language-plaintext highlighter-rouge">y_train</code> respectively.</p>

      <!--SNIPPET-->
      <blockquote class="tip">   <div class="box-title tip-title" id="tip-renaming-a-dataset"><button class="gtn-boxify-button tip" type="button" aria-controls="tip-renaming-a-dataset" aria-expanded="true"><i class="far fa-lightbulb" aria-hidden="true"></i> <span>Tip: Renaming a dataset</span><span class="fold-unfold fa fa-minus-square"></span></button></div>   <ul>   <li>Click on the <i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">galaxy-pencil</span> <strong>pencil icon</strong> for the dataset to edit its attributes</li>   <li>In the central panel, change the <strong>Name</strong> field</li>   <li>Click the <strong>Save</strong> button</li> </ul> </blockquote>
      <p><!--END_SNIPPET--></p>
    </li>
    <li>
      <p>Check that the datatype of all the four datasets is <code class="language-plaintext highlighter-rouge">tabular</code>. If not, change the dataset’s datatype to tabular.</p>

      <!--SNIPPET-->
      <blockquote class="tip">   <div class="box-title tip-title" id="tip-changing-the-datatype"><button class="gtn-boxify-button tip" type="button" aria-controls="tip-changing-the-datatype" aria-expanded="true"><i class="far fa-lightbulb" aria-hidden="true"></i> <span>Tip: Changing the datatype</span><span class="fold-unfold fa fa-minus-square"></span></button></div>   <ul>   <li>Click on the <i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">galaxy-pencil</span> <strong>pencil icon</strong> for the dataset to edit its attributes</li>   <li>In the central panel, click <i class="fas fa-database" aria-hidden="true"></i><span class="visually-hidden">galaxy-chart-select-data</span> <strong>Datatypes</strong> tab on the top</li>   <li>In the <i class="fas fa-database" aria-hidden="true"></i><span class="visually-hidden">galaxy-chart-select-data</span> <strong>Assign Datatype</strong>, select <code class="language-plaintext highlighter-rouge">tabular</code> from “<em>New type</em>” dropdown     <ul>       <li>Tip: you can start typing the datatype into the field to filter the dropdown menu</li>     </ul>   </li>   <li>Click the <strong>Save</strong> button</li> </ul> </blockquote>
      <p><!--END_SNIPPET--></p>
    </li>
  </ol>

</blockquote>

<h1 id="sentiment-classification-of-imdb-movie-reviews-with-rnn">Sentiment Classification of IMDB movie reviews with RNN</h1>

<p>In the section, we define a RNN and train it using IMDB movie reviews training dataset. The goal is to learn a model such that given the
words in a review we can predict whether the review was positive or negative. We then evaluate the trained RNN on the test dataset
and plot the confusion matrix.</p>

<h2 id="create-a-deep-learning-model-architecture">Create a deep learning model architecture</h2>

<blockquote class="notranslate hands_on">
  <div class="box-title hands-on-title" id="hands-on-model-config"><i class="fas fa-pencil-alt" aria-hidden="true" ></i> Hands-on: Model config</div>

  <ul>
    <li><span class="tool" data-tool="toolshed.g2.bx.psu.edu/repos/bgruening/keras_model_config/keras_model_config/1.0.10.0" title="Create a deep learning model architecture tool" aria-role="button"><i class="fas fa-wrench" aria-hidden="true"></i> <strong>Create a deep learning model architecture</strong> (<i class="fas fa-cubes" aria-hidden="true"></i> Galaxy version 1.0.10.0)</span>
      <ul>
        <li><em>“Select keras model type”</em>: <code class="language-plaintext highlighter-rouge">sequential</code></li>
        <li><em>“input_shape”</em>: <code class="language-plaintext highlighter-rouge">(500,)</code></li>
        <li>In <em>“LAYER”</em>:
          <ul>
            <li><i class="far fa-plus-square" aria-hidden="true"></i><span class="visually-hidden">param-repeat</span> <em>“1: LAYER”</em>:
              <ul>
                <li><em>“Choose the type of layer”</em>: <code class="language-plaintext highlighter-rouge">Embedding -- Embedding</code>
                  <ul>
                    <li><em>“input_dim”</em>”: <code class="language-plaintext highlighter-rouge">10000</code></li>
                    <li><em>“output_dim”</em>”: <code class="language-plaintext highlighter-rouge">32</code></li>
                  </ul>
                </li>
              </ul>
            </li>
            <li><i class="far fa-plus-square" aria-hidden="true"></i><span class="visually-hidden">param-repeat</span> <em>“2: LAYER”</em>:
              <ul>
                <li><em>“Choose the type of layer”</em>: <code class="language-plaintext highlighter-rouge">Recurrent -- LSTM</code>
                  <ul>
                    <li><em>“units”</em>”: <code class="language-plaintext highlighter-rouge">100</code></li>
                  </ul>
                </li>
              </ul>
            </li>
            <li><i class="far fa-plus-square" aria-hidden="true"></i><span class="visually-hidden">param-repeat</span> <em>“3: LAYER”</em>:
              <ul>
                <li><em>“Choose the type of layer”</em>: <code class="language-plaintext highlighter-rouge">Core -- Dense</code>
                  <ul>
                    <li><em>“units”</em>: <code class="language-plaintext highlighter-rouge">1</code></li>
                    <li><em>“Activation function”</em>: <code class="language-plaintext highlighter-rouge">sigmoid</code></li>
                  </ul>
                </li>
              </ul>
            </li>
          </ul>
        </li>
        <li>Click <em>“Run Tool”</em></li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>Input is a movie review of size 500 (longer reviews were trimmed and shorter ones padded). Our neural network has 3 layers. The first layer is
an embedding layer, that transforms each review words into a 32 dimensional vector (<em>output_dim</em>). We have 10,000 unique words in our IMDB dataset
(<em>input_dim</em>). The second layer is an <em>LSTM</em> layer, which is a type of RNN and it learns dependencies between time steps. We set the output size of the LSTM layer to <em>100</em>. The third layer is a
<em>Dense</em> layer, which is a fully connected layer (all 100 output neurons in LSTM layer are connected to a single neuron in this layer). It has a
<em>sigmoid</em> activation function, that generates an output between 0 and 1. Any output greater than 0.5 is considered a predicted positive review,
and anything less than 0.5 a negative one. The model config can be downloaded as a JSON file for future reuse.</p>

<h2 id="create-a-deep-learning-model">Create a deep learning model</h2>

<blockquote class="notranslate hands_on">
  <div class="box-title hands-on-title" id="hands-on-model-builder-optimizer-loss-function-and-fit-parameters"><i class="fas fa-pencil-alt" aria-hidden="true" ></i> Hands-on: Model builder (Optimizer, loss function, and fit parameters)</div>

  <ul>
    <li><span class="tool" data-tool="toolshed.g2.bx.psu.edu/repos/bgruening/keras_model_builder/keras_model_builder/1.0.10.0" title="Create deep learning model tool" aria-role="button"><i class="fas fa-wrench" aria-hidden="true"></i> <strong>Create deep learning model</strong> (<i class="fas fa-cubes" aria-hidden="true"></i> Galaxy version 1.0.10.0)</span>
      <ul>
        <li><em>“Choose a building mode”</em>: <code class="language-plaintext highlighter-rouge">Build a training model</code></li>
        <li><em>“Select the dataset containing model configuration”</em>: Select the <em>Keras Model Config</em> from the previous step.</li>
        <li><em>“Do classification or regression?”</em>: <code class="language-plaintext highlighter-rouge">KerasGClassifier</code></li>
        <li>In <em>“Compile Parameters”</em>:
          <ul>
            <li><em>“Select a loss function”</em>: <code class="language-plaintext highlighter-rouge">binary_crossentropy</code></li>
            <li><em>“Select an optimizer”</em>: <code class="language-plaintext highlighter-rouge">Adam - Adam optimizer </code></li>
            <li><em>“Select metrics”</em>: <code class="language-plaintext highlighter-rouge">acc/accuracy</code></li>
          </ul>
        </li>
        <li>In <em>“Fit Parameters”</em>:
          <ul>
            <li><em>“epochs”</em>: <code class="language-plaintext highlighter-rouge">2</code></li>
            <li><em>“batch_size”</em>: <code class="language-plaintext highlighter-rouge">128</code></li>
          </ul>
        </li>
        <li>Click <em>“Run Tool”</em></li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>A loss function measures how different the predicted output is versus the expected output. For binary classification problems, we use
<em>binary cross entropy</em> as loss function. Epochs is the number of times the whole training data is used to train the model. Setting <em>epochs</em> to 2
means each training example in our dataset is used twice to train our model. If we update network weights/biases after all the training data is
feed to the network, the training will be very slow (as we have 25,000 training examples in our dataset). To speed up the training, we present
only a subset of the training examples to the network, after which we update the weights/biases. <em>batch_size</em> decides the size of this subset.
The model builder can be downloaded as a zip file.</p>

<h2 id="deep-learning-training-and-evaluation">Deep learning training and evaluation</h2>

<blockquote class="notranslate hands_on">
  <div class="box-title hands-on-title" id="hands-on-training-the-model"><i class="fas fa-pencil-alt" aria-hidden="true" ></i> Hands-on: Training the model</div>

  <ul>
    <li><span class="tool" data-tool="toolshed.g2.bx.psu.edu/repos/bgruening/keras_train_and_eval/keras_train_and_eval/1.0.10.0" title="Deep learning training and evaluation tool" aria-role="button"><i class="fas fa-wrench" aria-hidden="true"></i> <strong>Deep learning training and evaluation</strong> (<i class="fas fa-cubes" aria-hidden="true"></i> Galaxy version 1.0.10.0)</span>
      <ul>
        <li><em>“Select a scheme”</em>: <code class="language-plaintext highlighter-rouge">Train and Validate</code></li>
        <li><em>“Choose the dataset containing pipeline/estimator object”</em>: Select the <em>Keras Model Builder</em> from the previous step.</li>
        <li><em>“Select input type:”</em>: <code class="language-plaintext highlighter-rouge">tabular data</code>
          <ul>
            <li><em>“Training samples dataset”</em>: Select <code class="language-plaintext highlighter-rouge">X_train</code> dataset</li>
            <li><em>“Choose how to select data by column:”</em>: <code class="language-plaintext highlighter-rouge">All columns</code></li>
            <li><em>“Dataset containing class labels or target values”</em>: Select <code class="language-plaintext highlighter-rouge">y_train</code> dataset</li>
            <li><em>“Choose how to select data by column:”</em>: <code class="language-plaintext highlighter-rouge">All columns</code></li>
          </ul>
        </li>
        <li>Click <em>“Run Tool”</em></li>
      </ul>
    </li>
  </ul>

</blockquote>

<p>The training step generates 2 datasets. 1) accuracy of the trained model, 2) the trained model, in <em>h5mlm</em> format. These files are needed for prediction in the next step.</p>

<h2 id="model-prediction">Model Prediction</h2>

<blockquote class="notranslate hands_on">
  <div class="box-title hands-on-title" id="hands-on-testing-the-model"><i class="fas fa-pencil-alt" aria-hidden="true" ></i> Hands-on: Testing the model</div>

  <ul>
    <li><span class="tool" data-tool="toolshed.g2.bx.psu.edu/repos/bgruening/model_prediction/model_prediction/1.0.10.0" title="Model Prediction tool" aria-role="button"><i class="fas fa-wrench" aria-hidden="true"></i> <strong>Model Prediction</strong> (<i class="fas fa-cubes" aria-hidden="true"></i> Galaxy version 1.0.10.0)</span>
      <ul>
        <li><em>“Choose the dataset containing pipeline/estimator object”</em> : Select the trained model from the previous step.</li>
        <li><em>“Select invocation method”</em>: <code class="language-plaintext highlighter-rouge">predict</code></li>
        <li><em>“Select input data type for prediction”</em>: <code class="language-plaintext highlighter-rouge">tabular data</code></li>
        <li><em>“Training samples dataset”</em>: Select <code class="language-plaintext highlighter-rouge">X_test</code> dataset</li>
        <li><em>“Choose how to select data by column:”</em>: <code class="language-plaintext highlighter-rouge">All columns</code></li>
        <li>Click <em>“Run Tool”</em></li>
      </ul>
    </li>
  </ul>

</blockquote>

<p>The prediction step generates 1 dataset. It’s a file that has predictions (1 or 0 for positive or negative movie reviews) for every review in
the test dataset.</p>

<h2 id="machine-learning-visualization-extension">Machine Learning Visualization Extension</h2>

<blockquote class="notranslate hands_on">
  <div class="box-title hands-on-title" id="hands-on-creating-the-confusion-matrix"><i class="fas fa-pencil-alt" aria-hidden="true" ></i> Hands-on: Creating the confusion matrix</div>

  <ul>
    <li><span class="tool" data-tool="toolshed.g2.bx.psu.edu/repos/bgruening/ml_visualization_ex/ml_visualization_ex/1.0.10.0" title="Machine Learning Visualization Extension tool" aria-role="button"><i class="fas fa-wrench" aria-hidden="true"></i> <strong>Machine Learning Visualization Extension</strong> (<i class="fas fa-cubes" aria-hidden="true"></i> Galaxy version 1.0.10.0)</span>
      <ul>
        <li><em>“Select a plotting type”</em>: <code class="language-plaintext highlighter-rouge">Confusion matrix for classes</code></li>
        <li><em>“Select dataset containing the true labels”</em>”: <code class="language-plaintext highlighter-rouge">y_test</code></li>
        <li><em>“Choose how to select data by column:”</em>: <code class="language-plaintext highlighter-rouge">All columns</code></li>
        <li><em>“Select dataset containing the predicted labels”</em>”: Select <code class="language-plaintext highlighter-rouge">Model Prediction</code> from the previous step</li>
        <li><em>“Does the dataset contain header:”</em>: <code class="language-plaintext highlighter-rouge">Yes</code></li>
        <li>Click <em>“Run Tool”</em></li>
      </ul>
    </li>
  </ul>

</blockquote>

<p><strong>Confusion Matrix</strong> is a table that describes the performance of a classification model. It lists the number of positive and negative examples
that were correctly classified by the model, true positives (TP) and true negatives (TN), respectively. It also lists the number of examples that
were classified as positive that were actually negative (false positive, FP, or type I error), and the number of examples that were classified
as negative that were actually positive (false negative, FN, or type 2 error). Given the confusion matrix, we can calculate <strong>precision</strong> and
<strong>recall</strong> <span class="citation"><a href="#TatbulEtAl">Tatbul <i>et al.</i> 2018</a></span>. Precision is the fraction of predicted positives that are true positives (precision = TP / (TP + FP)). Recall
is the fraction of true positives that are predicted (recall = TP / (TP + FN)). One way to describe the confusion matrix with just one value is
to use the <strong>F score</strong>, which is the harmonic mean of precision and recall.</p>

\[Precision = \frac{\text{True positives}}{\text{True positives + False positives}}\]

\[Recall = \frac{\text{True positives}}{\text{True positives + False negatives}}\]

\[F score = \frac{2 * \text{Precision * Recall}}{\text{Precision + Recall}}\]

<figure id="figure-12" style="max-width: 90%;"><img src="../../images/ConfusionMatrix.png" alt="Confusion matrix for our sentiment analysis problem. " width="890" height="902" loading="lazy" /><a target="_blank" href="../../images/ConfusionMatrix.png" rel="noopener noreferrer"><small>Open image in new tab</small></a><br /><br /><figcaption><span class="figcaption-prefix"><strong>Figure 12</strong>:</span> Sentiment analysis confusion matrix</figcaption></figure>

<p>Figure 12 is the resultant confusion matrix for our sentiment analysis problem (note that your numbers in the matrix may differ, and that is expected). The top row in the figure represents the <em>true</em> 0 (or negative sentiment)
class labels (we have 10,397 + 2,103 = 12,500 reviews with negative sentiment). The bottom row represents the <em>true</em> 1 (or positive sentiment) class labels
(Again, we have 1,281 + 11,219 = 12,500 reviews with positive sentiment). The left column represents the <em>predicted</em> negative sentiment class labels (Our RNN
predicted 10,397 + 1,281 = 11,678 reviews as having a negative sentiment). The right column represents the <em>predicted</em> positive class labels (Our RNN
predicted 11,219 + 2,103 = 13,322 reviews as having a positive sentiment).Looking at the bottom right cell, we see that our RNN has correctly predicted 11,219
reviews as having a positive sentiment (true positives). Looking at the top right cell, we see that our RNN has incorrectly predicted 2,103 reviews as having
a positive (false positives). Similarly, looking at the top left cell, we see that our RNN has correctly predicted 10,397 reviews as having negative sentiment
(true negative). Finally, looking at the bottom left cell, we see that our RNN has incorrectly predicted 1,281 reviews as negative (false negative). Given
these numbers we can calculate Precision, Recall, and the F score as follows:</p>

\[Precision = \frac{\text{True positives}}{\text{True positives + False positives}} = \frac{11,219}{11,219 + 2,102} = 0.84\]

\[Recall = \frac{\text{True positives}}{\text{True positives + False negatives}} = \frac{11,219}{11,219 + 1,281} = 0.89\]

\[F score = \frac{2 * \text{Precision * Recall}}{\text{Precision + Recall}} = \frac{2 * 0.84 * 0.89}{0.84 + 0.89} = 0.86\]

<h1 id="conclusion">Conclusion</h1>

<p>In this tutorial, we briefly reviewed feedforward neural networks, explained how recurrent neural networks are different, and discussed various
RNN input/outputs and architectures. We also discussed various text representation and preprocessing schemes and used Galaxy to solve a sentiment
classification problem using RNN on IMDB movie reviews dataset.</p>

                </section>

                <section aria-label="Tutorial Footer, Feedback, Citation" id="tutorial-footer">
                        <h3>You've Finished the Tutorial</h3>
                        <button id="tutorial-finish-button" class="btn btn-primary" onclick="tutorial_finish()">I finished this tutorial 👍</button>
                        <p style="display: none" id="tutorial-finish-text">Please also consider filling out the <a href="#gtn-feedback">Feedback Form</a> as well!</p>
                        <script>
                        function tutorial_finish() {
                          if(typeof plausible !== 'undefined'){
                            // Plausible may be undefined (script blocked)
                            // or it may be defined, but opted-out (select box/DNT),
                            // which means `plausible()` will work but not send data, *nor* execute the callback.
                            plausible('TutorialComplete', {props: {path: document.location.pathname}})
                          }
                          // since the callback is completely cosmetic, we'll just issue it optimistically.
                          tutorial_finish_finish();
                        }
                        function tutorial_finish_finish() {
                          document.getElementById("tutorial-finish-button").innerText = 'Congrats! Thanks for letting us know! 🎉'
                          document.getElementById("tutorial-finish-button").disabled = true
                          document.getElementById("tutorial-finish-button").disabled = true
                          document.getElementById("tutorial-finish-text").style.display = 'block'
                        }
                        </script>

                

                <h1>Frequently Asked Questions</h1>
                Have questions about this tutorial? Check out the <a href="faqs/">tutorial FAQ page</a> or the  <a href="/training-material/topics/statistics/faqs/">FAQ page for the Statistics and machine learning topic</a> to see if your question is listed there.
                If not, please ask your question on the <a href="https://gitter.im/Galaxy-Training-Network/Lobby">GTN Gitter Channel</a> or the
                <a href="https://help.galaxyproject.org">Galaxy Help Forum</a>

                

                


                
                <h1 id="bibliography">References</h1>
                <ol class="bibliography"><li id="Newell780">Newell, A., 1969 <b>Perceptrons. An Introduction to Computational Geometry. Marvin Minsky and Seymour Papert. M.I.T. Press, Cambridge, Mass., 1969. vi + 258 pp., illus. Cloth, 12; paper, 4.95</b>. Science 165: 780–782. <a href="https://doi.org/10.1126/science.165.3895.780">10.1126/science.165.3895.780</a> <a href="https://science.sciencemag.org/content/165/3895/780">https://science.sciencemag.org/content/165/3895/780</a></li>
<li id="Rumelhart1986">Rumelhart, D. E., G. E. Hinton, and R. J. Williams, 1986 <b>Learning representations by back-propagating errors</b>. Nature 323: 533–536. <a href="https://doi.org/10.1038/323533a0">10.1038/323533a0</a></li>
<li id="Cybenko1989">Cybenko, G., 1989 <b>Approximation by superpositions of a sigmoidal function</b>. Mathematics of Control, Signals and Systems 2: 303–314. <a href="https://doi.org/10.1007/BF02551274">10.1007/BF02551274</a></li>
<li id="hochreiter1997long">Hochreiter, S., and J. Schmidhuber, 1997 <b>Long short-term memory</b>. Neural computation 9: 1735–1780.</li>
<li id="maas-EtAl">Maas, A. L., R. E. Daly, P. T. Pham, D. Huang, A. Y. Ng <i>et al.</i>, 2011 <b>Learning Word Vectors for Sentiment Analysis</b>. Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies 142–150. <a href="http://www.aclweb.org/anthology/P11-1015">http://www.aclweb.org/anthology/P11-1015</a></li>
<li id="cho-etal-2014-learning">Cho, K., B. van Merriënboer, C. Gulcehre, D. Bahdanau, F. Bougares <i>et al.</i>, 2014 <b>Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation</b>. Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) 1724–1734. <a href="https://doi.org/10.3115/v1/D14-1179">10.3115/v1/D14-1179</a> <a href="https://www.aclweb.org/anthology/D14-1179">https://www.aclweb.org/anthology/D14-1179</a></li>
<li id="wen-etal-2015-semantically">Wen, T.-H., M. Gasic, N. Mrksic, P.-hao Su, D. Vandyke <i>et al.</i>, 2015 <b>Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems</b>. Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing 1711–1721. <a href="https://doi.org/10.18653/v1/D15-1199">10.18653/v1/D15-1199</a> <a href="https://www.aclweb.org/anthology/D15-1199">https://www.aclweb.org/anthology/D15-1199</a></li>
<li id="LimEtAl">Lim, W., D. Jang, and T. Lee, 2016 <b>Speech emotion recognition using convolutional and Recurrent Neural Networks</b>. 2016 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA) 1–4. <a href="https://doi.org/10.1109/APSIPA.2016.7820699">10.1109/APSIPA.2016.7820699</a></li>
<li id="karpathyEtAl">Karpathy, A., and L. Fei-Fei, 2017 <b>Deep Visual-Semantic Alignments for Generating Image Descriptions</b>. IEEE Transactions on Pattern Analysis and Machine Intelligence 39: 664–676. <a href="https://doi.org/10.1109/TPAMI.2016.2598339">10.1109/TPAMI.2016.2598339</a></li>
<li id="li-etal-2017-deep">Li, P., W. Lam, L. Bing, and Z. Wang, 2017 <b>Deep Recurrent Generative Decoder for Abstractive Text Summarization</b>. Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing 2091–2100. <a href="https://doi.org/10.18653/v1/D17-1222">10.18653/v1/D17-1222</a> <a href="https://www.aclweb.org/anthology/D17-1222">https://www.aclweb.org/anthology/D17-1222</a></li>
<li id="nwankpaEtAl">Nwankpa, C., W. Ijomah, A. Gachagan, and S. Marshall, 2018 <b>Activation Functions: Comparison of trends in Practice and Research for Deep Learning</b>. CoRR abs/1811.03378: <a href="http://arxiv.org/abs/1811.03378">http://arxiv.org/abs/1811.03378</a></li>
<li id="TatbulEtAl">Tatbul, N., T. J. Lee, S. Zdonik, M. Alam, and J. Gottschlich, 2018 <b>Precision and Recall for Time Series</b>. Advances in Neural Information Processing Systems 31: 1920–1930. <a href="https://proceedings.neurips.cc/paper/2018/file/8f468c873a32bb0619eaeb2050ba45d1-Paper.pdf">https://proceedings.neurips.cc/paper/2018/file/8f468c873a32bb0619eaeb2050ba45d1-Paper.pdf</a></li></ol>
                

                

                <h1 id="gtn-feedback">Feedback</h1>
                <p class="text-muted">Did you use this material as an instructor? Feel free to give us feedback on <a href="https://github.com/galaxyproject/training-material/issues/1452">how it went</a>.
                <br>Did you use this material as a learner or student? Click the form below to leave feedback.<i class="fas fa-hand-point-down"></i>
                </p>

                <iframe id="feedback-google" class="google-form" src="https://docs.google.com/forms/d/e/1FAIpQLSd4VZptFTQ03kHkMz0JyW9b6_S8geU5KjNE_tLM0dixT3ZQmA/viewform?embedded=true&entry.1235803833=statistics/RNN"><a href="https://docs.google.com/forms/d/e/1FAIpQLSd4VZptFTQ03kHkMz0JyW9b6_S8geU5KjNE_tLM0dixT3ZQmA/viewform?embedded=true&entry.1235803833=statistics/RNN">Feedback Form</a></iframe>

                <h1>Citing this Tutorial</h1>
                <p>
                    <ol>
                        <li id="citation-text">
                            Kaivan Kamali,  <b>Deep Learning (Part 2) - Recurrent neural networks (RNN) (Galaxy Training Materials)</b>. <a href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/RNN/tutorial.html">https://training.galaxyproject.org/training-material/topics/statistics/tutorials/RNN/tutorial.html</a> Online; accessed TODAY
                        </li>
                        <li>
                        Hiltemann, Saskia, Rasche, Helena et al., 2023 <b>Galaxy Training: A Powerful Framework for Teaching!</b> PLOS Computational Biology <a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010752">10.1371/journal.pcbi.1010752</a>
                        </li>
                        <li>
                        Batut et al., 2018 <b>Community-Driven Data Analysis Training for Biology</b> Cell Systems <a href="https://doi.org/10.1016%2Fj.cels.2018.05.012">10.1016/j.cels.2018.05.012</a>
                        </li>
                    </ol>
                </p>

                <!-- collapsible boxcontaining the BibTeX-formatted citation -->
                <blockquote class="details">

                  <div id="citation-bibtex" class="box-title">
                    <button type="button" aria-controls="citation-bibtex" aria-expanded="false">
                      <i class="fas fa-info-circle" aria-hidden="true"></i>
                      <span class="visually-hidden"></span> BibTeX<span role="button" class="fold-unfold fa fa-minus-square" aria-hidden="true"></span>
                    </button>
                   </div>
                   <p style="display: none;">

                   <div class="highlighter-rouge"><div class="highlight"><pre class="highlight">


<code id="citation-code">@misc{statistics-RNN,
author = "Kaivan Kamali",
	title = "Deep Learning (Part 2) - Recurrent neural networks (RNN) (Galaxy Training Materials)",
	year = "",
	month = "",
	day = ""
	url = "\url{https://training.galaxyproject.org/training-material/topics/statistics/tutorials/RNN/tutorial.html}",
	note = "[Online; accessed TODAY]"
}
@article{Hiltemann_2023,
	doi = {10.1371/journal.pcbi.1010752},
	url = {https://doi.org/10.1371%2Fjournal.pcbi.1010752},
	year = 2023,
	month = {jan},
	publisher = {Public Library of Science ({PLoS})},
	volume = {19},
	number = {1},
	pages = {e1010752},
	author = {Saskia Hiltemann and Helena Rasche and Simon Gladman and Hans-Rudolf Hotz and Delphine Larivi{\`{e}}re and Daniel Blankenberg and Pratik D. Jagtap and Thomas Wollmann and Anthony Bretaudeau and Nadia Gou{\'{e}} and Timothy J. Griffin and Coline Royaux and Yvan Le Bras and Subina Mehta and Anna Syme and Frederik Coppens and Bert Droesbeke and Nicola Soranzo and Wendi Bacon and Fotis Psomopoulos and Crist{\'{o}}bal Gallardo-Alba and John Davis and Melanie Christine Föll and Matthias Fahrner and Maria A. Doyle and Beatriz Serrano-Solano and Anne Claire Fouilloux and Peter van Heusden and Wolfgang Maier and Dave Clements and Florian Heyl and Björn Grüning and B{\'{e}}r{\'{e}}nice Batut and},
	editor = {Francis Ouellette},
	title = {Galaxy Training: A powerful framework for teaching!},
	journal = {PLoS Comput Biol} Computational Biology}
}
</code>
                   </pre></div></div>
                   </p>
                </blockquote>

        


<script>
// update the date on load, or leave fallback of 'today'
const citationTodaysDate = new Date();
document.getElementById("citation-code").innerHTML = document.getElementById("citation-code").innerHTML.replace("TODAY", citationTodaysDate.toDateString());
document.getElementById("citation-text").innerHTML = document.getElementById("citation-text").innerHTML.replace("TODAY", citationTodaysDate.toDateString());
</script>

                <i class="far fa-thumbs-up" aria-hidden="true"></i> Congratulations on successfully completing this tutorial!

                

                
                <blockquote class="agenda follow-up">
                    <div class="box-title">Go Further</div>
                    <strong class="follow-up"><i class="fas fa-graduation-cap" aria-hidden="true"></i> Do you want to extend your knowledge? Follow one of our recommended follow-up trainings:</strong>
                    <ul>
                        
    
        
        
        
            
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                        
                            <li>
                              <a href="/training-material/topics/statistics/tutorials/CNN/slides.html"><i class="fab fa-slideshare" aria-hidden="true"></i><span class="visually-hidden">slides</span> Slides: Deep Learning (Part 3) - Convolutional neural networks (CNN)</a>
                            </li>
                        
                        
                            
                                <li>
                                  <a href="/training-material/topics/statistics/tutorials/CNN/tutorial.html"><i class="fas fa-laptop" aria-hidden="true"></i><span class="visually-hidden">tutorial</span> Hands-on: Deep Learning (Part 3) - Convolutional neural networks (CNN)</a>
                                </li>
                            
                        
                    
                
                    
                
                    
                
                    
                
            
        
    


                    </ul>
                </blockquote>
                

		
                <blockquote class="details follow-up" id="admins-install-missing-tools">
                  <div id="admin-missing-tools" class="box-title">
                    <button type="button" aria-controls="admin-missing-tools" aria-expanded="false">
                      <i class="fas fa-info-circle" aria-hidden="true"></i>
                      <span class="visually-hidden"></span> Galaxy Administrators: Install the missing tools<span role="button" class="fold-unfold fa fa-minus-square" aria-hidden="true"></span>
                    </button>
                   </div>


			<p>You can use Ephemeris's <code>shed-tools install</code> command to install the tools used in this tutorial.</p>
<div class="highlight"><pre class="highlight"><code>shed-tools install [-g GALAXY] [-a API_KEY] -t &lt;(curl https://training.galaxyproject.org/training-material/api/topics/statistics/tutorials/RNN/tutorial.json | jq .admin_install_yaml -r)</code></pre></div>
<p>Alternatively you can copy and paste the following YAML</p>
<div class="highlight"><pre class="highlight"><code>---
install_tool_dependencies: true
install_repository_dependencies: true
install_resolver_dependencies: true
tools:
- name: keras_model_builder
  owner: bgruening
  revisions: 66d7efc06000
  tool_panel_section_label: Machine Learning
  tool_shed_url: https://toolshed.g2.bx.psu.edu/
- name: keras_model_config
  owner: bgruening
  revisions: f22a9297440f
  tool_panel_section_label: Machine Learning
  tool_shed_url: https://toolshed.g2.bx.psu.edu/
- name: keras_train_and_eval
  owner: bgruening
  revisions: 818f9b69d8a0
  tool_panel_section_label: Machine Learning
  tool_shed_url: https://toolshed.g2.bx.psu.edu/
- name: ml_visualization_ex
  owner: bgruening
  revisions: 1588f9076e32
  tool_panel_section_label: Machine Learning
  tool_shed_url: https://toolshed.g2.bx.psu.edu/
- name: model_prediction
  owner: bgruening
  revisions: 9991c4ddde14
  tool_panel_section_label: Machine Learning
  tool_shed_url: https://toolshed.g2.bx.psu.edu/
</code></pre></div>
                </blockquote>
		

		<blockquote class="details hide-when-printing" id="feedback-responses">
                  <div id="feedback-response-c" class="box-title">
                    <button type="button" aria-controls="feedback-response-c" aria-expanded="false">
                      <i class="fas fa-info-circle" aria-hidden="true"></i>
                      <span class="visually-hidden"></span> Feedback<span role="button" class="fold-unfold fa fa-minus-square" aria-hidden="true"></span>
                    </button>
                   </div>

		   <p>
		   
		   <table class="charts-css bar show-labels" style="--labels-size: 8rem; overflow-y: hidden">
		   
			<tr>
				<th scope="row"><span class="sr-only">5 stars</span><i class="fa fa-star" aria-hidden="true"></i><i class="fa fa-star" aria-hidden="true"></i><i class="fa fa-star" aria-hidden="true"></i><i class="fa fa-star" aria-hidden="true"></i><i class="fa fa-star" aria-hidden="true"></i></th>
				<td style="--size: 1.0">1</td>
			</tr>
		   
			<tr>
				<th scope="row"><span class="sr-only">4 stars</span><i class="fa fa-star" aria-hidden="true"></i><i class="fa fa-star" aria-hidden="true"></i><i class="fa fa-star" aria-hidden="true"></i><i class="fa fa-star" aria-hidden="true"></i></th>
				<td style="--size: 1.0">1</td>
			</tr>
		   
		   </table>
		   </p>
		
        
        
		    
		    <b>July 2022</b>
		    <ul>
				
				<li>
					<span class="sr-only">4 stars</span><i class="fa fa-star" aria-hidden="true"></i><i class="fa fa-star" aria-hidden="true"></i><i class="fa fa-star" aria-hidden="true"></i><i class="fa fa-star" aria-hidden="true"></i>:
					<b>Liked</b>: The way of presentation to make the tutorial easily understandable.
					<b>Disliked</b>: More numerical examples could be added.
				</li>
				
		    </ul>
		    
		    <b>March 2022</b>
		    <ul>
				
				<li>
					<span class="sr-only">5 stars</span><i class="fa fa-star" aria-hidden="true"></i><i class="fa fa-star" aria-hidden="true"></i><i class="fa fa-star" aria-hidden="true"></i><i class="fa fa-star" aria-hidden="true"></i><i class="fa fa-star" aria-hidden="true"></i>:
					<b>Liked</b>: Simple and concise
					
				</li>
				
		    </ul>
		    
        
		</blockquote>




		
		
		

                </section>

            </div>
        </div>
    </div>
</article>
<br/>
<br/>
<br/>

        </div>
        <footer>
	<hr />
	<div class="container">
		<div class="row">
			<div class="col-sm-3">
				<span style="font-size: 2em">GTN</span>
				<p>
					The GTN provides learners with a free, open repository of online training
					materials, with a focus on hands-on training that aims to be directly applicable for learners.
					We aim to connect researchers and learners with local trainers, and events worldwide.
				</p>
				<p>
					We promote FAIR and Open Science practices worldwide, are committed to the accessibility of this platform and training for everyone.
				</p>
			</div>
			<div class="col-sm-3">
				<span style="font-size: 1.3em">About Us</span>
				<ul class="no-bullets">
					<li><a href="/training-material/about.html">About</a></li>
					<li><a rel="code-of-conduct" href="https://galaxyproject.org/community/coc/">Code of Conduct</a></li>
					<li><a href="/training-material/accessibility.html">Accessibility</a></li>
					<li><a href="/training-material/faqs/gtn/fair_training.html">100% FAIR Training</a></li>
					<li><a href="/training-material/faqs/gtn/collaborative_development.html">Collaborative Development</a></li>
				</ul>
				<span style="font-size: 1.3em">Page</span>
				<ul class="no-bullets">
					
					<li><i class="fas fa-fingerprint" aria-hidden="true"></i><span class="visually-hidden">purl</span><abbr title="Persistent URL">PURL</abbr>: <a href="https://gxy.io/GTN:T00259">gxy.io/GTN:T00259</a></li>
					

					

					<li>
						<a rel="license" href="https://spdx.org/licenses/CC-BY-4.0">
							Content licensed under Creative Commons Attribution 4.0 International License
						</a>
					</li>
					<li>
						<a href="https://github.com/galaxyproject/training-material/edit/main/topics/statistics/tutorials/RNN/tutorial.md">
						<i class="fab fa-github" aria-hidden="true"></i><span class="visually-hidden">github</span> Edit on GitHub
						</a>
					</li>
					<li>
						<a href="https://github.com/galaxyproject/training-material/commits/main/topics/statistics/tutorials/RNN/tutorial.md">
						<i class="fab fa-github" aria-hidden="true"></i><span class="visually-hidden">github</span> View Changes on GitHub
						</a>
					</li>
				</ul>
			</div>
			<div class="col-sm-3">
				<span style="font-size: 1.3em">Support</span>
				<ul class="no-bullets">
					<li><a rel="me" href="/training-material/faqs/galaxy/">Galaxy FAQs</a></li>
					<li><a rel="me" href="https://help.galaxyproject.org">Galaxy Help Forum</a></li>
					<li><a rel="me" href="http://gxy.io/gtn-slack">GTN Slack Chat</a></li>
					<li><a rel="me" href="https://matrix.to/#/%23Galaxy-Training-Network_Lobby%3Agitter.im">GTN Matrix Chat</a></li>
					<li><a rel="me" href="https://matrix.to/#/#galaxyproject_Lobby:gitter.im">Galaxy Matrix Chat</a></li>
				</ul>
				<span style="font-size: 1.3em">Framework</span>
				<ul class="no-bullets">
					<li>Revision <a href="https://github.com/galaxyproject/training-material/commit/5f9c6d1af07b03871570c2addd54488777a85eec">5f9c6d1</a></li>
					<li><a rel="license" href="https://github.com/galaxyproject/training-material/blob/main/LICENSE.md">MIT</a> Licensed</li>
					<li><a href="https://jekyllrb.com/">Jekyll(4.3.2 | production)</a></li>
				</ul>
			</div>
			<div class="col-sm-3">
				<span style="font-size: 1.3em">Follow Us!</span>
				<ul class="no-bullets">
					<li><span style="fill: var(--hyperlink);"><svg   width="1em"   height="1em"   viewBox="0 0 8.4937906 9.1084023"   version="1.1"   id="svg356"   xmlns="http://www.w3.org/2000/svg"   xmlns:svg="http://www.w3.org/2000/svg">  <g     id="layer1"     transform="translate(-70.566217,-144.26757)">    <path       style="fill-opacity:1;stroke:none;stroke-width:0.0179182"       d="m 76.39081,152.24155 c -0.737138,0.20763 -1.554999,0.29101 -2.311453,0.14333 -0.475335,-0.0928 -0.891898,-0.32923 -1.031589,-0.82423 -0.04356,-0.15434 -0.06132,-0.32388 -0.06142,-0.48378 0.353724,0.0457 0.702251,0.1304 1.057176,0.17407 0.701338,0.0864 1.394702,0.0784 2.096434,0.008 0.744056,-0.0745 1.433711,-0.21546 2.060598,-0.64854 0.243974,-0.16855 0.474672,-0.39133 0.603487,-0.66252 0.181421,-0.38195 0.175886,-0.89336 0.204447,-1.30803 0.0923,-1.34029 0.20588,-2.98599 -1.076708,-3.846 -0.499561,-0.33497 -1.208891,-0.39913 -1.791824,-0.45742 -0.987026,-0.0987 -1.971078,-0.0946 -2.956509,0.0338 -0.841146,0.10961 -1.595223,0.31468 -2.1065,1.0443 -0.493296,0.70396 -0.509564,1.52563 -0.509564,2.34729 0,1.37831 -0.05534,2.87744 0.595934,4.13911 0.504703,0.97774 1.498709,1.29589 2.52184,1.41832 0.473239,0.0566 0.96049,0.0849 1.434158,0.0172 0.328853,-0.0471 0.650325,-0.0999 0.966886,-0.20511 0.08957,-0.0298 0.266911,-0.0614 0.322027,-0.14486 0.04089,-0.0618 0.0099,-0.15812 0.0035,-0.22545 -0.01611,-0.16924 -0.02094,-0.34967 -0.02096,-0.51963 m -1.594723,-5.48298 c 0.214822,-0.25951 0.315898,-0.56088 0.60922,-0.75705 0.687899,-0.46006 1.692038,-0.11202 1.992096,0.63161 0.214571,0.5317 0.140174,1.15913 0.140174,1.72017 v 1.03925 c 0,0.0911 0.04009,0.30954 -0.01842,0.38339 -0.04193,0.053 -0.173018,0.0287 -0.232436,0.0287 h -0.698809 v -1.88142 c 0,-0.28413 0.04813,-0.63823 -0.09912,-0.89591 -0.234746,-0.4108 -0.875019,-0.36105 -1.092116,0.0358 -0.123368,0.22555 -0.116792,0.50369 -0.116792,0.75257 v 1.0751 h -0.931726 v -1.05718 c 0,-0.2555 0.0024,-0.53932 -0.121773,-0.77049 -0.21432,-0.39919 -0.857782,-0.44403 -1.090217,-0.0358 -0.147324,0.25871 -0.09604,0.61056 -0.09604,0.89591 v 1.88142 H 72.09042 v -1.98893 c 0,-0.4711 -0.01604,-0.95902 0.233201,-1.3797 0.585269,-0.98786 2.133584,-0.74836 2.472454,0.32253 z"       id="path2318" />  </g></svg></span> <a rel="me" href="https://mstdn.science/@gtn">Mastodon</a></li>
					<li><span style="fill: var(--hyperlink);"><svg  viewBox="0 0 64 57" width="1em" ><path style="fill-opacity:1;stroke:none;stroke-width:0.0179182" d="M13.873 3.805C21.21 9.332 29.103 20.537 32 26.55v15.882c0-.338-.13.044-.41.867-1.512 4.456-7.418 21.847-20.923 7.944-7.111-7.32-3.819-14.64 9.125-16.85-7.405 1.264-15.73-.825-18.014-9.015C1.12 23.022 0 8.51 0 6.55 0-3.268 8.579-.182 13.873 3.805ZM50.127 3.805C42.79 9.332 34.897 20.537 32 26.55v15.882c0-.338.13.044.41.867 1.512 4.456 7.418 21.847 20.923 7.944 7.111-7.32 3.819-14.64-9.125-16.85 7.405 1.264 15.73-.825 18.014-9.015C62.88 23.022 64 8.51 64 6.55c0-9.818-8.578-6.732-13.873-2.745Z"></path></svg></span><a rel="me" href="https://bsky.app/profile/galaxytraining.bsky.social"> Bluesky</a></li>
				</ul>

				<span style="font-size: 1.3em">Publications</span>
				<ul class="no-bullets">
					<li><a href="https://doi.org/10.1371/journal.pcbi.1010752">Hiltemann et al. 2023</a></li>
					<li><a href="https://doi.org/10.1016/j.cels.2018.05.012"> Batut et al. 2018</a></li>
					<li><a href="/training-material/faqs/gtn/gtn_citing.html">Citing Us</a></li>
				</ul>
			</div>
		</div>
	</div>
</footer>


        <script  async defer src='/training-material/assets/js/bundle.main.40d4e218.js'></script>

	
	<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
	
	

    </body>
</html>