<!DOCTYPE html>
<html lang="en" dir="auto">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Slides: Convolutional neural networks (CNN) 
 Deep Learning - Part 3 / Deep Learning (Part 3) - Convolutional neural networks (CNN) / Statistics and machine learning</title>
        
            <meta name="google-site-verification" content="9mOXn2JL833-i7-aioCCEuIdG4_tb6qjwUozB5GJnPQ" />

<!-- JavaScript Error Monitoring, and performance tracking. -->
<script
  src="https://browser.sentry-cdn.com/7.52.1/bundle.tracing.min.js"
  integrity="sha384-muuFXKS3752PNA4rPm9Uq6BLvOfV4CXyr9MHDBPvozOJJUWLKkogEFWOIRoVps43"
  crossorigin="anonymous"
></script>
<script type="text/javascript">
if(localStorage.getItem('sentry-opt-out') !== 'opt-out' && navigator.doNotTrack !== "1") {
	console.log("Sentry: opt-in");
	Sentry.init({
		dsn: "https://45e0ec6e4373462b92969505df37cf40@sentry.galaxyproject.org/10",
		release: "galaxy-training-network@6853b1bc36f26630048d6fa1c8f68724c98fb09f",
		integrations: [new Sentry.BrowserTracing(), new Sentry.Replay()],
		sampleRate: 0.1,
		tracesSampleRate: 0.1,
		// Capture Replay for no sessions by default
		replaysSessionSampleRate: 0.01,
		// plus for 1% of sessions with an error
		replaysOnErrorSampleRate: 0.01,
		// PII OFF
		sendDefaultPii: false, // Off by default but just in case.
		environment: "production",
	});
}
</script>

<!-- Page view tracking -->
<script defer data-domain="training.galaxyproject.org" src="https://plausible.galaxyproject.eu/js/plausible.js"></script>
<script>
if(localStorage.getItem('plausible-opt-out') !== 'opt-out' && navigator.doNotTrack !== "1") {
	localStorage.removeItem("plausible_ignore")
	console.log("Plausible: opt-in");
	window.plausible = window.plausible || function() { (window.plausible.q = window.plausible.q || []).push(arguments) }
} else {
	// if they're opting-out, or DNT
	// we might get one page by accident but we won't get future ones.
	localStorage.setItem("plausible_ignore", "true")
}
</script>

        
        <link rel="shortcut icon" href="/training-material/favicon.ico" type="image/x-icon">
        <link rel="alternate" type="application/atom+xml" href="/training-material/feed.xml">
        <link rel="canonical" href="https://training.galaxyproject.org/training-material/topics/statistics/tutorials/CNN/slides-plain.html">
        <link rel="license" href="https://spdx.org/licenses/CC-BY-4.0">
        <link rel="preload" href="/training-material/assets/fonts/AtkinsonHyperlegible/Atkinson-Hyperlegible-Regular-102a.woff2" as="font" type="font/woff2" crossorigin>
        <link rel="preload" href="/training-material/assets/fonts/AtkinsonHyperlegible/Atkinson-Hyperlegible-Bold-102a.woff2" as="font" type="font/woff2" crossorigin>
        <link rel="preload" href="/training-material/assets/fonts/AtkinsonHyperlegible/Atkinson-Hyperlegible-Italic-102a.woff2" as="font" type="font/woff2" crossorigin>
        
        <link rel="preload" href="/training-material/assets/css/main.css?v=3" as="style">
        <link rel='preload' href='/training-material/assets/js/bundle.theme.f1f2de89.js' as='script'>
<link rel='preload' href='/training-material/assets/js/bundle.main.40d4e218.js' as='script'>
        <link rel="stylesheet" href="/training-material/assets/css/main.css?v=3">
        <link rel="manifest" href="/training-material/manifest.json">
        <meta name="theme-color" content="#2c3143"/>
	

        <meta name="DC.identifier" content="https://github.com/galaxyproject/training-material">
<meta name="DC.type" content="text">
<meta name="DC.title" content="Convolutional neural networks (CNN) 
 Deep Learning - Part 3">
<meta name="DC.publisher" content="Galaxy Training Network">
<meta name="DC.date" content="2022-06-02 15:39:49 +0000">
<meta name="DC.creator" content="Kaivan Kamali"><meta name="description" content="# What is a convolutional neural network (CNN)?  ???  What is a convolutional neural network (CNN)?  ---  # Convolutional Neural Network (CNN)  - Increasing popularity of social media in past decade  - Image and video processing tasks have become very important - FNN could not scale up to image and video processing tasks - CNN specifically tailored for image and video processing tasks  ---  # Feedforward neural networks (FNN)  - In FNN all nodes in a layer connected to all nodes in next layer  - Each connection has a weight, must be learned by learning algorithm  ![Neurons forming the input, output, and hidden layers of a multi-layer feedforward neural network]({{site.baseurl}}/topics/statistics/images/FFNN.png)   ---  # Limitations of FNN  - If input is 64 pixel by 64 pixel grayscale image  - Each grayscale pixel represented by 1 value, usually between 0 to 255  - Where 0 is black, 255 is white, and values in between are shades of gray - Since each grayscale pixel represented by 1 ...">
        <meta property="og:site_name" content="Galaxy Training Network">
	<meta property="og:title" content="Statistics and machine learning / Deep Learning (Part 3) - Convolutional neural networks (CNN) / Slides: Convolutional neural networks (CNN) 
 Deep Learning - Part 3">
        <meta property="og:description" content="# What is a convolutional neural network (CNN)?  ???  What is a convolutional neural network (CNN)?  ---  # Convolutional Neural Network (CNN)  - Increasing popularity of social media in past decade  - Image and video processing tasks have become very important - FNN could not scale up to image and video processing tasks - CNN specifically tailored for image and video processing tasks  ---  # Feedforward neural networks (FNN)  - In FNN all nodes in a layer connected to all nodes in next layer  - Each connection has a weight, must be learned by learning algorithm  ![Neurons forming the input, output, and hidden layers of a multi-layer feedforward neural network]({{site.baseurl}}/topics/statistics/images/FFNN.png)   ---  # Limitations of FNN  - If input is 64 pixel by 64 pixel grayscale image  - Each grayscale pixel represented by 1 value, usually between 0 to 255  - Where 0 is black, 255 is white, and values in between are shades of gray - Since each grayscale pixel represented by 1 ...">
        <meta property="og:image" content="https://training.galaxyproject.org/training-material/assets/images/GTNLogo1000.png"></head>
    <body data-spy="scroll" data-target="#toc" data-brightness="auto" data-contrast="auto">
        <script  src='/training-material/assets/js/bundle.theme.f1f2de89.js'></script>
        <header>
    <nav class="navbar navbar-expand-md navbar-dark" aria-label="Site Navigation">
        <div class="container">
            <a class="navbar-brand" href="/training-material/">
                <img src="/training-material/assets/images/GTN-60px.png" height="30" alt="Galaxy Training Network logo">
                
                    Galaxy Training!
                
            </a>

            <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#top-navbar" aria-controls="top-navbar" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="top-navbar">
                <ul class="navbar-nav">
                    <li class="nav-item">
                        
			

                        
                    </li>

                    <li class="nav-item">
                        
                        <a class="nav-link" href="/training-material/learning-pathways" title="Learning Pathways">
                           <i class="fas fa-graduation-cap" aria-hidden="true"></i><span class="visually-hidden">curriculum</span> Learning Pathways
                        </a>
                        
                    </li>

                    <li class="nav-item dropdown">
    <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-expanded="false" title="Help">
        <i class="far fa-question-circle" aria-hidden="true"></i><span class="visually-hidden">help</span> Help
    </a>
    <div class="dropdown-menu dropdown-menu-right">
	<a class="dropdown-item" href="/training-material/faqs/index.html" title="Check our FAQs">
           <i class="far fa-question-circle" aria-hidden="true"></i><span class="visually-hidden">question</span> FAQs
        </a>
        
        <a class="dropdown-item" href="https://help.galaxyproject.org/" title="Discuss on Galaxy Help">
            <i class="far fa-comments" aria-hidden="true"></i><span class="visually-hidden">feedback</span> Galaxy Help Forum
        </a>
        <a class="dropdown-item" href="https://gitter.im/Galaxy-Training-Network/Lobby" title="Discuss on gitter">
           <i class="fab fa-gitter" aria-hidden="true"></i><span class="visually-hidden">gitter</span> Discuss on Matrix
        </a>
    </div>
</li>


                    <li class="nav-item dropdown">
    <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-expanded="false" title="Settings">
	<i class="fas fa-cog" aria-hidden="true"></i><span class="visually-hidden">galaxy-gear</span> Settings
    </a>
    <div class="dropdown-menu dropdown-menu-right">

	<h6 class="dropdown-header">Preferences</h6>

	<a href="/training-material/user/theme.html" class="dropdown-item">
		<i class="fas fa-palette" aria-hidden="true"></i><span class="visually-hidden">gtn-theme</span> Theme
	</a>

	<a href="/training-material/user/privacy.html" class="dropdown-item">
		<i class="fas fa-lock" aria-hidden="true"></i><span class="visually-hidden">pref-dataprivate</span> Data Privacy
	</a>

	<div class="dropdown-divider"></div>

	<h6 class="dropdown-header">For Everyone</h6>

        <a class="dropdown-item" href="https://github.com/galaxyproject/training-material/edit/main/./topics/statistics/tutorials/CNN/slides.html">
          <i class="fab fa-github" aria-hidden="true"></i><span class="visually-hidden">github</span> Propose a change or correction
        </a>

	<h6 class="dropdown-header">Instructor Utilities</h6>

        <a class="dropdown-item" href="/training-material/stats.html">
            <i class="fas fa-chart-column" aria-hidden="true"></i><span class="visually-hidden">galaxy-barchart</span> GTN statistics
        </a>

        <a class="dropdown-item" href="https://plausible.galaxyproject.eu/training.galaxyproject.org?period=12mo&page=/training-material/topics/statistics/tutorials/CNN/slides-plain.html">
            <i class="fas fa-chart-column" aria-hidden="true"></i><span class="visually-hidden">galaxy-barchart</span> Page View Metrics
        </a>

        <!-- link to feedback -->
        
            <a class="dropdown-item" href="/training-material/feedback.html">
                <i class="fas fa-chart-column" aria-hidden="true"></i><span class="visually-hidden">galaxy-barchart</span> GTN feedback
            </a>
        

        <div class="dropdown-item">
            <div>
                <i class="fas fa-history" aria-hidden="true"></i><span class="visually-hidden">galaxy-rulebuilder-history</span> Previous Versions
            </div>

            <div id="archive-selector">
            
                <a class="btn btn-warning" href="https://training.galaxyproject.org/archive/">Older Versions</a>
            </div>

        </div>

    </div>
</li>


                    <!-- Search bar-->
                    <li class="nav-item">
                      <div id="navbarSupportedContent" role="search">
                        <!-- Search form -->
                        <form class="form-inline mr-auto" method="GET" action="/training-material/search2">
                          <i class="fas fa-search nav-link" aria-hidden="true"></i>
                          <div class="md-form mb-2">
                            <input name="query" class="form-control nicer" type="text" placeholder="Search Tutorials" aria-label="Search">
                          </div>
                        </form>
                      </div>
                    </li>
                </ul>
            </div>
        </div>
    </nav>
</header>

        
        <div class="container main-content" role="main">
        <section class="tutorial">
	<a href="https://github.com/galaxyproject/training-material/blob/main//topics/statistics/tutorials/CNN/slides.html">View markdown source on GitHub</a>
	<h1>Convolutional neural networks (CNN) 
 Deep Learning - Part 3</h1>
		<h2>Contributors</h2>
<div markdown="0">

	<div class="contributors-line">
		
  <a href="/training-material/hall-of-fame/kxk302/" class="contributor-badge contributor-kxk302"><img src="https://avatars.githubusercontent.com/kxk302?s=36" alt="Kaivan Kamali avatar" width="36" class="avatar" />
    Kaivan Kamali</a>
  
	</div>

</div>


		
		<h2>Questions</h2>
		<ul>
		
		<li><p>What is a convolutional neural network (CNN)?</p>
</li>
		
		<li><p>What are some applications of CNN?</p>
</li>
		
		</ul>
		

		
		<h2>Objectives</h2>
		<ul>
		
		<li><p>Understand the inspiration behind CNN and learn the CNN architecture</p>
</li>
		
		<li><p>Learn the convolution operation and its parameters</p>
</li>
		
		<li><p>Learn how to create a CNN using Galaxy’s deep learning tools</p>
</li>
		
		<li><p>Solve an image classification problem on MNIST digit classification dataset using CNN in Galaxy</p>
</li>
		
		</ul>
		

		
		<h2>Requirements</h2>
		<ul>
		

		
    
        
        
        
            
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                        
                        
                            
                                <li>
                                  <a href="/training-material/topics/statistics/tutorials/intro_deep_learning/tutorial.html"><i class="fas fa-laptop" aria-hidden="true"></i><span class="visually-hidden">tutorial</span> Hands-on: Introduction to deep learning</a>
                                </li>
                            
                        
                    
                
                    
                
                    
                
                    
                
                    
                
            
                
                    
                
                    
                
                    
                
                    
                        
                            <li>
                              <a href="/training-material/topics/statistics/tutorials/FNN/slides.html"><i class="fab fa-slideshare" aria-hidden="true"></i><span class="visually-hidden">slides</span> Slides: Deep Learning (Part 1) - Feedforward neural networks (FNN)</a>
                            </li>
                        
                        
                            
                                <li>
                                  <a href="/training-material/topics/statistics/tutorials/FNN/tutorial.html"><i class="fas fa-laptop" aria-hidden="true"></i><span class="visually-hidden">tutorial</span> Hands-on: Deep Learning (Part 1) - Feedforward neural networks (FNN)</a>
                                </li>
                            
                        
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                        
                            <li>
                              <a href="/training-material/topics/statistics/tutorials/RNN/slides.html"><i class="fab fa-slideshare" aria-hidden="true"></i><span class="visually-hidden">slides</span> Slides: Deep Learning (Part 2) - Recurrent neural networks (RNN)</a>
                            </li>
                        
                        
                            
                                <li>
                                  <a href="/training-material/topics/statistics/tutorials/RNN/tutorial.html"><i class="fas fa-laptop" aria-hidden="true"></i><span class="visually-hidden">tutorial</span> Hands-on: Deep Learning (Part 2) - Recurrent neural networks (RNN)</a>
                                </li>
                            
                        
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            
        
    


		</ul>
		

		<div><strong> <i class="far fa-calendar" aria-hidden="true"></i><span class="visually-hidden">last_modification</span> Published:</strong> May 19, 2021 </div>
		<div><strong> <i class="far fa-calendar" aria-hidden="true"></i><span class="visually-hidden">last_modification</span> Last Updated:</strong> Jun 2, 2022 </div>

	<hr />


	<h1 id="what-is-a-convolutional-neural-network-cnn">What is a convolutional neural network (CNN)?</h1>

<p><span>Speaker Notes</span></p>

<p>What is a convolutional neural network (CNN)?</p>

<hr />

<h1 id="convolutional-neural-network-cnn">Convolutional Neural Network (CNN)</h1>

<ul>
  <li>Increasing popularity of social media in past decade
    <ul>
      <li>Image and video processing tasks have become very important</li>
    </ul>
  </li>
  <li>FNN could not scale up to image and video processing tasks</li>
  <li>CNN specifically tailored for image and video processing tasks</li>
</ul>

<hr />

<h1 id="feedforward-neural-networks-fnn">Feedforward neural networks (FNN)</h1>

<ul>
  <li>In FNN all nodes in a layer connected to all nodes in next layer
    <ul>
      <li>Each connection has a weight, must be learned by learning algorithm</li>
    </ul>
  </li>
</ul>

<p><img src="/training-material/topics/statistics/images/FFNN.png" alt="Neurons forming the input, output, and hidden layers of a multi-layer feedforward neural network" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="limitations-of-fnn">Limitations of FNN</h1>

<ul>
  <li>If input is 64 pixel by 64 pixel grayscale image
    <ul>
      <li>Each grayscale pixel represented by 1 value, usually between 0 to 255</li>
      <li>Where 0 is black, 255 is white, and values in between are shades of gray</li>
    </ul>
  </li>
  <li>Since each grayscale pixel represented by 1 value, we say <em>channel</em> size is 1</li>
  <li>Image represented by 64 x 64 x 1 = 4,096 values (rows x columns x channels)
    <ul>
      <li>Hence, input layer of FNN has 4096 nodes</li>
    </ul>
  </li>
  <li>Lets assume next layer has 500 nodes
    <ul>
      <li>Since FNN fully connected, we have 4,096 x 500 = 2,048,000 weights</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="limitations-of-fnn-1">Limitations of FNN</h1>

<ul>
  <li>For complex problems, we need multiple hidden layers in our FNN
    <ul>
      <li>Compunds the problem of having many weights</li>
    </ul>
  </li>
  <li>Having too many weights
    <ul>
      <li>Makes learning more difficult as dimension of search space is increased</li>
      <li>Makes training more time/resource consuming</li>
      <li>Increases the likelihood of overfitting</li>
    </ul>
  </li>
  <li>Problem is further compunded for color images
    <ul>
      <li>Each pixel in color image represented by 3 values (RGB color mode)</li>
      <li>Since each pixel represented by 3 values, we say <em>channel</em> size is 3</li>
      <li>Image represented by 64 x 64 x 3 = 12,288 values (rows x columns x channels)</li>
      <li>Number of weights is now 12,288 x 500 = 6,144,000</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="limitations-of-fnn-2">Limitations of FNN</h1>

<ul>
  <li>Clear that FNN cannot scale to larger images (Too many weights)</li>
  <li>Another problem with FNN
    <ul>
      <li>2D image represented as 1D vector in input layer</li>
      <li>Any spatial relationship in the data is ignored</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="inspiration-for-cnn">Inspiration for CNN</h1>

<ul>
  <li>In 1959 Hubel &amp; Wiesel did an experiment to understand how visual cortex of brain processes visual info
    <ul>
      <li>Recorded activity of neurons in visual cortex of a cat</li>
      <li>While moving a bright line in front of the cat</li>
    </ul>
  </li>
  <li>Some cells fired when bright line is shown at a particular angle/location
    <ul>
      <li>Called these <em>simple</em> cells</li>
    </ul>
  </li>
  <li>Other cells fired when bright line was shown regardless of angle/location
    <ul>
      <li>Seemed to detect movement</li>
      <li>Called these <em>complex</em> cells</li>
    </ul>
  </li>
  <li>Seemed complex cells receive inputs from multiple simple cells
    <ul>
      <li>Have an hierarchical structure</li>
    </ul>
  </li>
  <li>Hubel and Wiesel won Noble prize in 1981</li>
</ul>

<hr />

<h1 id="inspiration-for-cnn-1">Inspiration for CNN</h1>

<ul>
  <li>Inspired by complex/simple cells, Fukushima proposed <em>Neocognitron</em> (1980)
    <ul>
      <li>Hierarchical neural network used for handwritten Japanese character recognition</li>
      <li>First CNN, had its own training algorithm</li>
    </ul>
  </li>
  <li>In 1989, LeCun proposed CNN that was trained by backpropagation</li>
  <li>CNN got popular when outperformed other models at ImageNet Challenge
    <ul>
      <li>Competition in object classification/detection</li>
      <li>On hundreds of object categories and millions of images</li>
      <li>Run annually from 2010 to present</li>
    </ul>
  </li>
  <li>Notable CNN architectures that won ImageNet challenge
    <ul>
      <li>AlexNet (2012), ZFNet (2013), GoogLeNet &amp; VGG (2014), ResNet (2015)</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="architecture-of-cnn">Architecture of CNN</h1>

<ul>
  <li>A typical CNN has 4 layers
    <ul>
      <li>Input layer</li>
      <li>Convolution layer</li>
      <li>Pooling layer</li>
      <li>Fully connected layer</li>
    </ul>
  </li>
  <li>We will explain a 2D CNN here
    <ul>
      <li>Same concepts apply to a 1 (or 3) dimensional CNN</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="input-layer">Input layer</h1>

<ul>
  <li>Example input a 28 pixel by 28 pixel grayscale image</li>
  <li>Unlike FNN, we do not “flatten” the input to a 1D vector
    <ul>
      <li>Input is presented to network in 2D as 28 x 28 matrix</li>
      <li>This makes capturing spatial relationships easier</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="convolution-layer">Convolution layer</h1>

<ul>
  <li>Composed of multiple filters (kernels)</li>
  <li>Filters for 2D image are also 2D</li>
  <li>Suppose we have a 3 by 3 filter (9 values in total)
    <ul>
      <li>Values are randomly set to 0 or 1</li>
    </ul>
  </li>
  <li>Convolution: placing 3 by 3 filter on the top left corner of image
    <ul>
      <li>Multiply filter values by pixel values, add the results</li>
      <li>Move filter to right one pixel at a time, and repeat this process</li>
      <li>When at top right corner, move filter down one pixel and repeat process</li>
      <li>Process ends when we get to bottom right corner of image</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="3-by-3-filter">3 by 3 Filter</h1>

<p><img src="/training-material/topics/statistics/images/Conv_no_padding_no_strides.gif" alt="A 3 by 3 filter applied to a 4 by 4 image, resulting in a 2 by 2 image" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="convolution-operator-parameters">Convolution operator parameters</h1>

<ul>
  <li>Filter size</li>
  <li>Padding</li>
  <li>Stride</li>
  <li>Dilation</li>
  <li>Activation function</li>
</ul>

<hr />

<h1 id="filter-size">Filter size</h1>

<ul>
  <li>Filter size can be 5 by 5, 3 by 3, and so on</li>
  <li>Larger filter sizes should be avoided
    <ul>
      <li>As learning algorithm needs to learn filter values (weights)</li>
    </ul>
  </li>
  <li>Odd sized filters are preferred to even sized filters
    <ul>
      <li>Nice geometric property of all input pixels being around output pixel</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="padding">Padding</h1>

<ul>
  <li>After applying 3 by 3 filter to 4 by 4 image, we get a 2 by 2 image
  – Size of the image has gone down</li>
  <li>If we want to keep image size the same, we can use padding
    <ul>
      <li>We pad input in every direction with 0’s before applying filter</li>
      <li>If padding is 1 by 1, then we add 1 zero in evey direction</li>
      <li>If padding is 2 by 2, then we add 2 zeros in every direction, and so on</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="3-by-3-filter-with-padding-of-1">3 by 3 filter with padding of 1</h1>

<p><img src="/training-material/topics/statistics/images/Conv_same_padding_no_strides.gif" alt="A 3 by 3 filter applied to a 5 by 5 image, with padding of 1, resulting in a 5 by 5 image" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="stride">Stride</h1>

<ul>
  <li>How many pixels we move filter to the right/down is stride</li>
  <li>Stride 1: move filter one pixel to the right/down</li>
  <li>Stride 2: move filter two pixels to the right/down</li>
</ul>

<hr />

<h1 id="3-by-3-filter-with-stride-of-2">3 by 3 filter with stride of 2</h1>

<p><img src="/training-material/topics/statistics/images/Conv_no_padding_strides.gif" alt="A 3 by 3 filter applied to a 5 by 5 image, with stride of 2, resulting in a 2 by 2 image" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="dilation">Dilation</h1>

<ul>
  <li>When we apply 3 by 3 filter, output affected by pixels in 3 by 3 subset of image</li>
  <li>Dilation: To have a larger receptive field (portion of image affecting filter’s output)</li>
  <li>If dilation set to 2, instead of contiguous 3 by 3 subset of image, every other pixel of a 5 by 5 subset of image affects output</li>
</ul>

<hr />

<h1 id="3-by-3-filter-with-dilation-of-2">3 by 3 filter with dilation of 2</h1>

<p><img src="/training-material/topics/statistics/images/Conv_dilation.gif" alt="A 3 by 3 filter applied to a 7 by 7 image, with dilation of 2, resulting in a 3 by 3 image" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="activation-function">Activation function</h1>

<ul>
  <li>After filter applied to whole image, apply activation function to output to introduce non-linearlity</li>
  <li>Preferred activation function in CNN is ReLU</li>
  <li>ReLU leaves outputs with positive values as is, replaces negative values with 0</li>
</ul>

<hr />

<h1 id="relu-activation-function">Relu activation function</h1>

<p><img src="/training-material/topics/statistics/images/Conv_ReLU.png" alt="Two matrices representing filter output before and after ReLU activation function is applied" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="single-channel-2d-convolution">Single channel 2D convolution</h1>

<p><img src="/training-material/topics/statistics/images/Conv_single_input_channel.png" alt="One matrix representing an input vector and another matrix representing a filter, along with calculation for single input channel two dimensional convolution operation" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="triple-channel-2d-convolution">Triple channel 2D convolution</h1>

<p><img src="/training-material/topics/statistics/images/Conv_multiple_input_channel.png" alt="Three matrices representing an input vector and another three matrices representing a filter, along with calculation for multiple input channel two dimensional convolution operation" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="triple-channel-2d-convolution-in-3d">Triple channel 2D convolution in 3D</h1>

<p><img src="/training-material/topics/statistics/images/Conv_multiple_channel_3d.gif" alt="Multiple cubes representing input vector, filter, and output in a 3 channel 2 dimensional convolution operation" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="change-channel-size">Change channel size</h1>

<ul>
  <li>Output of a multi-channel 2D filter is a single channel 2D image</li>
  <li>Applying <em>multiple</em> filters results in a multi-channel 2D image</li>
  <li>E.g., if input image is 28 x 28 x 3 (rows x columns x channels)
    <ul>
      <li>We apply a 3 x 3 filter with 1 x 1 padding, we get a 28 x 28 x 1 image</li>
      <li>If we apply 15 such filters, we get a 28 x 28 x 15</li>
    </ul>
  </li>
  <li>Number of filters allows us to increase or decrease channel size</li>
</ul>

<hr />

<h1 id="pooling-layer">Pooling layer</h1>

<ul>
  <li>Pooling layer performs down sampling to reduce spatial dimensionality of input</li>
  <li>This decreases number of parameters
    <ul>
      <li>Reduces learning time/computation</li>
      <li>Reduces likelihood of overfitting</li>
    </ul>
  </li>
  <li>Most popular type is <em>max</em> pooling
    <ul>
      <li>Usually a 2 x 2 filter with a stride of 2</li>
      <li>Returns maximum value as it slides over input data</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="fully-connected-layer">Fully connected layer</h1>

<ul>
  <li>Last layer in a CNN</li>
  <li>Connect all nodes from previous layer to this fully connected layer
    <ul>
      <li>Which is responsible for classification of the image</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="an-example-cnn">An example CNN</h1>

<p><img src="/training-material/topics/statistics/images/Conv_CNN.png" alt="A convolutional neural network with 3 convolution layers followed by 3 pooling layers" /> <!-- https://pixy.org/3013900/ CC0 license--></p>

<hr />

<h1 id="an-example-cnn-1">An example CNN</h1>

<ul>
  <li>A typical CNN has several convolution plus pooling layers
    <ul>
      <li>Each responsible for feature extraction at different levels of abstraction</li>
      <li>E.g., filters in first layer detect horizontal, vertical, and diagonal edges</li>
      <li>Filters in the next layer detect shapes</li>
      <li>Filters in the last layer detect collection of shapes</li>
    </ul>
  </li>
  <li>Filter values randomly initialized, learned by learning algorithm</li>
  <li>CNN not only do classification, but can also automatically do feature extraction
    <ul>
      <li>Distinguishes CNN from other classification techniques (like Support Vector Machines)</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="mnist-dataset">MNIST dataset</h1>

<ul>
  <li>MNIST dataset of handwritten digits
    <ul>
      <li>Composed of training set of 60,000 and test set of 10,000 images</li>
    </ul>
  </li>
  <li>Digits have been size-normalized/centered in a fixed-size image (28 by 28 pixels)</li>
  <li>Images are grayscale
    <ul>
      <li>Each pixel is represented by a number between 0 and 255</li>
      <li>0 for black, 255 for white, and other values for shades of gray</li>
    </ul>
  </li>
  <li>MNIST dataset is a standard image classification dataset
    <ul>
      <li>
        <h2 id="used-to-compare-various-machine-learning-techniques">Used to compare various Machine Learning techniques</h2>
      </li>
    </ul>
  </li>
</ul>

<h1 id="classification-of-mnist-images-with-cnn">Classification of MNIST images with CNN</h1>

<ul>
  <li>We define a CNN and train it using MNIST dataset training data</li>
  <li>Goal is to learn a model such that given image of a digit we predict the digit (0 to 9)</li>
  <li>We then evaluate the trained CNN on test dataset and plot the confusion matrix</li>
</ul>

<hr />

<h1 id="for-references-please-see-tutorials-references-section">For references, please see tutorial’s References section</h1>

<hr />

<ul>
  <li>Galaxy Training Materials (<a href="https://training.galaxyproject.org">training.galaxyproject.org</a>)</li>
</ul>

<p><img src="/training-material/topics/introduction/images/gtn_stats.png" alt="Screenshot of the gtn stats page with 21 topics, 170 tutorials, 159 contributors, 16 scientific topics, and a growing community" /></p>

<p><span>Speaker Notes</span></p>

<ul>
  <li>If you would like to learn more about Galaxy, there are a large number of tutorials available.</li>
  <li>These tutorials cover a wide range of scientific domains.</li>
</ul>

<hr />

<h1 id="getting-help">Getting Help</h1>

<ul>
  <li>
    <p><strong>Help Forum</strong> (<a href="https://help.galaxyproject.org">help.galaxyproject.org</a>)</p>

    <p><img src="/training-material/topics/introduction/images/galaxy_help.png" alt="Galaxy Help" /></p>
  </li>
  <li>
    <p><strong>Gitter Chat</strong></p>
    <ul>
      <li><a href="https://gitter.im/galaxyproject/Lobby">Main Chat</a></li>
      <li><a href="https://gitter.im/Galaxy-Training-Network/Lobby">Galaxy Training Chat</a></li>
      <li>Many more channels (scientific domains, developers, admins)</li>
    </ul>
  </li>
</ul>

<p><span>Speaker Notes</span></p>

<ul>
  <li>If you get stuck, there are ways to get help.</li>
  <li>You can ask your questions on the help forum.</li>
  <li>Or you can chat with the community on Gitter.</li>
</ul>

<hr />

<h1 id="join-an-event">Join an event</h1>

<ul>
  <li>Many Galaxy events across the globe</li>
  <li>Event Horizon: <a href="https://galaxyproject.org/events">galaxyproject.org/events</a></li>
</ul>

<p><img src="/training-material/topics/introduction/images/event_horizon.png" alt="Event schedule" /></p>

<p><span>Speaker Notes</span></p>

<ul>
  <li>There are frequent Galaxy events all around the world.</li>
  <li>You can find upcoming events on the Galaxy Event Horizon.</li>
</ul>


	<hr />








<h2>Thank you!</h2>

This material is the result of a collaborative work. Thanks to the <a href="https://training.galaxyproject.org" aria-label="Visit the GTN">Galaxy Training Network</a> and all the contributors!


<img src="/training-material/assets/images/GTNLogo1000.png" alt="Galaxy Training Network" style="height: 100px;"/>


Tutorial Content is licensed under

  <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.

</section>






        </div>
        <footer>
	<hr />
	<div class="container">
		<div class="row">
			<div class="col-sm-3">
				<span style="font-size: 2em">GTN</span>
				<p>
					The GTN provides learners with a free, open repository of online training
					materials, with a focus on hands-on training that aims to be directly applicable for learners.
					We aim to connect researchers and learners with local trainers, and events worldwide.
				</p>
				<p>
					We promote FAIR and Open Science practices worldwide, are committed to the accessibility of this platform and training for everyone.
				</p>
			</div>
			<div class="col-sm-3">
				<span style="font-size: 1.3em">About Us</span>
				<ul class="no-bullets">
					<li><a href="/training-material/about.html">About</a></li>
					<li><a rel="code-of-conduct" href="https://galaxyproject.org/community/coc/">Code of Conduct</a></li>
					<li><a href="/training-material/accessibility.html">Accessibility</a></li>
					<li><a href="/training-material/faqs/gtn/fair_training.html">100% FAIR Training</a></li>
					<li><a href="/training-material/faqs/gtn/collaborative_development.html">Collaborative Development</a></li>
				</ul>
				<span style="font-size: 1.3em">Page</span>
				<ul class="no-bullets">
					

					

					<li>
						<a rel="license" href="https://spdx.org/licenses/CC-BY-4.0">
							Content licensed under Creative Commons Attribution 4.0 International License
						</a>
					</li>
					<li>
						<a href="https://github.com/galaxyproject/training-material/edit/main/./topics/statistics/tutorials/CNN/slides.html">
						<i class="fab fa-github" aria-hidden="true"></i><span class="visually-hidden">github</span> Edit on GitHub
						</a>
					</li>
					<li>
						<a href="https://github.com/galaxyproject/training-material/commits/main/./topics/statistics/tutorials/CNN/slides.html">
						<i class="fab fa-github" aria-hidden="true"></i><span class="visually-hidden">github</span> View Changes on GitHub
						</a>
					</li>
				</ul>
			</div>
			<div class="col-sm-3">
				<span style="font-size: 1.3em">Support</span>
				<ul class="no-bullets">
					<li><a rel="me" href="/training-material/faqs/galaxy/">Galaxy FAQs</a></li>
					<li><a rel="me" href="https://help.galaxyproject.org">Galaxy Help Forum</a></li>
					<li><a rel="me" href="http://gxy.io/gtn-slack">GTN Slack Chat</a></li>
					<li><a rel="me" href="https://matrix.to/#/%23Galaxy-Training-Network_Lobby%3Agitter.im">GTN Matrix Chat</a></li>
					<li><a rel="me" href="https://matrix.to/#/#galaxyproject_Lobby:gitter.im">Galaxy Matrix Chat</a></li>
				</ul>
				<span style="font-size: 1.3em">Framework</span>
				<ul class="no-bullets">
					<li>Revision <a href="https://github.com/galaxyproject/training-material/commit/6853b1bc36f26630048d6fa1c8f68724c98fb09f">6853b1b</a></li>
					<li><a rel="license" href="https://github.com/galaxyproject/training-material/blob/main/LICENSE.md">MIT</a> Licensed</li>
					<li><a href="https://jekyllrb.com/">Jekyll(4.3.2 | production)</a></li>
				</ul>
			</div>
			<div class="col-sm-3">
				<span style="font-size: 1.3em">Follow Us!</span>
				<ul class="no-bullets">
					<li><span style="fill: var(--hyperlink);"><svg   width="1em"   height="1em"   viewBox="0 0 8.4937906 9.1084023"   version="1.1"   id="svg356"   xmlns="http://www.w3.org/2000/svg"   xmlns:svg="http://www.w3.org/2000/svg">  <g     id="layer1"     transform="translate(-70.566217,-144.26757)">    <path       style="fill-opacity:1;stroke:none;stroke-width:0.0179182"       d="m 76.39081,152.24155 c -0.737138,0.20763 -1.554999,0.29101 -2.311453,0.14333 -0.475335,-0.0928 -0.891898,-0.32923 -1.031589,-0.82423 -0.04356,-0.15434 -0.06132,-0.32388 -0.06142,-0.48378 0.353724,0.0457 0.702251,0.1304 1.057176,0.17407 0.701338,0.0864 1.394702,0.0784 2.096434,0.008 0.744056,-0.0745 1.433711,-0.21546 2.060598,-0.64854 0.243974,-0.16855 0.474672,-0.39133 0.603487,-0.66252 0.181421,-0.38195 0.175886,-0.89336 0.204447,-1.30803 0.0923,-1.34029 0.20588,-2.98599 -1.076708,-3.846 -0.499561,-0.33497 -1.208891,-0.39913 -1.791824,-0.45742 -0.987026,-0.0987 -1.971078,-0.0946 -2.956509,0.0338 -0.841146,0.10961 -1.595223,0.31468 -2.1065,1.0443 -0.493296,0.70396 -0.509564,1.52563 -0.509564,2.34729 0,1.37831 -0.05534,2.87744 0.595934,4.13911 0.504703,0.97774 1.498709,1.29589 2.52184,1.41832 0.473239,0.0566 0.96049,0.0849 1.434158,0.0172 0.328853,-0.0471 0.650325,-0.0999 0.966886,-0.20511 0.08957,-0.0298 0.266911,-0.0614 0.322027,-0.14486 0.04089,-0.0618 0.0099,-0.15812 0.0035,-0.22545 -0.01611,-0.16924 -0.02094,-0.34967 -0.02096,-0.51963 m -1.594723,-5.48298 c 0.214822,-0.25951 0.315898,-0.56088 0.60922,-0.75705 0.687899,-0.46006 1.692038,-0.11202 1.992096,0.63161 0.214571,0.5317 0.140174,1.15913 0.140174,1.72017 v 1.03925 c 0,0.0911 0.04009,0.30954 -0.01842,0.38339 -0.04193,0.053 -0.173018,0.0287 -0.232436,0.0287 h -0.698809 v -1.88142 c 0,-0.28413 0.04813,-0.63823 -0.09912,-0.89591 -0.234746,-0.4108 -0.875019,-0.36105 -1.092116,0.0358 -0.123368,0.22555 -0.116792,0.50369 -0.116792,0.75257 v 1.0751 h -0.931726 v -1.05718 c 0,-0.2555 0.0024,-0.53932 -0.121773,-0.77049 -0.21432,-0.39919 -0.857782,-0.44403 -1.090217,-0.0358 -0.147324,0.25871 -0.09604,0.61056 -0.09604,0.89591 v 1.88142 H 72.09042 v -1.98893 c 0,-0.4711 -0.01604,-0.95902 0.233201,-1.3797 0.585269,-0.98786 2.133584,-0.74836 2.472454,0.32253 z"       id="path2318" />  </g></svg></span> <a rel="me" href="https://mstdn.science/@gtn">Mastodon</a></li>
					<li><span style="fill: var(--hyperlink);"><svg  viewBox="0 0 64 57" width="1em" ><path style="fill-opacity:1;stroke:none;stroke-width:0.0179182" d="M13.873 3.805C21.21 9.332 29.103 20.537 32 26.55v15.882c0-.338-.13.044-.41.867-1.512 4.456-7.418 21.847-20.923 7.944-7.111-7.32-3.819-14.64 9.125-16.85-7.405 1.264-15.73-.825-18.014-9.015C1.12 23.022 0 8.51 0 6.55 0-3.268 8.579-.182 13.873 3.805ZM50.127 3.805C42.79 9.332 34.897 20.537 32 26.55v15.882c0-.338.13.044.41.867 1.512 4.456 7.418 21.847 20.923 7.944 7.111-7.32 3.819-14.64-9.125-16.85 7.405 1.264 15.73-.825 18.014-9.015C62.88 23.022 64 8.51 64 6.55c0-9.818-8.578-6.732-13.873-2.745Z"></path></svg></span><a rel="me" href="https://bsky.app/profile/galaxytraining.bsky.social"> Bluesky</a></li>
				</ul>

				<span style="font-size: 1.3em">Publications</span>
				<ul class="no-bullets">
					<li><a href="https://doi.org/10.1371/journal.pcbi.1010752">Hiltemann et al. 2023</a></li>
					<li><a href="https://doi.org/10.1016/j.cels.2018.05.012"> Batut et al. 2018</a></li>
					<li><a href="/training-material/faqs/gtn/gtn_citing.html">Citing Us</a></li>
				</ul>
			</div>
		</div>
	</div>
</footer>


        <script  async defer src='/training-material/assets/js/bundle.main.40d4e218.js'></script>

	
	

    </body>
</html>
