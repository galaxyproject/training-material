<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <title>Introduction to deep learning</title>
        <link rel="stylesheet" href="/training-material/assets/css/bootstrap.min.css?v=3">
        <link rel="stylesheet" href="/training-material/assets/css/bootstrap-toc.min.css">
        <link rel="stylesheet" href="/training-material/assets/css/main.css?v=2">
        <script src="https://kit.fontawesome.com/67b3f98409.js" crossorigin="anonymous"></script>
        <link rel="stylesheet" href="/training-material/assets/css/academicons.css">
        <link rel="stylesheet" href="/training-material/assets/css/syntax_highlighting.css">
        <link rel="shortcut icon" href="/training-material/favicon.ico" type="image/x-icon" />

        
        
        
        
        
        <meta name="description" content="Statistical Analyses for omics data and machine learning ..." />
        <meta property="og:title" content="Galaxy Training: Introduction to deep learning" />
        <meta property="og:description" content="Statistical Analyses for omics data and machine learning ..." />
        <meta property="og:image" content="/training-material/assets/images/GTNLogo1000.png" />
    </head>
    <body data-spy="scroll" data-target="#toc">
        











<!-- Gitter -->


<script>
  ((window.gitter = {}).chat = {}).options = {
  room: 'Galaxy-Training-Network/Lobby'
  };
</script>
<script src="https://sidecar.gitter.im/dist/sidecar.v1.js" async defer></script>

<header>
    <nav class="navbar navbar-expand-lg navbar-dark">
        <div class="container">
            <a class="navbar-brand" href="/training-material/">
                <img src="/training-material/assets/images/GTN-60px.png" height="30" alt="Galaxy Training Network logo">
                Galaxy Training!
            </a>

            <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#top-navbar" aria-controls="top-navbar" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="top-navbar">
                <ul class="navbar-nav">
                    <li class="nav-item">
                        <a class="nav-link" href="/training-material/topics/statistics" title="Go back to list of tutorials">
                            <i class="far fa-folder" aria-hidden="true"></i><span class="visually-hidden">topic</span> Statistics and machine learning
                        </a>
                    </li>

                    <li class="nav-item dropdown">
                        <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-expanded="false" title="Language Selector">
                            <i class="fas fa-language" aria-hidden="true"></i><span class="visually-hidden">language</span> Language
                        </a>
                        <div class="dropdown-menu">
                            
                            <a class="dropdown-item" href="https://translate.google.com/translate?hl=jp&sl=en&tl=fr&u=https%3A%2F%2Ftraining.galaxyproject.org%2Ftopics%2Fstatistics%2Ftutorials%2Fintro_deep_learning%2Ftutorial.html&edit-text=&act=url" title="">
                                Fran√ßais
                            </a>
                            
                            <a class="dropdown-item" href="https://translate.google.com/translate?hl=jp&sl=en&tl=ja&u=https%3A%2F%2Ftraining.galaxyproject.org%2Ftopics%2Fstatistics%2Ftutorials%2Fintro_deep_learning%2Ftutorial.html&edit-text=&act=url" title="">
                                Êó•Êú¨Ë™û
                            </a>
                            
                            <a class="dropdown-item" href="https://translate.google.com/translate?hl=jp&sl=en&tl=es&u=https%3A%2F%2Ftraining.galaxyproject.org%2Ftopics%2Fstatistics%2Ftutorials%2Fintro_deep_learning%2Ftutorial.html&edit-text=&act=url" title="">
                                Espa√±ol
                            </a>
                            
                            <a class="dropdown-item" href="https://translate.google.com/translate?hl=jp&sl=en&tl=pt&u=https%3A%2F%2Ftraining.galaxyproject.org%2Ftopics%2Fstatistics%2Ftutorials%2Fintro_deep_learning%2Ftutorial.html&edit-text=&act=url" title="">
                                Portugu√™s
                            </a>
                            
                            <a class="dropdown-item" href="https://translate.google.com/translate?hl=jp&sl=en&tl=ar&u=https%3A%2F%2Ftraining.galaxyproject.org%2Ftopics%2Fstatistics%2Ftutorials%2Fintro_deep_learning%2Ftutorial.html&edit-text=&act=url" title="">
                                ÿßŸÑÿπÿ±ÿ®Ÿäÿ©
                            </a>
                            
                            <a class="dropdown-item" href="https://translate.google.com/translate?hl=jp&sl=en&tl=&u=https%3A%2F%2Ftraining.galaxyproject.org%2Ftopics%2Fstatistics%2Ftutorials%2Fintro_deep_learning%2Ftutorial.html&edit-text=&act=url" title="">
                                And more!
                            </a>
                        </div>
                    </li>

                    <li class="nav-item dropdown">
    <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-expanded="false" title="Help">
        <i class="far fa-question-circle" aria-hidden="true"></i><span class="visually-hidden">help</span> Help
    </a>
    <div class="dropdown-menu dropdown-menu-right">
        <form method="get" action="https://tess.elixir-europe.org/materials">
            <input type="text" id="search" name="q" value="" style="margin-left: 0.5em;/*! border-radius: 0px; */">
            <input type="hidden" value="Galaxy Training" name="content_provider">
            <input type="submit" value="Search on TeSS" style="width: 92%;border-radius: 0px;margin: 0.5em;background: #f47d20;border: 0px;padding: 0.25em;" class="">
        </form>

        <div class="dropdown-divider"></div>
        <a class="dropdown-item" href="/training-material/faq" title="Check our FAQ">
            FAQ
        </a>
        <a class="dropdown-item" href="https://help.galaxyproject.org/" title="Discuss on Galaxy Help">
            Discuss on Galaxy Help
        </a>

        <div class="dropdown-item">
            <div>
                Theme
            </div>

            <div id="theme-selector" data-toggle="buttons">
                <label data-value="default" class="btn btn-secondary">
                    <input type="radio" name="options" id="default" autocomplete="off"> Default
                </label>
                <label data-value="night" class="btn btn-secondary">
                    <input type="radio" name="options" id="night" autocomplete="off"> Night
                </label>
                <label data-value="midnight" class="btn btn-secondary">
                    <input type="radio" name="options" id="midnight" autocomplete="off"> Midnight
                </label>
                <label data-value="rainbow" class="btn btn-secondary">
                    <input type="radio" name="options" id="rainbow" autocomplete="off"> Rainbow
                </label>
                <label data-value="halloween" class="btn btn-secondary">
                    <input type="radio" name="options" id="halloween" autocomplete="off"> üéÉ
                </label>
            </div>

        </div>
    </div>
</li>


                    <li class="nav-item">
                        <a class="nav-link" href="https://github.com/galaxyproject/training-material/edit/master/topics/statistics/tutorials/intro_deep_learning/tutorial.md">
                            <i class="fab fa-github" aria-hidden="true"></i><span class="visually-hidden">github</span> Edit
                        </a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>
</header>

<div class="container main-content">
    <script type="application/ld+json">
        


{
  "@context": "http://schema.org",
  "@type": "Course",
  "accessMode": [
    "textual",
    "visual"
  ],
  "accessModeSufficient": [
    "textual",
    "visual"
  ],
  "accessibilityControl": [
    "fullKeyboardControl",
    "fullMouseControl"
  ],
  "accessibilityFeature": [
    "alternativeText",
    "tableOfContents"
  ],
  "accessibilitySummary": "Short descriptions are present but long descriptions will be needed for non-visual users",
  "audience": {
    "@type": "EducationalAudience",
    "educationalRole": "students"
  },
  "citation": {
    "@type": "CreativeWork",
    "name": "Community-Driven Data Analysis Training for Biology",
    "url": "https://doi.org/10.1016/j.cels.2018.05.012"
  },
  "copyrightHolder": {
    "@type": "Organization",
    "email": "galaxytrainingnetwork@gmail.com",
    "name": "Galaxy Training Network",
    "url": "https://galaxyproject.org/teach/gtn/"
  },
  "discussionUrl": "https://gitter.im/Galaxy-Training-Network/Lobby",
  "headline": "Introduction to deep learning",
  "inLanguage": {
    "@type": "Language",
    "name": "English",
    "alternateName": "en"
  },
  "interactivityType": "mixed",
  "isAccessibleForFree": true,
  "license": "https://github.com/galaxyproject/training-material/blob/master/LICENSE.md",
  "producer": {
    "@type": "Organization",
    "email": "galaxytrainingnetwork@gmail.com",
    "name": "Galaxy Training Network",
    "url": "https://galaxyproject.org/teach/gtn/"
  },
  "provider": {
    "@type": "Organization",
    "email": "galaxytrainingnetwork@gmail.com",
    "name": "Galaxy Training Network",
    "url": "https://galaxyproject.org/teach/gtn/"
  },
  "sourceOrganization": {
    "@type": "Organization",
    "email": "galaxytrainingnetwork@gmail.com",
    "name": "Galaxy Training Network",
    "url": "https://galaxyproject.org/teach/gtn/"
  },
  "isPartOf": {
    "@type": "CreativeWork",
    "name": "Statistics and machine learning",
    "description": "Statistical Analyses for omics data and machine learning using Galaxy tools",
    "url": "https://training.galaxyproject.org//training-material/topics/statistics/"
  },
  "courseCode": "statistics / intro_deep_learning / hands-on",
  "learningResourceType": "hands-on tutorial",
  "name": "Hands-on for 'Introduction to deep learning' tutorial",
  "url": "https://training.galaxyproject.org//training-material/topics/statistics/tutorials/intro_deep_learning/tutorial.html",
  "timeRequired": "PT1H",
  "description": "The questions this  addresses are:\n - What are deep learning and neural networks?\n - Why is it useful?\n - How to create a neural network architecture for classification?\n\n\\nThe objectives are:\n - Learn basic principles of deep learning\n - Learn about how to create an end-to-end neural network architecture\n - Learn about Galaxy deep learning tools\n - Learn how to interpret predictions\n\n",
  "coursePrerequisites": [
    {
      "@type": "CreativeWork",
      "url": "https://training.galaxyproject.org//training-material/topics/introduction/",
      "name": "Introduction to Galaxy Analyses",
      "description": "Introduction to Galaxy Analyses",
      "provider": {
        "@type": "Organization",
        "email": "galaxytrainingnetwork@gmail.com",
        "name": "Galaxy Training Network",
        "url": "https://galaxyproject.org/teach/gtn/"
      }
    }
  ],
  "hasPart": [

  ],
  "author": [
    {
      "@type": "Person",
      "name": "Anup Kumar"
    },
    {
      "@type": "Person",
      "name": "Alireza Khanteymoori"
    }
  ],
  "contributor": [
    {
      "@type": "Person",
      "name": "Anup Kumar"
    },
    {
      "@type": "Person",
      "name": "Alireza Khanteymoori"
    }
  ],
  "about": [
    {
      "@type": "CreativeWork",
      "name": "Statistics and machine learning",
      "description": "Statistical Analyses for omics data and machine learning using Galaxy tools",
      "url": "https://training.galaxyproject.org//training-material/topics/statistics/"
    },
    {
      "@type": "DefinedTerm",
      "@id": "http://edamontology.org/topic_2269",
      "inDefinedTermSet": "http://edamontology.org",
      "termCode": "topic_2269",
      "url": "https://bioportal.bioontology.org/ontologies/EDAM/?p=classes&conceptid=http%3A%2F%2Fedamontology.org%2Ftopic_2269"
    }
  ]
}
    </script>

    <section class="tutorial">
        <h1 data-toc-skip>Introduction to deep learning</h1>
        

        <div class="contributors-line">By: 

<a href="/training-material/hall-of-fame/anuprulez/" class="contributor-badge"><img src="https://avatars.githubusercontent.com/anuprulez" alt="Anup Kumar">Anup Kumar</a>, <a href="/training-material/hall-of-fame/khanteymoori/" class="contributor-badge"><img src="https://avatars.githubusercontent.com/khanteymoori" alt="Alireza Khanteymoori">Alireza Khanteymoori</a>

</div>

        <blockquote class="overview">
            <h3>Overview</h3>
            <strong><i class="far fa-question-circle" aria-hidden="true"></i><span class="visually-hidden">question</span> Questions</strong>
            <ul>
            
            <li><p>What are deep learning and neural networks?</p>
</li>
            
            <li><p>Why is it useful?</p>
</li>
            
            <li><p>How to create a neural network architecture for classification?</p>
</li>
            
            </ul>

            <strong><i class="fas fa-bullseye" aria-hidden="true"></i><span class="visually-hidden">objectives</span> Objectives</strong>
            <ul>
            
            <li><p>Learn basic principles of deep learning</p>
</li>
            
            <li><p>Learn about how to create an end-to-end neural network architecture</p>
</li>
            
            <li><p>Learn about Galaxy deep learning tools</p>
</li>
            
            <li><p>Learn how to interpret predictions</p>
</li>
            
            </ul>

            
            <strong><i class="fas fa-check-circle" aria-hidden="true"></i><span class="visually-hidden">requirements</span> Requirements</strong>
            <ul>
            
    <li>
    
        
        
        <a href="/training-material/topics/introduction">Introduction to Galaxy Analyses</a>
        
    
    </li>

            
            </ul>
            

            
            <p><strong><i class="fas fa-hourglass-half" aria-hidden="true"></i><span class="visually-hidden">time</span> Time estimation:</strong> 1 hour</p>
            

            

            
            

            
            <p id="supporting-materials"><strong><i class="fa fa-external-link" aria-hidden="true"></i> Supporting Materials</strong></p>
            <ul>
                <div class="supporting_material">
                

                
                    <li class="btn btn-default supporting_material">
<a class="topic-icon" href="https://zenodo.org/record/3706539#.XmjDYHVKg5k">
    <i class="far fa-copy" aria-hidden="true"></i><span class="visually-hidden">zenodo_link</span> Datasets
</a>

</li>
                

                

                

                
                    <li class="btn btn-default supporting_material">

    <a href="#" class="btn btn-default dropdown-toggle topic-icon" data-toggle="dropdown" aria-expanded="false" title="Where to run the tutorial">
        <i class="fas fa-globe" aria-hidden="true"></i><span class="visually-hidden">instances</span> Available on these Galaxies
    </a>
    <ul class="dropdown-menu">
    
        <li>
            <a class="dropdown-item" href="https://github.com/galaxyproject/training-material/tree/master/topics/statistics/docker" title="Docker image for this tutorial">
                <i class="fab fa-docker" aria-hidden="true"></i><span class="visually-hidden">docker_image</span> Docker image
            </a>
        </li>
    
    
    </ul>


</li>
                
                </div>
            </ul>
            

            <p><strong> <i class="far fa-calendar" aria-hidden="true"></i><span class="visually-hidden">last_modification</span> Last modification:</strong> Jan 6, 2021 </p>
        </blockquote>

        <div class="container">
            <div class="row">
                <!-- sidebar, which will move to the top on a small screen -->
                <div class="col-sm-2">
                    <nav id="toc" data-toggle="toc" class="sticky-top"></nav>
                </div>
                <div class="col-sm-10">
                    <h2 id="introduction">Introduction</h2>

<h3 id="deep-learning-and-neural-networks">Deep learning and neural networks</h3>
<p><a href="https://en.wikipedia.org/wiki/Deep_learning">Deep learning</a>, a branch of artificial intelligence, provides a collection of learning methods to model data with complex architectures to perform different non-linear transformations of data. Using these transformations, patterns are recognised in large volumes of data and new data can be categorised using these patterns extracted on existing data. These patterns are learned by computational models devised using different architectures of neural networks. In the recent years, the neural network architectures such as convolutional, long short-term memory networks, deep belief networks have become increasingly popular as machine learning tools in the fields of computer vision, image analysis, bioinformatics, speech recognition, natural language processing and so on achieving state-of-the-art performance, sometimes exceeding human performance. The availability of greater computational resources, more data, new algorithms for training deep models and easy to use libraries for implementation and training of neural networks are the drivers of this development. Deep learning works by approximating the mathematical function which maps data to its output and it has been shown that it can <a href="https://arxiv.org/pdf/1910.03344.pdf">approximate</a> any function making it widely popular across multiple fields to analyse data. A neural network is a web of artificial neurons which are also called processing units. The idea of a neural network is inspired by <a href="https://en.wikipedia.org/wiki/Neural_circuit">biological neural networks</a> where neuronal circuits are used to process information and learn. An artificial neural network is structured into multiple layers where each layer contains several neurons. The neurons from adjacent layers are interconnected (<a href="https://en.wikipedia.org/wiki/Feedforward_neural_network">feed-forward neural network</a>) allowing the exchange of information between layers of neurons.</p>

<figure id="figure-1"><img src="../../images/neuron.svg" alt="data" /><figcaption><span class="figcaption-prefix">Figure 1:</span> Structure of an artificial neuron. The input x (x1, x2, ..., xn) and its corresponding weight w (w1, w2, ..., wn) are vectors. The input and its weight are transformed to produce an output y</figcaption></figure>

<p>An artificial neuron is shown in Figure 1. The neuron, shown in orange, takes input <code class="language-plaintext highlighter-rouge">x</code> (only <code class="language-plaintext highlighter-rouge">x1</code> and <code class="language-plaintext highlighter-rouge">x2</code> are shown for simplicity) and computes output <code class="language-plaintext highlighter-rouge">y</code>. The entities <code class="language-plaintext highlighter-rouge">w1</code>, <code class="language-plaintext highlighter-rouge">w2</code> are the weights of the connections (between inputs and neuron). The weights and inputs are combined following the basic principles of mathematics to produce output <code class="language-plaintext highlighter-rouge">y</code> (shown in Figures 2, 3 and 4).</p>

<figure id="figure-2"><img src="../../images/eq1.png" alt="data" /><figcaption><span class="figcaption-prefix">Figure 2:</span> Transformation of a component (x1) of the input vector (x).</figcaption></figure>

<figure id="figure-3"><img src="../../images/eq2.png" alt="data" /><figcaption><span class="figcaption-prefix">Figure 3:</span> Transformation of a component (x2) of the input vector (x).</figcaption></figure>

<p>Weights denote the significance of a particular input to produce the observed output. When it is large, the input is significant and when small, the input is less significant to produce the output. These weights can be initialised randomly and they are modified throughout the learning by a neural network. Using the updated inputs (as shown in the above equations), the output is computed:</p>

<figure id="figure-4"><img src="../../images/eq3.png" alt="data" /><figcaption><span class="figcaption-prefix">Figure 4:</span> Computation of output y using input x, weight w and activation function f.</figcaption></figure>

<p>where <em>f</em> is an activation function. An <a href="https://keras.io/activations/">activation function</a> is a mathematical function which translates the combination of inputs to an output. The choices of these functions are many - sigmoid, linear, tanh, ReLU and so on. For example, sigmoid is:</p>

<figure id="figure-5"><img src="../../images/eq4.png" alt="data" /><figcaption><span class="figcaption-prefix">Figure 5:</span> Sigmoid activation function.</figcaption></figure>

<p>The above equation will return a real number between 0 and 1.</p>

<p>Rectified exponential linear unit (ReLU) is given by:</p>

<figure id="figure-6"><img src="../../images/eq5.png" alt="data" /><figcaption><span class="figcaption-prefix">Figure 6:</span> Rectified exponential linear unit (ReLU) activation function.</figcaption></figure>

<p>As discussed earlier, neurons make the building blocks of a neural network and are arranged in several layers and a usual neural network looks like as shown in Figure 7.</p>

<h4 id="input-layer">Input layer</h4>
<p>In the neural network (Figure 7), the input layer is shown in green. This layer receives input data and passes it on to the next layer. The number of neurons in this layer depends on the number of dimensions of input data. For example, if input data (matrix) is of size (500, 10), 500 rows (samples) and 10 columns (features), then the number of neurons in the input layer should be 10. Each neuron in input layer is connected to all neurons in the next layer. All these connections have a separate weight (denoted by <code class="language-plaintext highlighter-rouge">w</code>).</p>

<h4 id="hidden-layer">Hidden layer</h4>
<p>The next two layers after the input layer are called hidden layers. In the first hidden layer too, all the neurons are connected to all other neurons in the adjacent (hidden) layer. The number of hidden layers determines if the resulting neural network is deep (2 or more hidden layers) or shallow. When the number of hidden layers is 2 or more, the structure or architecture of the neural network is deep and overall learning is called deep learning. More the number of hidden layers, the more complex the architecture is. A complex architecture is beneficial for learning unique patterns from big data. But, complex architecture is prone to <a href="https://en.wikipedia.org/wiki/Overfitting">overfitting</a> when a neural network starts memorising data without learning unique and general patterns.</p>

<figure id="figure-7"><img src="../../images/neural_network.svg" alt="data" /><figcaption><span class="figcaption-prefix">Figure 7:</span> A neural network consisting of 4 layers - 1 input, 2 hidden and 1 output. The neurons in each layer are connected to all neurons in the adjacent layer. Each connection between a pair of neurons contains a weight.</figcaption></figure>

<p>The number of hidden layers and the size of each hidden layer is not fixed as it completely depends on the data. If the dataset is small (say only 1,000 samples), then it is sufficient to choose a less complex architecture (fewer hidden layers) to avoid the danger of overfitting. However, if the dataset is large (say &gt; 100,000 samples), more complex architecture can be chosen. In short, the architecture of the hidden layer is completely dependent on the nature and size of data.</p>

<h4 id="output-layer">Output layer</h4>
<p>This layer collects output computed using input data and weights which are optimised during learning. An activation function is chosen to transform the combination of input and weight to an output. Some examples of activation functions have been discussed above.</p>

<h4 id="optimisation">Optimisation</h4>
<p>Compted or predicted output, collected at the output layer, and the actual output are compared to find error (or loss). Neural network learning aims is to minimise this error so that the predicted output gets as close to the actual output as possible. This process of minimising error between predicted and actual output is called optimisation. There are several optimisers such as <a href="https://en.wikipedia.org/wiki/Gradient_descent">gradient descent</a>, root mean square propagation (<a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#RMSProp">RMSProp</a>), <a href="https://arxiv.org/pdf/1212.5701.pdf">adadelta</a> and so on are available. These optimisers work by primarily adjusting the weights of connections so that the error is minimised. Once, a set of weights are achieved which provides the best accuracy or minimum error, the learning is terminated because the weights cannot be updated anymore which can further minimise the error.</p>

<h4 id="neural-network-training">Neural network training</h4>
<p>Training is a process where input data is passed to a neural network at input layer and when finished, a trained model is created containing all the learned parameters such as weights of all connections in the neural network. Usually, a portion of data is extracted and saved as test data which is not used for training. It is used only for evaluating the trained model to get an unbiased estimate of learning and prediction strength. The partitioning of data into training and test can be set by deep learning practitioners. An example of partition can be - 70% training and 30% test data.</p>

<h4 id="batch-and-epoch">Batch and Epoch</h4>
<p>While training a neural network, input data is passed in small batches. A batch is a subset of training data. An epoch is one iteration when all the training data is used for training in multiple batches. For example, if there is training data of size (500, 10) and batch size is fixed at 50, then there would be 10 batches (50 * 10 = 500) in each epoch. Each batch will have 50 samples and they are passed to the input layer of neural network. The loss computed at the output layer is propagated back and the weights are adjusted. The newly adjusted weights are used for the second batch of samples and so on. When all batches are finished, then one epoch of learning is done. The number of epochs and the size of a batch are parameters to be set by deep learning practitioners. These parameters depend on the size of data and should be tuned according to the data for optimum results.</p>

<figure id="figure-8"><img src="../../images/mse.png" alt="data" /><figcaption><span class="figcaption-prefix">Figure 8:</span> Mean squared error loss function.</figcaption></figure>

<h4 id="loss-function">Loss function</h4>
<p>The error between the computed and actual output is calculated using a loss function which is necessary to evaluate the strength of learning. Learning is good when loss decreases with training epochs otherwise, training should be stopped and the architecture should be carefully adjusted. There are several choices of loss functions too. Functions such as root mean squared error (RMSE) and absolute error (AE) are used for regression problems while cross-entropy error functions such as binary cross-entropy and categorical cross-entropy are used in classification problems. An example of loss function is shown in Figure 8.</p>

<blockquote class="question">
  <h3 id="question-questions"><i class="far fa-question-circle" aria-hidden="true"></i><span class="visually-hidden">question</span> Questions</h3>

  <ol>
    <li>What do you understand by an architecture of a neural network?</li>
    <li>How does a neural network learn?</li>
  </ol>

  <blockquote class="solution">
    <h3 id="solution-solution"><i class="far fa-eye" aria-hidden="true"></i><span class="visually-hidden">solution</span> Solution</h3>

    <ol>
      <li>Architecture of a neural network consists of multiple layers such as input, hidden, convolutional, output and their number of respective neurons, optimiser, loss and activation functions etc.</li>
      <li>The learning happens by minimising the loss between the computed and actual output. The weights of all neuronal connections are adjusted (increased or decreased) to achieve the minimum loss. To ascertain the amount of change for weights, a technique known as backpropagation is used. Using this technique, the loss computed at the output layer is ‚Äúpropagated‚Äù back in the neural network (from output to input layer) and each neuronal connection is assigned a share of the total loss. In other words, how much each neuron is contributing to the total accumulated loss. For example, w1 is adjusted according to equation:</li>
    </ol>
    <figure id="figure-9"><img src="../../images/partial_derivative.png" alt="data" /><figcaption><span class="figcaption-prefix">Figure 9:</span> Weight w1 is updated by computing a partial derivative of loss L with respect to weight. The derivative is multiplied with learning rate n.</figcaption></figure>
    <p>In the above equation, <code class="language-plaintext highlighter-rouge">L</code> is the total loss, <code class="language-plaintext highlighter-rouge">w1</code> is the weight of a connection between an input neuron and a hidden neuron. Similarly, all weights are adjusted and in the subsequent iteration, the updated weights are used to compute loss at the output layer. Parameter <code class="language-plaintext highlighter-rouge">n</code> is the learning rate which determines how small or big changes are needed in weights. It can either be a fixed quantity or a variable one. In case of a variable learning rate, it usually starts with a large number (say 1.0) and subsequently decays to a small number (say 0.001) as the training epochs proceed because initially a large learning rate helps to reach close to the minimum error quickly and then it is decayed to slow down the learning so that it stabilises at the minimum. More on backpropagation can be read <a href="http://neuralnetworksanddeeplearning.com/chap2.html">here</a>.</p>

  </blockquote>

</blockquote>

<h3 id="relevance-of-deep-learning-in-bioinformatics">Relevance of deep learning in Bioinformatics</h3>
<p>Deep learning is an established tool in finding patterns in big data for multiple fields of research such as computer vision, image analysis, drug response prediction, protein structure prediction and so on. Different research areas use different architectures of neural network which are suitable to their respective data. For example - in computer vision and image analysis, convolutional neural network (CNN) is popular, graph convolutional neural network is often used for drug response prediction, recurrent neural network is useful for identifying motifs in protein sequences and so on. The table below shows more examples of neural networks which are popular with different fields of bioinformatics. These use-cases of deep learning in bioinformatics prove that it is essential to explore deep learning algorithms to find patterns in big data in biology. More details can be found in <a href="https://www.sciencedirect.com/science/article/pii/S1046202318303256">Deep learning in bioinformatics: Introduction, application, and perspective in the big data era</a>.</p>

<figure id="figure-10"><img src="../../images/dl_bioinformatics.png" alt="data" /><figcaption><span class="figcaption-prefix">Figure 10:</span> Different architectures of neural networks for different fields of bioinformatics.</figcaption></figure>

<h2 id="get-training-and-test-datasets">Get training and test datasets</h2>
<p>The datasets used for this tutorial contain gene <span class="notranslate">expression</span> profiles of humans suffering from two types of cancer - <a href="https://en.wikipedia.org/wiki/Acute_myeloid_leukemia">acute myeloid leukemia (AML)</a> and <a href="https://en.wikipedia.org/wiki/Acute_lymphoblastic_leukemia">acute lymphoblastic leukemia (ALL)</a>. The tutorial aims to differentiate between these two cancer types, predicting a cancer type for each patient, by learning unique patterns in gene <span class="notranslate">expression</span> profiles of patients. The data is divided into 2 parts - one for training and another for prediction. Each part contains two datasets - one has the gene <span class="notranslate">expression</span> profiles and another has labels (the types of cancer). The size of the training data (<code class="language-plaintext highlighter-rouge">X_train</code>) is (38, 7129) where 38 is the number of patients and 7129 is the number of genes. The label dataset (<code class="language-plaintext highlighter-rouge">y_train</code>) is of size (38, 1) and contains the information of the type of cancer for each patient (label encoding is 0 for ALL and 1 for AML). The test dataset (<code class="language-plaintext highlighter-rouge">X_test</code>) is of size (34, 7129) and contains the same genes for 34 different patients. The label dataset for test is <code class="language-plaintext highlighter-rouge">y_test</code> and is of size (34, 1). The neural network, which will be formulated in the remaining part of the tutorial, learns on the training data and its labels to create a trained model. The prediction ability of this model is evaluated on the test data (which is unseen during training to get an unbiased estimate of prediction ability). These datasets are uploaded to <span class="notranslate">Galaxy</span> by following the steps defined below:</p>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-data-upload"><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Data upload</h3>

  <ol>
    <li>
      <p>Create a new history for this tutorial</p>

      <blockquote class="tip">

        <h3 id="tip-tip-creating-a-new-history"><i class="far fa-lightbulb" aria-hidden="true"></i><span class="visually-hidden">tip</span> Tip: Creating a new history</h3>

        <p>Click the <i class="fas fa-plus" aria-hidden="true"></i><span class="visually-hidden">new-history</span> icon at the top of the history panel</p>

        <p>If the <i class="fas fa-plus" aria-hidden="true"></i><span class="visually-hidden">new-history</span> is missing:</p>
        <ol>
          <li>Click on the <i class="fas fa-cog" aria-hidden="true"></i><span class="visually-hidden"><span class="notranslate">galaxy</span>-gear</span> icon (<strong>History options</strong>) on the top of the history panel</li>
          <li>Select the option <strong>Create New</strong> from the menu</li>
        </ol>
      </blockquote>
    </li>
    <li>
      <p>Import the files from <a href="https://zenodo.org/record/3706539#.XmjDYHVKg5k">Zenodo</a></p>

      <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>https://zenodo.org/record/3706539/files/X_test.tsv
https://zenodo.org/record/3706539/files/X_train.tsv
https://zenodo.org/record/3706539/files/y_test.tsv
https://zenodo.org/record/3706539/files/y_train.tsv
</code></pre></div>      </div>
    </li>
    <li>
      <p>Rename the datasets as <code class="language-plaintext highlighter-rouge">X_test</code>, <code class="language-plaintext highlighter-rouge">X_train</code>, <code class="language-plaintext highlighter-rouge">y_test</code> and <code class="language-plaintext highlighter-rouge">y_train</code> respectively.</p>

      <blockquote class="tip">

        <h3 id="tip-tip-renaming-a-dataset"><i class="far fa-lightbulb" aria-hidden="true"></i><span class="visually-hidden">tip</span> Tip: Renaming a dataset</h3>
        <ul>
          <li>Click on the <i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden"><span class="notranslate">galaxy</span>-pencil</span> <strong>pencil icon</strong> for the dataset to edit its attributes</li>
          <li>In the central panel, change the <strong>Name</strong> field</li>
          <li>Click the <strong>Save</strong> button</li>
        </ul>
      </blockquote>

      <blockquote class="tip">

        <h3 id="tip-tip-importing-data-via-links"><i class="far fa-lightbulb" aria-hidden="true"></i><span class="visually-hidden">tip</span> Tip: Importing data via links</h3>

        <ul>
          <li>Copy the link location</li>
          <li>
            <p>Open the <span class="notranslate">Galaxy</span> Upload Manager (<i class="fas fa-upload" aria-hidden="true"></i><span class="visually-hidden"><span class="notranslate">galaxy</span>-upload</span> on the top-right of the tool panel)</p>
          </li>
          <li>Select <strong>Paste/Fetch Data</strong></li>
          <li>
            <p>Paste the link into the text field</p>
          </li>
          <li>
            <p>Press <strong>Start</strong></p>
          </li>
          <li><strong>Close</strong> the window</li>
        </ul>

        <p>By default, <span class="notranslate">Galaxy</span> uses the URL as the name, so rename the files with a more useful name.</p>

      </blockquote>
    </li>
    <li>
      <p>Check that the datatype is <code class="language-plaintext highlighter-rouge">tabular</code>.</p>

      <blockquote class="tip">

        <h3 id="tip-tip-changing-the-datatype"><i class="far fa-lightbulb" aria-hidden="true"></i><span class="visually-hidden">tip</span> Tip: Changing the datatype</h3>
        <ul>
          <li>Click on the <i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden"><span class="notranslate">galaxy</span>-pencil</span> <strong>pencil icon</strong> for the dataset to edit its attributes</li>
          <li>In the central panel, click on the <i class="fas fa-database" aria-hidden="true"></i><span class="visually-hidden"><span class="notranslate">galaxy</span>-chart-select-data</span> <strong>Datatypes</strong> tab on the top</li>
          <li>Select <code class="language-plaintext highlighter-rouge">datatypes</code></li>
          <li>Click the <strong>Change datatype</strong> button</li>
        </ul>
      </blockquote>
    </li>
  </ol>

</blockquote>

<h2 id="neural-network-architecture">Neural network architecture</h2>
<p>Defining a neural network architecture needs to ascertain the types and number of layers, the number of neurons for each layer, activation functions for all layers, type of optimiser and loss function. Choosing these parameters may require many experiments with data as there is no golden rule to choose the best combination of these parameters. The neural network used in this tutorial has an input layer, 2 hidden layers and one output layer. The input layer has a parameter <code class="language-plaintext highlighter-rouge">input_shape</code> which is set according to the number of dimensions of data. It is set to (7129,) which is the number of genes present in data. The hidden layers have 16 neurons (units) each and the output layer has only one because a scalar output is expected (0 or 1). This partial architecture (having input shape, types and size of layers, and activation functions) of the neural network is defined as follows:</p>

<h3 id="create-architecture-choose-layers">Create architecture: Choose layers</h3>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-create-a-deep-learning-model-architecture-using-keras"><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Create a deep learning model architecture using Keras</h3>

  <ol>
    <li><strong>Create a deep learning model architecture using Keras</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span> with the following parameters:
      <ul>
        <li><em>‚ÄúSelect keras model type‚Äù</em>: <code class="language-plaintext highlighter-rouge">Sequential</code></li>
        <li>
          <p><em>‚Äúinput_shape‚Äù</em>: <code class="language-plaintext highlighter-rouge">(7129, )</code></p>
        </li>
        <li>In <em>‚ÄúLAYER‚Äù</em>:
          <ul>
            <li><i class="far fa-plus-square" aria-hidden="true"></i><span class="visually-hidden">param-repeat</span> <em>‚Äú1: LAYER‚Äù</em>:
              <ul>
                <li><em>‚ÄúChoose the type of layer‚Äù</em>: <code class="language-plaintext highlighter-rouge">Core -- Dense</code>
                  <ul>
                    <li><em>‚Äúunits‚Äù</em>: <code class="language-plaintext highlighter-rouge">16</code></li>
                    <li><em>‚ÄúActivation function‚Äù</em>: <code class="language-plaintext highlighter-rouge">elu</code></li>
                  </ul>
                </li>
              </ul>
            </li>
            <li><i class="far fa-plus-square" aria-hidden="true"></i><span class="visually-hidden">param-repeat</span> <em>‚Äú2: LAYER‚Äù</em>:
              <ul>
                <li><em>‚ÄúChoose the type of layer‚Äù</em>: <code class="language-plaintext highlighter-rouge">Core -- Dense</code>
                  <ul>
                    <li><em>‚Äúunits‚Äù</em>: <code class="language-plaintext highlighter-rouge">16</code></li>
                    <li><em>‚ÄúActivation function‚Äù</em>: <code class="language-plaintext highlighter-rouge">elu</code></li>
                  </ul>
                </li>
              </ul>
            </li>
            <li><i class="far fa-plus-square" aria-hidden="true"></i><span class="visually-hidden">param-repeat</span> <em>‚Äú3: LAYER‚Äù</em>:
              <ul>
                <li><em>‚ÄúChoose the type of layer‚Äù</em>: <code class="language-plaintext highlighter-rouge">Core -- Dense</code>
                  <ul>
                    <li><em>‚Äúunits‚Äù</em>: <code class="language-plaintext highlighter-rouge">1</code></li>
                    <li><em>‚ÄúActivation function‚Äù</em>: <code class="language-plaintext highlighter-rouge">sigmoid</code></li>
                  </ul>
                </li>
              </ul>
            </li>
          </ul>
        </li>
      </ul>
    </li>
  </ol>

</blockquote>

<p>The tool returns a JSON output file containing data about the neural network layers and their attributes like their types, number of units they have and their activation functions. This file is used as an input to the next step where the architecture of the neural network is completed by adding optimiser, loss function, and training parameters such as the number of epochs and batch size. The loss function is chosen as <code class="language-plaintext highlighter-rouge">binary_crossentropy</code> as the learning task is the classification of two labels (0 and 1).</p>

<h3 id="create-architecture-add-training-parameters">Create architecture: Add training parameters</h3>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-create-deep-learning-model-with-an-optimizer-loss-function-and-fit-parameters"><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Create deep learning model with an optimizer, loss function and fit parameters</h3>

  <ol>
    <li><strong>Create deep learning model with an optimizer, loss function and fit parameters</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span> with the following parameters:
      <ul>
        <li><em>‚ÄúChoose a building mode‚Äù</em>: <code class="language-plaintext highlighter-rouge">Build a training model</code></li>
        <li><em>‚ÄúSelect the dataset containing model configurations (JSON)‚Äù</em>: <code class="language-plaintext highlighter-rouge">Keras model config</code> (output of <strong>Create a deep learning model architecture using Keras</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span>)</li>
        <li><em>‚ÄúDo classification or regression?‚Äù</em>: <code class="language-plaintext highlighter-rouge">KerasGClassifier</code></li>
      </ul>

      <p><code class="language-plaintext highlighter-rouge">KerasGClassifier</code> is chosen because the learning task is classfication i.e. assigning each patient a type of cancer.</p>
      <ul>
        <li>In <em>‚ÄúCompile Parameters‚Äù</em>:
          <ul>
            <li><em>‚ÄúSelect a loss function‚Äù</em>: <code class="language-plaintext highlighter-rouge">binary_crossentropy</code></li>
          </ul>

          <p>The loss function is <code class="language-plaintext highlighter-rouge">binary_crossentropy</code> because the labels are discrete and binary (0 and 1).</p>
          <ul>
            <li><em>‚ÄúSelect an optimizer‚Äù</em>: <code class="language-plaintext highlighter-rouge">RMSprop - RMSProp optimizer</code></li>
          </ul>
        </li>
        <li>In <em>‚ÄúFit Parameters‚Äù</em>:
          <ul>
            <li><em>‚Äúepochs‚Äù</em>: <code class="language-plaintext highlighter-rouge">10</code></li>
            <li><em>‚Äúbatch_size‚Äù</em>: <code class="language-plaintext highlighter-rouge">4</code></li>
          </ul>

          <p>The training data is small (only 38 patients). Therefore the number of epochs and batch size are also small.</p>
        </li>
      </ul>
    </li>
  </ol>

</blockquote>

<p>The tool returns a zipped file containing an object of the neural network architecture (define in the last two steps) which is used as a classifier to train it on data. Once the architecture is finalised, its associated object is used for training combining it with the training data as follows:</p>

<h3 id="deep-learning-training">Deep learning training</h3>
<p>A neural network is trained on training data to learn hidden representations and <span class="notranslate">mapping</span> from features (genes) to both the types of cancer. As discussed earlier, the neural network minimises the error, which is given by the loss function, between actual and predicted labels while adjusting the weights of connections among neurons in multiple layers. Once the training is finished, the architecture and learned weights are saved. They are used to predict labels in test data. The deep learning training is set up as follows:</p>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-deep-learning-training-and-evaluation-conduct-deep-training-and-evaluation-either-implicitly-or-explicitly"><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Deep learning training and evaluation conduct deep training and evaluation either implicitly or explicitly</h3>

  <ol>
    <li><strong>Deep learning training and evaluation conduct deep training and evaluation</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span> with the following parameters:
      <ul>
        <li><em>‚ÄúSelect a scheme‚Äù</em>: <code class="language-plaintext highlighter-rouge">Train and validate</code></li>
        <li><em>‚ÄúChoose the dataset containing pipeline/estimator object‚Äù</em>: <code class="language-plaintext highlighter-rouge">Keras model builder</code> (output of <strong>Create deep learning model</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span>)</li>
        <li><em>‚ÄúSelect input type‚Äù</em>: <code class="language-plaintext highlighter-rouge">tabular data</code></li>
        <li><em>‚ÄúTraining samples dataset‚Äù</em>: <code class="language-plaintext highlighter-rouge">X_train</code>
          <ul>
            <li><em>‚ÄúDoes the dataset contain header‚Äù</em>: <code class="language-plaintext highlighter-rouge">Yes</code></li>
            <li><em>‚ÄúChoose how to select data by column‚Äù</em>: <code class="language-plaintext highlighter-rouge">All columns</code></li>
          </ul>
        </li>
        <li><em>‚ÄúDataset containing class labels or target values‚Äù</em>: <code class="language-plaintext highlighter-rouge">y_train</code>
          <ul>
            <li><em>‚ÄúDoes the dataset contain header‚Äù</em>: <code class="language-plaintext highlighter-rouge">Yes</code></li>
            <li><em>‚ÄúChoose how to select data by column‚Äù</em>: <code class="language-plaintext highlighter-rouge">All columns</code></li>
          </ul>
        </li>
      </ul>
    </li>
  </ol>

</blockquote>

<p>The tool gives 3 files as output - a tabular file containing output (accuracy of cross-validation) of training, a zipped file with the trained model (fitted estimator) and an H5 (HDF5) file containing the weights of neural network layers. The files containing the fitted estimator and weights are used to recreate the model and this recreated model is used to predict labels in test data.</p>

<h3 id="prediction-on-test-data">Prediction on test data</h3>
<p>After training, the saved architecture (fitted estimator) and weights are used to predict labels for the test data. For each patient in the test data, a type of cancer is predicted using the trained model learned in the previous step.</p>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-model-prediction-predicts-on-new-data-using-a-preffited-model"><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Model Prediction predicts on new data using a preffited model</h3>

  <ol>
    <li><strong>Model Prediction predicts on new data using a preffited model</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span> with the following parameters:
      <ul>
        <li><em>‚ÄúChoose the dataset containing pipeline/estimator object‚Äù</em>: <code class="language-plaintext highlighter-rouge">Fitted estimator or estimator skeleton</code> (output of <strong>Deep learning training and evaluation</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span>)</li>
        <li><em>‚ÄúChoose the dataset containing weights for the estimator above‚Äù</em>: <code class="language-plaintext highlighter-rouge">Weights trained</code> (output of <strong>Create deep learning model</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span>)</li>
        <li><em>‚ÄúSelect invocation method‚Äù</em>: <code class="language-plaintext highlighter-rouge">predict</code></li>
        <li><em>‚ÄúSelect input data type for prediction‚Äù</em>: <code class="language-plaintext highlighter-rouge">tabular data</code>
          <ul>
            <li><em>‚ÄúTraining samples dataset‚Äù</em>: <code class="language-plaintext highlighter-rouge">X_test</code></li>
            <li><em>‚ÄúDoes the dataset contain header‚Äù</em>: <code class="language-plaintext highlighter-rouge">Yes</code></li>
            <li><em>‚ÄúChoose how to select data by column‚Äù</em>: <code class="language-plaintext highlighter-rouge">All columns</code></li>
          </ul>
        </li>
      </ul>
    </li>
  </ol>

</blockquote>

<p>The tool returns the predicted labels (0 for ALL and 1 AML) for test data in a tabular format. The size of this data is (34,1) where 34 is the number of cancer patients in test data.</p>

<h2 id="visualisation">Visualisation</h2>
<p>Visualising the results is important to ascertain the generalisation ability of the trained model on an unseen dataset. Using a dataset with the actual labels for the test data, the performance of the trained model is estimated by comparing the actual labels against the predicted labels using a confusion matrix plot.</p>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-machine-learning-visualization-extension-includes-several-types-of-plotting-for-machine-learning"><i class="fas fa-pencil-alt" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Machine Learning Visualization Extension includes several types of plotting for machine learning</h3>

  <ol>
    <li><strong>Machine Learning Visualization Extension includes several types of plotting for machine learning</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span> with the following parameters:
      <ul>
        <li><em>‚ÄúSelect a plotting type‚Äù</em>: <code class="language-plaintext highlighter-rouge">Confusion matrix for classes</code></li>
        <li><em>‚ÄúSelect dataset containing true labels‚Äù</em>: <code class="language-plaintext highlighter-rouge">y_test</code></li>
        <li><em>‚ÄúDoes the dataset contain header‚Äù</em>: <code class="language-plaintext highlighter-rouge">Yes</code></li>
        <li><em>‚ÄúChoose how to select data by column‚Äù</em>: <code class="language-plaintext highlighter-rouge">All columns</code></li>
        <li><em>‚ÄúSelect dataset containing predicted labels‚Äù</em>: <code class="language-plaintext highlighter-rouge">Model prediction</code> (output of <strong>Model Prediction predicts on new data using a preffited model</strong> <i class="fas fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span>)</li>
        <li><em>‚ÄúDoes the dataset contain header‚Äù</em>: <code class="language-plaintext highlighter-rouge">Yes</code></li>
      </ul>
    </li>
  </ol>

</blockquote>

<blockquote class="comment">
  <h3 id="comment-comment"><i class="far fa-comment-dots" aria-hidden="true"></i><span class="visually-hidden">comment</span> Comment</h3>
  <p>Please note that your predictions could be different from the plot shown in Figure 11 because the training data is small and the predictions may vary. Stability in predictions can be achieved if the deep learning model is trained on large data. But, for this tutorial, it is kept small to reduce the training time as the aim is to showcase how to create a pipeline for deep learning training. Generally, deep learning models are trained on large data and may keep running for a few hours to a few days.</p>
</blockquote>

<p>The image below shows <a href="https://en.wikipedia.org/wiki/Confusion_matrix">confusion matrix</a> which is a square matrix. It contains actual labels on the y-axis and predicted labels on the x-axis. Each cell in the matrix plot gives the number of cancer patients who got predicted correctly or incorrectly. For example, the number in the top-left cell (0, 0) denotes how many of these patients are predicted correctly for ALL (17/20). The higher the number in this cell, the better is the model for this cell. In the top-right cell, 3 patients who have ALL but they are predicted having AML. Similarly, the bottom-right cell denotes how many patients are predicted correctly for AML (10/14). In the bottom-left cell, 4 patients have AML but are predicted as ALL.</p>

<figure id="figure-11"><img src="../../images/confusion_matrix_dl.png" alt="data" /><figcaption><span class="figcaption-prefix">Figure 11:</span> Confusion matrix for true and predicted classes</figcaption></figure>

<h2 id="conclusion">Conclusion</h2>
<p>The tutorial presents a case-study to predict labels (ALL and AML) of 34 new cancer patients after learning gene <span class="notranslate">expression</span> profiles of 38 cancer patients through multiple steps of a deep learning pipeline. All these steps show how to create a neural network architecture using <span class="notranslate">Galaxy</span>‚Äôs deep learning tools and analyse results using a confusion matrix visualisation. Similarly, multiple different architectures of neural networks can be created well-suited to datasets and aim of particular experiments. Moreover, it should be noted that one architecture of neural network giving promising results on a dataset may not work at all with another dataset. It is essential to perform multiple experiments with a dataset to formulate an optimal neural network architecture.</p>



                    
                    <blockquote class="key_points">
                        <h3><i class="fas fa-key" aria-hidden="true"></i><span class="visually-hidden">keypoints</span> Key points</h3>
                        <ul>
                            
                            <li><p>Multiple tools to constitute a neural network architecture</p>
</li>
                            
                            <li><p>Interpretation of predictions using visualisation tools</p>
</li>
                            
                        </ul>
                    </blockquote>
                    

                    

                    

                    <h1>Feedback</h1>
                    <p class="text-muted">Did you use this material as an instructor? Feel free to give us feedback on <a href="https://github.com/galaxyproject/training-material/issues/1452" target="_blank">how it went</a>.</p>

                    <div id="feedback-button">
                        <img src="/training-material/shared/images/feedback.png" title="Click to activate" alt="Click here to load Google feedback frame" />
                    </div>
                    <div id="feedback-form">
                    </div>
                    <script type="text/javascript">
                        (function (window, document) {
                            function onDocumentReady(fn) {
                                if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
                                    fn();
                                } else {
                                    document.addEventListener('DOMContentLoaded', fn);
                                }
                            }

                            onDocumentReady(function () {
                                $("#feedback-button").click(function(evt){
                                    var e = $(evt.target)
                                    e.hide();

                                    $("#feedback-form").html(`
                                        <iframe id="feedback-google" class="google-form" src="https://docs.google.com/forms/d/e/1FAIpQLSd4VZptFTQ03kHkMz0JyW9b6_S8geU5KjNE_tLM0dixT3ZQmA/viewform?embedded=true&entry.1235803833=Introduction to deep learning (Statistics and machine learning)">Loading...</iframe>
                                    `)
                                })
                            });
                        })(window, document);
                    </script>



                    <h1>Citing this Tutorial</h1>
                    <p>
                        <ol>
                            <li id="citation-text">Anup Kumar, Alireza Khanteymoori, 2021 <b>Introduction to deep learning (Galaxy Training Materials)</b>. <a href="/training-material/topics/statistics/tutorials/intro_deep_learning/tutorial.html">/training-material/topics/statistics/tutorials/intro_deep_learning/tutorial.html</a> Online; accessed TODAY
                            </li>
                            <li>
                            Batut et al., 2018 <b>Community-Driven Data Analysis Training for Biology</b> Cell Systems <a href="https://doi.org/10.1016%2Fj.cels.2018.05.012">10.1016/j.cels.2018.05.012</a>
                            </li>
                        </ol>
                    </p>


                    <blockquote class="details">
                      <h3><i class="fa fa-info-circle" aria-hidden="true"></i><span class="visually-hidden">details</span> BibTeX</h3>
                      <p style="display: none;">

                    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight">
<code id="citation-code">@misc{statistics-intro_deep_learning,
    author = "Anup Kumar and Alireza Khanteymoori",
    title = "Introduction to deep learning (Galaxy Training Materials)",
    year = "2021",
    month = "01",
    day = "06"
    url = "\url{/training-material/topics/statistics/tutorials/intro_deep_learning/tutorial.html}",
    note = "[Online; accessed TODAY]"
}
@article{Batut_2018,
        doi = {10.1016/j.cels.2018.05.012},
        url = {https://doi.org/10.1016%2Fj.cels.2018.05.012},
        year = 2018,
        month = {jun},
        publisher = {Elsevier {BV}},
        volume = {6},
        number = {6},
        pages = {752--758.e1},
        author = {B{\'{e}}r{\'{e}}nice Batut and Saskia Hiltemann and Andrea Bagnacani and Dannon Baker and Vivek Bhardwaj and Clemens Blank and Anthony Bretaudeau and Loraine Brillet-Gu{\'{e}}guen and Martin {\v{C}}ech and John Chilton and Dave Clements and Olivia Doppelt-Azeroual and Anika Erxleben and Mallory Ann Freeberg and Simon Gladman and Youri Hoogstrate and Hans-Rudolf Hotz and Torsten Houwaart and Pratik Jagtap and Delphine Larivi{\`{e}}re and Gildas Le Corguill{\'{e}} and Thomas Manke and Fabien Mareuil and Fidel Ram{\'{\i}}rez and Devon Ryan and Florian Christoph Sigloch and Nicola Soranzo and Joachim Wolff and Pavankumar Videm and Markus Wolfien and Aisanjiang Wubuli and Dilmurat Yusuf and James Taylor and Rolf Backofen and Anton Nekrutenko and Bj√∂rn Gr√ºning},
        title = {Community-Driven Data Analysis Training for Biology},
        journal = {Cell Systems}
}</code>
                    </pre></div></div>
                    </p>
                    </blockquote>


<script type="text/javascript">
// update the date on load, or leave fallback of 'today'
d = new Date();
document.getElementById("citation-code").innerHTML = document.getElementById("citation-code").innerHTML.replace("TODAY", d.toDateString());
document.getElementById("citation-text").innerHTML = document.getElementById("citation-text").innerHTML.replace("TODAY", d.toDateString());
</script>

                </div>
            </div>
        </div>

        <h3><i class="far fa-thumbs-up" aria-hidden="true"></i><span class="visually-hidden">congratulations</span> Congratulations on successfully completing this tutorial!</h3>

        

        
    </section>
</div>


<footer>
    <div class="container">
        <p>
            This material is the result of a collaborative work. Thanks to the
            <a href="https://wiki.galaxyproject.org/Teach/GTN">Galaxy Training Network</a>
            and all the <a href="/training-material/hall-of-fame">contributors</a> (Anup Kumar, Alireza Khanteymoori)!
        </p>
        <p>
            Found a typo? Something is wrong in this tutorial? Edit it on
            <a href="https://github.com/galaxyproject/training-material/tree/master/topics/statistics/tutorials/intro_deep_learning/tutorial.md">GitHub</a>.
        </p>
        <p>
    The content of the tutorials and website is licensed under the <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
</p>
    </div>
</footer>

    </body>
    <script type="text/javascript" src="/training-material/assets/js/jquery.slim.min.js"></script>
    <script type="text/javascript" src="/training-material/assets/js/popper.min.js"></script>
    <script type="text/javascript" src="/training-material/assets/js/bootstrap.min.js?v=3"></script>
    <script type="text/javascript" src="/training-material/assets/js/details-element-polyfill.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="/training-material/assets/js/bootstrap-toc.min.js"></script>
    <script type="text/javascript" src="/training-material/assets/js/main.js"></script>
    <script type="text/javascript" src="/training-material/assets/js/theme.js"></script>

    <script type="text/javascript" src="/training-material/assets/js/clipboard.min.js"></script>
    <script type="text/javascript">
    var snippets=document.querySelectorAll('div.highlight');
    [].forEach.call(snippets,function(snippet){
        snippet.firstChild.insertAdjacentHTML('beforebegin','<button class="btn btn-light" data-clipboard-snippet><i class="fa fa-copy"></i>&nbsp;Copy</button>');
    });

    var clipboardSnippets=new ClipboardJS('[data-clipboard-snippet]',{
        target:function(trigger){return trigger.nextElementSibling;
    }});
    </script>
    

    <script type="text/javascript">
        if(window.location.hostname === "galaxyproject.github.io") {
            // Redirect
            var redirect = "https://training.galaxyproject.org" + window.location.pathname + window.location.search;
            $('div.container.main-content').prepend("<div class='alert alert-warning'><strong>Note: </strong>This content has a new home at <a href=\"" + redirect + "\">" + redirect + "</a>, which you will be redirected to in 5 seconds.</div>");

            window.setTimeout(function(){
                window.location.href = redirect;
            }, 5000)

        }
    </script>
</html>
